Th Roo Code Way
We recently had someone new to our community post looking for help and they made an error in their question. 

A number of you were dismissive and rude to this person and even more of you upvoted this poor behaviour. 

A minority of you were helpful. That is not how we act in the RooCode community. We accept new and old dogs. 

It was not the Roo Code way. Please be better than that.  
Thanks for calling this out. We should be terrified of any semblance to r/ChatGPTCoding ;)
New dog = Joey

Pack of dogs = Mob 


Kangaroo analogies please. The personnel department has been alerted.
Nice, I‚Äôve just started using RooCode today and part of that is checking out the community. Great to see this being called out and setting expectations.
Get Roo‚Äôd, not rude‚Ä¶
This might be the best community on reddit
Listen Bro. What are you even talking about? I thought this was a safe space for Kangaroos. Now we're talking about old dogs and new dogs....

We need to come up with some consistent naming conventions here.

A new dog is a Joey. (Baby Kangaroo)  
And old dog is a buck or a Jack. 

Put a shrimp on the Baaabie, this is the outback.
Thanks for this post
This is what people who refuse change look like (rude). Some people's comfort zones were disturbed by hordes of people building. The crowns are shaky, because under the hood the were feeling shaky, but elite. The great equalizer came.
I have technical degrees (including cs) and I love this change
Love this so much, we all started somewhere.
Amen. We discourage students even coming to reddit for the exact reason. People can be very mean when they sit behind a keyboard. Many seem to forget they too were not " a code genius" when they first started.
I have lived with Aussies and Kiwi's once, they taught me very different swear words....
Then why were these comments not removed according to rule number #1?
With all due respect sir, I also made an apparent faux pas (I‚Äôm guessing posting a link?) to the ‚ÄúGeneral‚Äù channel in Discord, and was not only kicked but immediately banned. It‚Äôs a. It confusing because I‚Äôd posted a link in the Open Hours channel earlier that day and I believe you yourself even referenced it.  If I misread, misunderstood, misinterpreted, or simply forgot a rule, doesn‚Äôt an immediate ban seem a bit extreme of a response? I‚Äôm sure most of us participate in dozens of chat forums with different rules and it‚Äôs sometimes difficult to remember each rule of each forum/chat 24/7 without making mistakes. I would respectfully ask that you might consider that as well in our shared hopes of building bridges and a stronger, healthier community. I‚Äôm pumped about the things the Roo team is doing and I‚Äôd love to be a part of it but if we‚Äôre completely intolerant to the most anodyne of mistakes by the community then surely that community may not last very long, right?
Roo overtakes Cline to become the most used app on OpenRouter

[Join our Discord so Hannes can pump the MAUs](https://discord.gg/Fku5q25B)

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/RooCode) if you have any questions or concerns.*
That‚Äôs not popularity that‚Äôs tokens
Frankly, it's just better.
honestly that is a bad metric. Im not interested in a wasteful use of token competition
I'm now using it instead of Cline. But I'm still missing a way, like with Cline, to specify a maximum of 12 API requests before asking whether to proceed. Or to specify up to $x before further approval.
That was always the case. Cline requires substantially lesser system message. Roo does not optimize on length of system message. They only give you an option to do it yourself. Cline is more thrifty with your tokens. It doesn‚Äôt have some tools too. But the focus is still there in Cline.
I mean im happy, but also... what % of that is the damn model retrying to generate the right fucking diff
RemindMe! 1 day
Roo nailed Gemini 2.5, model is basically unusable with cline, fails to update file 50% of the time and generally feels worse, that's the reason I switched to Roo, though I must say some ux staff seem better with Cline
There's one reason why.... Cline doesn't have boomerang üòÇ
Seems we‚Äôve done this 3 Friday‚Äôs in a row I think.
[deleted]
Can someone explain to me openrouter? How does it work
I fell half of those tokens are mine :/
thanks to roo team
Been on top for a while now
How I use RooCode.
I have started to use Gemini 2.0 Flash via Vertex In RooCode. 

You can also use It via Copilot and the Direct Gemini connection. 

For everyone complaining about the Limits of Sonnet, as a Guy with an MS in CS and almost 20 years in enterprise development, this is a seriously good model, and Very Underrated in my opinion. 

I was amazed how concise the replys were, it was just creative enough to try something new, but does not seem to hallucinate as much as Sonnet. 

**Here is my Setup**

* Gemini 2.0 Flash
* Set the Temperature to about 0.29 , I find anything below that, and it doesn't work well with Roos Tools. 

**Now this is Very Important and will trip up non-experienced Coders.** 

* Create a .md file call it [DesignDoument.md](http://DesignDoument.md) or what ever you want, Roo just treats it as another file.
*  In the above file, give samples of your Code that you have written/Structured, From your understanding and "**Fit for Purpose.**" 
* I have Examples for how i like my DTOs, How I retrieve Singular and Multiple Results (I hate Query strings) Search Parameters. I even go as far as Giving Examples of how I like my Fast Endpoints to be written. Short descriptions/ comments on the code line. Have a 1 or 2 line Description of Why and How come and the purpose of the code example and how it fits into your Project, My file is very comprehensive.  
* In RooCode , Use the Awesome **Power Steering Feature**, so it injects the Code/Architect Role Definitions to Keep it on Track. 
* In the **Roll definition** add a line something like this *"....design patterns, and best practices. - I Keep Reading and Referring to the "DesignDocument.md" file to keep me on track while I code to its standard and practices. I do not deviate.  ‚Äî I Do Not Write to ‚ÄúDesignDocument.md"* 
* Suggest you put **Read-only"** permission as well in Windows on the File. So you don't get updates, I do find Sonnet 3.5 trying to do this,  a lot more than Gemini. 
* The Prompt you write is - "in this Solution/Folder Read and Understand ‚ÄúDesignDoument.md" to get it started and on the Right track.

Now you run Your Prompts,  Refactoring or whatever you want it to do. 

Gemini Stays so much on track, it's amazing.

I was able to get it to create an Entire **Compliant** Fast Endpoint, I also did Refactoring of some Files to get it Up to Naming Standard and coding standard. 

Holy Crap, Efficiency increased 10-Fold. 

I thought Somebody might find this Useful. 

**Remember AI is a tool in a Toolbox**, it's **not a Replacement**, AI Works on Patterns of Previous work, that's why the "DesignDoument.md"  works very well.  

AI is Horrible if you don't keep it in Check, because Hallucinations are just repeats of patterns it's learnt, during Training. 

It **cannot** Come up with Solutions in Real time for unique Situations, read up on the **"AI Black Box Paradox"** to learn more. 

Hope it helps to make your experience RooAwsome.

Cheers. 


Excellent post. We need more best practises shared by the community.
ok, looks like an excellent approach - say you are doing a new project from scratch (so you might not have code sampes etc.) - would you run "Architect" via Sonnet first to create the documentation (and snippet codes) or you would use Flash all the way?
Wait until this guy finds ScottyMac's RooFlow. [https://github.com/GreatScottyMac/RooFlow](https://github.com/GreatScottyMac/RooFlow)
amazing, someone actually sharing practical advice who seems to be a professional, thank you!

How expensive is gemini flash via Vertex? I don't have a vertex license
Thank you for sharing this, I want to try more gemini instead claude for costs
How does this strategy compare to Gemini Thinking? Have you tried it? I could be wrong, but I would assume the thinking model would be more efficient for coding.
That‚Äôs great advice, thanks. Do you have any examples of good design documents that you could point to? I tried using a project brief, as explained in GreatScottyMac‚Äôs roo code memory bank repo, and Gemini got very much off track so I abandoned it. I didn‚Äôt include code examples though, but one of the other documents is about the tech context for the project. I‚Äôm hoping to adapt my existing docs to provide Gemini with what you have found that it needs.
I have no luck with roocode with Gemini. If you build anything other than the simplest things it just errors and gives up when it can't fix them. I'm trying to build a react native app and build for testing with expo and have spent the last 3 hours trying to get it to resolve build errors.
![gif](giphy|l4pMattUYTTM7qpIk)
A big thank you to the developers of this magnificent project
Seriously, thank you. This is maybe the most amazing tool of all time. I showed a CEO of a company some of the scripts I made (in large part thanks to Roo), and the guy was absolutely floored. I seriously can't believe this tool is free and if I ever make money with it I'll make sure to donate to the developers. I seriously love you and the rest of the opensource devs.

It's funny when people get hyped about mainstram AI releases with pretty UIs, when Opensource devs did the same thing 6 months prior. The developers of this project are my heroes. Sending all the love your way, you lovely specimens.

Also, I laugh at Primeagen talking about all the things AI can't do, he clearly just doesn't know how to use AI. WE VIBING... lmao 
The Boomerang Mode is my best friend now. Thank you!
Yes, They Are Awesome, I help anyway I can.  They need to open a GitHub Sponsor Function. We need to get them Coffee for a long time‚Ä¶
I get your point about Prime but he just did a vibe coding series where he vibes code a tower defense game while living in a tower for 7 days.
Roocode + Quasar = $
That's actually sick af!
Boomerang Mode is such a big unlock!
Would you guys recommend this over say windsurf?
Symphony: a multi-agent AI framework for structured software development
For the past few weeks, I've been working on solving a problem that's been bugging me - how to organize AI agents to work together in a structured, efficient way for complex software development projects.

Today I'm sharing **Symphony**, an orchestration framework that coordinates specialized AI agents to collaborate on software projects with well-defined roles and communication protocols. **It's still a work in progress**, but I'm excited about where it's headed and would love your feedback.

## What makes Symphony different?

Instead of using a single AI for everything, Symphony leverages Roo's Boomerang feature to deploy 12 specialized agents that each excel at specific aspects of development:

* **Composer**: Creates the architectural vision and project specifications
* **Score**: Breaks down projects into strategic goals
* **Conductor**: Transforms goals into actionable tasks
* **Performer**: Implements specific tasks (coding, config, etc.)
* **Checker**: Performs quality assurance and testing
* **Security Specialist**: Handles threat modeling and security reviews
* **Researcher**: Investigates technical challenges
* **Integrator**: Ensures components work together smoothly
* **DevOps**: Manages deployment pipelines and environments
* **UX Designer**: Creates intuitive interfaces and design systems
* **Version Controller**: Manages code versioning and releases
* **Dynamic Solver**: Tackles complex analytical challenges

## Core Features

### Adaptive Automation Levels

Symphony supports three distinct automation levels that control how independently agents operate:

* **Low**: Agents require explicit human approval before delegating tasks or executing commands
* **Medium**: Agents can delegate tasks but need approval for executing commands
* **High**: Agents operate autonomously, delegating tasks and executing commands as needed

This flexibility allows you to maintain as much control as you want, from high supervision to fully autonomous operation.

### Comprehensive User Command Interface

Each agent responds to specialized commands (prefixed with `/`) for direct interaction:

**Common Commands**
* `/continue` - Initiates handoff to a new agent instance
* `/set-automation [level]` - Sets the automation level (Dependent on your Roo `Auto-approve` settings
* `/help` - Display available commands and information

**Composer Commands:**
* `/vision` - Display the high-level project vision
* `/architecture` - Show architectural diagrams
* `/requirements` - Display functional/non-functional requirements

**Score Commands:**
* `/status` - Generate project status summary
* `/project-map` - Display the visual goal map
* `/goal-breakdown` - Show strategic goals breakdown

**Conductor Commands:**
* `/task-list` - Display tasks with statuses
* `/task-details [task-id]` - Show details for a specific task
* `/blockers` - List blocked or failed tasks

**Performer Commands:**
* `/work-log` - Show implementation progress
* `/self-test` - Run verification tests
* `/code-details` - Explain implementation details

...and many more across all agents (see the README for more details).

### Structured File System

Symphony organizes all project artifacts in a standardized file structure:

```
symphony-[project-slug]/
‚îú‚îÄ‚îÄ core/                  # Core system configuration
‚îú‚îÄ‚îÄ specs/                 # Project specifications
‚îú‚îÄ‚îÄ planning/              # Strategic goals
‚îú‚îÄ‚îÄ tasks/                 # Task breakdowns
‚îú‚îÄ‚îÄ logs/                  # Work logs
‚îú‚îÄ‚îÄ communication/         # Agent interactions
‚îú‚îÄ‚îÄ testing/               # Test plans and results
‚îú‚îÄ‚îÄ security/              # Security requirements
‚îú‚îÄ‚îÄ integration/           # Integration specs
‚îú‚îÄ‚îÄ research/              # Research reports
‚îú‚îÄ‚îÄ design/                # UX/UI design artifacts
‚îú‚îÄ‚îÄ knowledge/             # Knowledge base
‚îú‚îÄ‚îÄ documentation/         # Project documentation
‚îú‚îÄ‚îÄ version-control/       # Version control strategies
‚îî‚îÄ‚îÄ handoffs/              # Agent transition documents
```

### Intelligent Agent Collaboration

Agents collaborate through a standardized protocol that enables:
* Clear delegation of responsibilities
* Structured task dependencies and sequencing
* Documented communication in team logs
* Formalized escalation paths
* Knowledge sharing across agents

### Visual Representations

Symphony generates visualizations throughout the development process:
* Project goal maps with dependencies
* Task sequence diagrams
* Architecture diagrams
* Security threat models
* Integration maps

### Built-in Context Management

Symphony includes mechanisms to handle context limitations:
* Contextual handoffs between agent instances (with user command `/continue`)
* Progressive documentation to maintain project continuity

### Advanced Problem-Solving Methodologies

The Dynamic Solver implements structured reasoning approaches:
* Self Consistency for problems with verifiable answers
* Tree of Thoughts for complex exploration
* Reason and Act for iterative refinement
* Methodology selection based on problem characteristics

## Key benefits I've seen:

* **Better code quality**: Specialized agents excel at their specific roles
* **More thorough documentation**: Every decision is tracked and explained
* **Built-in security**: Security considerations are integrated from day one
* **Clear visibility**: Visual maps of goals, tasks, and dependencies
* **Structured workflows**: Consistent, repeatable processes from vision to deployment
* **Modularity**: Focus on low coupling and high cohesion in code
* **Knowledge capture**: Learning and insights documented for future reference

## When to use Symphony:
Symphony works best for projects with multiple components where organization becomes critical. Solo developers can use it as a complete development team substitute, while larger teams can leverage it for coordination and specialized expertise.

If you'd like to check it out or contribute: [github.com/sincover/Symphony](https://github.com/sincover/Symphony)

Since this is a work in progress, I'd especially appreciate feedback, suggestions, or contributions.

Thanks!
Wtf bro, this looks insane, can‚Äôt wait to try this out
Well fellow devs, it's been real.
Would love to integrate this here:
https://mcparty.ai

Your system seems about as comprehensive as mine, but it‚Äôs actually organized with a readme üòÜ‚Äîwill be borrowing some of your concepts, thank you!
- Agents: https://github.com/rawr-ai/ai/tree/main/ai/agents
- Playbooks: https://github.com/rawr-ai/ai/tree/main/ai/playbooks

‚Äî‚Äî‚Äî

What do you use for managing the project? I just hooked up my agent team to use Linear, which has been pretty insane.
This looks super cool. Will be giving it a try today/tomorrow and provide feedback. Feel free to join the Discord, I‚Äôm sure many people will have questions
Wow, this is like the next iteration of boomerang tasks! Going to be trying this out for my existing NextJS project.¬†
After I tried it, I used up a lot of tokens to check and update the status of files and todo. Probably almost half of it was for editing and updating \*.md files. I think the status updates are too much.
Very cool. I've been doing similar things manually so automating it would be huge.
How would you recommend utilizing this with an existing project? Would it be as simple and telling the composer it‚Äôs an existing project and to analyze the current structure/code?
Concept is next level (maybe akin to Devin?) Practicalities are uncertain (will probably change after test drive). It surely will burn down my wallet. What LLM do you use? I would guess Gemini 2.5pro for cost sake?
I have try it.   
In the plan phase, it works good. But in the development stage, it focuses too much on update logs, plan and other md file without doing the real work much.   
Since each step called AI API so it kinda waste the prompt to just update those markdown files.   
Logging the work is good, and updating plan is also good but at the end, the work need to be done.   
There are lot of things need to be improved but the product is promising.   
For now, I will stop the agent after they completed the high level plan.
Good job, will read through your project this week
This looks awesome! Any support for MCPs?
I played with this a bit and am impressed. 

  
Currently folks are discussing using Linear or mcp memory servers. I see your system builds its own task list, have you considered integrating with systems like that?
I spent the past few weeks trying to develop my own system (for local LM‚Äôs like Gemini-27b) but couldn‚Äôt quite dial it in to the level of reliability of your Symphony. Although Symphony doesn‚Äôt seem to work well for smaller models either (yet), I‚Äôve been running it for a few days with gpt-4o-mini and it‚Äôs been pretty good so far. I probably should‚Äôve test with a smaller project first (building a non-trivial web app) but so far so good. Someone mentioned that it seems over-engineered but on the contrary I very much prefer the rather pedantic features such as detailed status logs and constantly updating task lists to maintain context (please easier for human and AI audit). Although I suspect it will take me the better part of a week to begin seeing my website come to life (due to my own time constraints), I‚Äôll provide another update when it‚Äôs done, good bad indifferent.
RemindMe! 7 days
Looks great, the roles looks a lot alike my agent defined within RooFlow but seems more refined, gonna make do a try. Well done!

  
A missing agent might be a SEO/Discoverability Agent that write down report on the discoverability score and actions to improve it. 

Is there some prompt or recommendation on how to set it up for dedicated project/conventions? e.g. initial fill of the specs, enforces DDD usage, ...?
Sounds expensive with the API costs. :D

Lovely project.
The Ultimate Roo Code Hack: Building a Structured, Transparent, and Well-Documented AI Team that Delegates Its Own Tasks
After weeks of experimenting with Roo Code, I've managed to develop a multi-agent framework that's dramatically improved my productivity. I wanted to share the approach in case others find it useful.

# The Core Concept: Specialized Agents with Clear Boundaries

Instead of using a single generalist AI, I designed this system of specialized agents that work together through an orchestrator: Kudos to Roo Code, honest stroke of genius with this newest setup.

1. **Orchestrator**: The project manager that breaks down complex tasks and delegates to specialists
2. **Research Agent**: Deep information gathering with proper citations and synthesis
3. **Code Agent**: Software implementation with clean architecture
4. **Architect Agent**: System design and technical strategy
5. **Debug Agent**: Systematic problem diagnosis and solution validation
6. **Ask Agent**: Focused information retrieval with proper attribution

# But that's all pretty standard, right? The Secret Sauce: SPARC Framework

My system runs on what we call the SPARC framework with these key components:

* **Cognitive Process Library**: 50 reusable reasoning patterns (e.g., Exploratory Analysis = Observe ‚Üí Infer)
* **Boomerang Logic**: Tasks are assigned and must return to the orchestrator when complete
* **Structured Documentation**: Everything is logged with consistent formats
* **"Scalpel, not Hammer" Philosophy**: Always use the minimum resource for the job

# How Tasks Flow Through the System

1. **Initial Request**: User submits complex project
2. **Decomposition**: Orchestrator breaks it into primitive subtasks
3. **Assignment**: Tasks are delegated to specialized agents with precise instructions
4. **Processing**: Specialists complete tasks within their domain
5. **Verification**: Orchestrator validates output quality
6. **Integration**: Components are assembled into final deliverable

# Standardized Task Prompts

The magic happens in how tasks are structured. Every subtask prompt follows this exact format:

    # [Task Title]
    
    ## Context
    [Background and project relationship]
    
    ## Scope
    [Specific requirements and boundaries]
    
    ## Expected Output
    [Detailed deliverable specifications]
    
    ## [Optional] Additional Resources
    [Tips, examples, or references]
    

# Multi-Agent Framework Structure: Ensuring Consistency Across Specialized Agents

# Three-Part Structure for Each Agent

We developed a consistent three-part structure for each specialized agent in our multi-agent system:

# 1. Role Definition

Every agent has a clear role definition with these standardized sections:

    # Roo Role Definition: [Specialty] Specialist
    
    ## Identity & Expertise
    - Technical domain knowledge
    - Methodological expertise
    - Cross-domain understanding
    
    ## Personality & Communication Style
    - Decision-making approach
    - Information presentation style
    - Interaction characteristics
    - Communication preferences
    
    ## Core Competencies
    - Specific technical capabilities
    - Specialized skills relevant to role
    - Analytical approaches
    
    ## [Role-Specific] Values
    - Guiding principles
    - Quality standards
    - Ethical considerations
    

This component establishes the agent's identity and specialized capabilities, allowing each agent to have a distinct "personality" while maintaining a consistent structural format.

# 2. Mode-Specific Instructions

Each agent receives tailored operational instructions in a consistent format:

    # Mode-specific Custom Instructions: [Agent] Mode
    
    ## Process Guidelines
    - Phase 1: Initial approach steps
    - Phase 2: Core work methodology
    - Phase 3: Problem-solving behaviors
    - Phase 4: Quality control procedures
    - Phase 5: Workflow management
    - Phase 6: Search & reference protocol
    
    ## Communication Protocols
    - Domain-specific communication standards
    - Audience adaptation guidelines
    - Information presentation formats
    
    ## Error Handling & Edge Cases
    - Handling incomplete information
    - Managing ambiguity
    - Responding to unexpected scenarios
    
    ## Self-Monitoring Guidelines
    - Quality verification checklist
    - Progress assessment criteria
    - Completion standards
    

This component details how each agent should operate within its domain while maintaining consistent process phases across all agents.

# 3. Mode Prompt Append

Finally, each agent includes a system prompt append that integrates SPARC framework elements:

    # [Agent] Mode Prompt Append
    
    ## [Agent] Mode Configuration
    - Agent persona summary
    - Key characteristics and approach
    
    ## SPARC Framework Integration
    1. Cognitive Process Application
       - Role-specific cognitive processes
    2. Boomerang Logic
       - Standardized JSON return format
    3. Traceability Documentation
       - Log formats and requirements
    4. Token Optimization
       - Context management approach
    
    ## Domain-Specific Standards
    - Reference & attribution protocol
    - File structure standards
    - Documentation templates
    - Tool prioritization matrix
    
    ## Self-Monitoring Protocol
    - Domain-specific verification checklist
    

This component ensures that all agents integrate with the wider system framework while maintaining their specialized focus.

# Consistency Mechanisms Across Agents

To ensure all agents function cohesively within the system, we implemented these consistency mechanisms:

# 1. Common SPARC Framework

All agents operate within the unified SPARC framework which provides:

* Shared cognitive process library
* Standardized boomerang logic for task flow
* Consistent traceability documentation
* Universal ethics layer
* Uniform file structure standards

# 2. Standardized Search & Citation Protocol

Every agent follows identical guidelines for handling external information:

* Temporal references instead of specific dates
* 25-word limit for direct quotes
* One quote maximum per source
* 2-3 sentence limit for summaries
* Never reproducing copyrighted content
* Proper attribution requirements

# 3. Unified Token Optimization

All agents apply the same approach to context management:

* 40% context window limit
* Progressive task complexity
* Minimal necessary context packaging
* "Scalpel, not hammer" philosophy

# 4. Consistent Task Structuring

Every task in the system follows the standardized format:

    # [Task Title]
    
    ## Context
    [Background information]
    
    ## Scope
    [Requirements and boundaries]
    
    ## Expected Output
    [Deliverable specifications]
    
    ## [Optional] Additional Resources
    [Helpful references]
    

# Agent-Specific Specializations

While maintaining structural consistency, each agent is optimized for its specific role:

|Agent|Primary Focus|Core Cognitive Processes|Key Deliverables|
|:-|:-|:-|:-|
|**Orchestrator**|Task decomposition & delegation|Strategic Planning, Problem-Solving|Task assignments, verification reports|
|**Research**|Information discovery & synthesis|Evidence Triangulation, Synthesizing Complexity|Research documents, source analyses|
|**Code**|Software implementation|Problem-Solving, Operational Optimization|Code artifacts, technical documentation|
|**Architect**|System design & pattern application|Strategic Planning, Complex Decision-Making|Architectural diagrams, decision records|
|**Debug**|Problem diagnosis & solution validation|Root Cause Analysis, Hypothesis Testing|Diagnostic reports, solution implementations|
|**Ask**|Information retrieval & communication|Fact-Checking, Critical Review|Concise information synthesis, citations|

This structured approach ensures that each agent maintains its specialized capabilities while operating within a consistent framework that enables seamless collaboration throughout the system.

# Results So Far

This approach has been transformative for:

* Research projects that require deep dives across multiple domains
* Complex software development with clear architecture needs
* Technical troubleshooting of difficult problems
* Documentation projects requiring consistent structure

The structured approach ensures nothing falls through the cracks, and the specialization means each component gets expert-level attention.

# Next Steps

I'm working on further refining each specialist's capabilities and developing templates for common project types. Would love to hear if others are experimenting with similar multi-agent approaches and what you've learned!

*Has anyone else built custom systems with Roo Code? What specialized agents have you found most useful?*
The T in SPARC stands for Token Usage Optimization
Do you have a GitHub page?
Looks promising
I don't think you know what a "hack" is  üòÇ

But thanks for the information. I can see some of this being useful, although much of it looks unnecessary maybe (do I really need to define ethics guidelines for each agent)? Also including some specific examples would've been helpful.
Very interesting. Following this.
Comments on this post seems like bots ü§î
So can I just drop the documentation in your github link into a repository, then ask roo code to set up a bunch of modes based on it?

Is that the basic starting point or is there more I need to do?
I built one with a kind of similar premise called MicroManager, where the goal is to be able to use less capable models to do the grunt work and ideally save money. [https://github.com/adamwlarson/RooCodeMicroManager](https://github.com/adamwlarson/RooCodeMicroManager)

I really like some of the ideas you have in yours, it would be interesting to compare results from them.
I've been working in this same direction. One suggestion is to consider creating a DevOps agent for deploying, managing and verifying infrastructure. I have done something similar and setup the Cloudflare MCP for it to use.
Keep us updated. Would love to try
would love to build on top of this
Nice
Are you gonna publish your modes?
I‚Äôve had really good results with using repomix to create file that contains my overall project context that I attach to the agent and tell him to make task list for each implementation or feature and I have a task manager role which creates tasks and every agent has to strictly follow the tasks step by step. Also TDD is very good
One suggestion: The setup process seems needlessly complicated. It would be much easier if you can just have everything set up so that people can just download it into their root folder.
Thanks
The SPARC framework was originally built by [https://github.com/ruvnet](https://github.com/ruvnet) He has build some amazing stuff in this GIT and I have learned a ton from him.
I am also building a custom one. Similar to your approach.
Thanks for the headup, I just switched my chuckchuk setup to SPARC Orchastrator, let's see what it spit out until evening.
Getting 404 error!
How do we include sparc in our project
I am not getting a starting point to use SPARC. From what I have heard, it seems promising but I need to get my hands dirty to see how it works.

Two questions if you can help -

1. If I have to start a new project, have a decent idea as to what needs to be built, features, etc, how do I get started?

2. Similar to above but on an existing project to add new features. Like I have done the backend but need to develop the frontend now. How do I get started?
I copied the contents of your Git repo into my project folder. But Roo doesn't pick up these role definitions. 

Do they need to be added manually in the GUI?
Would you mind to point on to the .roo config file so i can try it out? <3
Heres a link to part 2! 

[https://www.reddit.com/r/RooCode/comments/1kbtxb6/the\_ultimate\_roo\_code\_hack\_20\_advanced\_techniques/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/r/RooCode/comments/1kbtxb6/the_ultimate_roo_code_hack_20_advanced_techniques/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)
This is amazing and can thank you enough for your contribution. Have you looked at Adam's micromanager? What would make something like this even better would be adding functionality from that which could delegate easier and less complex tasks out to cheaper llms.
Honestly,  your contribution is gold. I hope you can monetise your efforts!
[deleted]
ü™É Boomerang Tasks: Automating Code Development with Roo Code and SPARC Orchestration. This tutorial shows you how-to automate secure, complex, production-ready scalable Apps.
This is my complete guide on automating code development using Roo Code and the new Boomerang task concept, the very approach I use to construct my own systems.

SPARC stands for Specification, Pseudocode, Architecture, Refinement, and Completion.

This methodology enables you to deconstruct large, intricate projects into manageable subtasks, each delegated to a specialized mode. By leveraging advanced reasoning models such as o3, Sonnet 3.7 Thinking, and DeepSeek for analytical tasks, alongside instructive models like Sonnet 3.7 for coding, DevOps, testing, and implementation, you create a robust, automated, and secure workflow.

Roo Codes new 'Boomerang Tasks' allow you to delegate segments of your work to specialized assistants. Each subtask operates within its own isolated context, ensuring focused and efficient task management. 

SPARC Orchestrator guarantees that every subtask adheres to best practices, avoiding hard-coded environment variables, maintaining files under 500 lines, and ensuring a modular, extensible design.

ü™É See: https://www.linkedin.com/pulse/boomerang-tasks-automating-code-development-roo-sparc-reuven-cohen-nr3zc
So would people recommend this Boomerang workflow, or the one in the highlighted threads by one of the mods here? This one is different because it has a TDD mode and that's the way I code with AI, and noticed the best results, but curious about whether this one works  or stick with the other one.
All these groundbreaking models start being brilliant and when they get exhausted they automatically slow down the level of intelligence. Sonnet was brilliant one month ago and now my roo version is sloppy as hell. Not taking direction, being forgetful. Costing  fortunes in tokens. Same behaviour two years ago with early iterations of chat gpt. We're miles away from agentic development when models act the dumbass from time to time. I'll sit on the sidelines and wait until a truly agentic system comes along with roo. We're many 6 months away.
This is gold! Thank you so much
this got pricey quick
Love this. Hope to have. Time to give it a try soon! I wish they let me just sit there and play around with this stuff all day üíï
I gave this a try, but my Orchestrator did not generate any subtasks and instead just switched to Code mode and did the entire task in there.

But big +1 for the easy to drop in .roomodes file.

I set Orchestrator and Architect to 3.7 thinking and all the other modes to normal 3.7.
Right in time! truly life-saver
Did you test this on other models? I keep getting this error: 'Cannot read properties of undefined (reading '0').' I am using Gemini 2.5 PRO.
I know we all dream of paying anthropic and co as much money as possible, so perhaps others don't care.. but to the extent any others are users of the memory bank.... did you keep that custom prompt in roocode? Or only use the framework above? wary of token cost of keeping it..
Are you on the discord? I wanted to ask you some questions about your process
Please help! The installation guide for this amazing feature says that you can set cline\_custom\_modes.json as global, but I can‚Äôt find where to put it ‚Äî does anyone know?
Tried using this with exclusively OpenAI Models. (o3-mini-high, 4o) 

It's a far cry from describe a detailed application and let it run overnight to find a solution.

Curious to know what specific setup you're using to achieve what was described. And maybe show the demo app that was created.
Been using it for the last few hours. It is really good. There's nothing it does that you can't accomplish with just Roocode or other similar tools, but it takes so much of the manual work out of it. Looking forward to seeing how this concept evolves.
can this be used with memory bank?
Guy, this is amazing. The system enables Boomerang to be effective on projects more complicated than checkers.
Try it w quasar. Works great!
u/Educational_Ice151 How did you modify the original modes like "ask" and "architect"? By default those modes are not editable in these settings.
Any tips on how to get it working well?

Im guessing we start with SPARC Orchestrator and give it the main thing and the project specs. And let it go?

Or should we be building a plan in a file with one of them first to then follow?   
It seems TDD just goes and does its thing, then auto-coder makes stuff, then updates a whole bunch of stuff TDD did anyway?
The old guy in me saw SPARC and got all sentimental about my old Sun SPARCstations.
Anyone interested in an updated tutorial for setting up RooCode the best way possible
Hey,  
I'm trying to make a tutorial about how to install the "good" setup for Roo Code on any project.  
I was wondering how many people it would help so I see if it's worth it.

For anyone wondering, actually I use Roo Code with Deepseek V3 0324 for coding and R1 for planning (Architect mode).  
I'm also using Roo Flow for memory management. Actually i'm planning on adding MCPs (I don't really need them for now as i'm mostly trying to find the most stable way to use the new Deepseek v3 which is wild).
The most useful would be a current best practice on how to tackle context management. Using Roo Flow? Memory bank? MCP?  How to keep RooCode on track across sessions. 

Another particularly helpful thing would be which models to start with for which modes or tasks. Maybe a set for ‚Äúmoney is tight‚Äù and another set for ‚Äúsome else is paying‚Äù.
yes, yes, and yes.
how does the roo code profile system fit in with the vs code profile system.?

what are good multiple profiles e.g. cheap, mid, espensive, for each role.

any custom roles?

how to set it all up without UI - json only please.

glama? openrouter? requesty? pros and cons?

how to sync configs / profiles across installations. if not possible, at a minimum, backup restore strategies (save configs in git?)
I would love a tutorial for setting up orchestrators and code reviewer agents!

A video like a Loom or similar screenshare would be beneficial to a lot of people.
Right now I try to use Gemini 2 Pro for architect/Orchestrator to destructure tasks and have it set to a custom temperature of somewhere around 0.8 and then I have 3.5 Sonnet with a temperature of about 0.2 to do the tasks broken down by Gemini. I'd be happy to know if there's a way to optimize things in two areas. First would be getting things done right faster. Second would be optimizing token usage which in part goes with the first one.
Thumbs up for an improved tutorial! Thanks in advance.
![gif](giphy|WPoppdas67C6kzxVkg)
Yes please! I'm switching over from Cline and would love a tutorial.
Yes please. And what's your experience with roocode vs cline?
Please make the tutorial
That would be cool, please share it
I will start working on it this night! I've read most of the comments and will TRY to adress every point
Deepseek V3 0324 is not available on ollama. how to run it locally for RooCode ?
![gif](giphy|Zai3ffKrUcLFwalDor)
It may take more time than expected as a lot of people want a lot of different things in it.
Yes definitely !
Yes, please make a tutorial. I couldnt find any on youtube on how to set up rooflow.
Yes please, I was just looking at using deepseek but would love to hear your thoughts and best ways to use all these tools you mentioned. I am burning too many $$$ using Claude, so having some other strategies would be awesome. Thank you!!
a tutorial would be great - include github best practice as well, live server, browser use etc.  I would be interested in that.
That is an excellent idea. Using DeepSeek in the way you are would be a great start.
Yes
please do it, I just started using today, not sure about how to perfectly set it up in terms of all the settings it has.
Codex o3 Cracked 10x DEV
Okay okay the title was too much.

But really, letting o3 rip via Codex to handle all of the preparation before sending an orchestrator + agent team to implement is truly ü§å

Gemini is excellent for intermediate analysis work. Even good for permanent documentation. But o3 (and even o4-mini) via Codex 

The important difference between the models in Codex and anywhere else:
- In codex, OAI models finally, truly have access to local repos (not the half implementation of ChatGPT Desktop) and can ‚Äúthink‚Äù by using tools safely in a sandboxed mirror environment of your repository. That means it can, for example, reason/think by running code without actually impacting your repository.
- Codex enables models to use OpenAI‚Äôs own implementation of tools‚Äîi.e. their own tool stack for search, images, etc.)‚Äîand _doesn‚Äôt burn tokens_ on back to back tool calls while trying to use custom implementations of basic tools, which is required when running these models anywhere else (e.g. Roo/every other)
- It is really really really good at ‚Äúworking the metal‚Äù‚Äîit doesn‚Äôt just check the one file you tell it to; it follows dependencies, prefers source files over output (e.g. config over generated output), and is purely a beast with shell and python scripting on the fly.

All of this culminates in an agent that feels as close to ‚Äúthat one engineer the entire org depends on for not falling apart but costs like $500k/year while working 10hrs/week‚Äù

In short, o3 could lead an eng team.

Here‚Äôs an example plan it put together after a deep scan of the repo. I needed it to unf*ck a test suite setup that my early implementation of boomerang + agent team couldn‚Äôt get working.

(P.S. once o3 writes these:
1. ‚ÄòPM‚Äô agent creates a parent issue in Linear for the project, breaks it down into sub issues, and assigns individual agents as owners according to o3‚Äôs direction.
2. ‚ÄòCommand‚Äô agent then kicks off implementation workflow more as a project/delivery manager and moves issues across the pipeline as tasks complete. If anything needs to be noted, it comments on the issue and optionally tags it, then moves on.
3. Parent issue is tied to a draft PR. Once the PR is merged by the team, it automatically gets closed [this is just a linear automation])


 Could you share more about how you set up your multi agent system in  roo and how you prompt for this in codex?
Hey man totally agree. OAI currently only works well in codex. 

I have posts coming to the same conclusion!

Can I PM you about the multiagent set up?

My situation is the same as you slogging through 600 failing tests after a refactor. I‚Äôve been using Codex but haven‚Äôt messed around with Roos multiagent mode. 

As in which was implemented with which? I‚Äôll also dump your post in GPT but it wasn‚Äôt immediately obvious and I‚Äôve heavily been using Roo / Cline / Cursor / windsurf.

‚Äî‚Äî‚Äî‚Äî


Edit: are you saying you only used o3 to draft the documentation plan, and then roo‚Äôs multi agent to read the plan and implement?
Would love to see the prompt you used with codex get that prepped. I typically do this manually myself with an llm directly to end up with a roadmap plus detailed task lists for each phase and subphase within the roadmap. Would be Keen to compare
Please share your setup! This sounds like an upgrade from Manus implementation. Instant karma upgrade
Do you actually need o3 Codex, or can you use the o3 via the API and have the \`Architect\` mode use o3?
Could Roo mimic the API calls from Codex to get openapi models to work better with it?
So are you just telling o3 the names of the roo agents available to it, and having it draft up a plan using them?
Looks interesting. Like some of the other comments, I'd be interested in knowing the whole setup. Or a closer in example with a bit more details.   
I've tried to do something like this a few times, and I think having an orchestration layer on top of Roo is a neat idea.
Need more details
So basically while Roocode fires away you have codex scanning your files and making suggestions?
What is Codex?
Is it only usable with API or can you use it with the 'chat' sub?
How is the price to run it? I saw your screenshot, it costs about $0.18 per message? How the price compares to direct API usage on Roo?
Pls make a tutorial on how to implement this. Or do you simply feed the image as the instructions for the codex cli?
can you talk about cost. or anyone for that matter. new dev here very interested but very dumb as well lmao.
TBC: you‚Äôre referring to codex CLI or something else branded ¬†codex? ¬†There‚Äôs so much coming out this year alone‚Ä¶.
Why not just use aider?
what do you mean by 

"orchestrator + agent team"
Wait - what does this mean for Roo, can it be used in conjunction with Roo? FFS I leave for one day and the world is 260 steps ahead
\> All of this culminates in an agent that feels as close to ‚Äúthat one engineer the entire org depends on for not falling apart but costs like $500k/year while working 10hrs/week‚Äù

Seriously doubt it, unless your codebase is <5k LOC or you want to have at most superficial code updates like one on the screenshot.

\> In short, o3 could lead an eng team.

Hopefully not any eng team I'm apart of, thanks..
the repo:

https://github.com/openai/codex
How is this relevant for this sub ?
Roo Code 3.10 - Release Notes
If you find Roo Code helpful, please consider **[leaving a review](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details)** on the VS Code Marketplace. Your feedback helps others discover this tool!

## üì¢ Suggested Responses
Added options for quick responses when Roo asks questions. Pick from a list instead of typing everything out. (thanks samhvw8!)

## üìï Large File Support
Reading large files is now more efficient with chunked loading. This allows you to work with extremely large files that would previously cause context issues. (thanks samhvw8!)

## üó£Ô∏è Improved @-mentions
Completely redesigned file and folder lookup system when using @-mentions. Now uses server-side processing with proper gitignore support, scanning up to 5000 workspace files and giving you much more accurate results when referencing files in your workspace.

##üêõ **Bug Fixes and Other Improovements**
* Make suggested responses optional to not break overridden system prompts
* Fix MCP error logging (thanks aheizi!)
* Fix changelog formatting in GitHub Releases (thanks pdecat!)
* Fix bug that was causing task history to be lost when using WSL
* Consolidate code actions into a submenu (thanks samhvw8!)
* Improvements to search_files tool formatting and logic (thanks KJ7LNW!)
* Add fake provider for integration tests (thanks franekp!)
* Reflect Cross-region inference option in ap-xx region (thanks Yoshino-Yukitaro!)
I mean, like seriously, you guys are the best! 

I‚Äôm here just trying to learn from the best, and hoping one of you guys at Roo responds as I think it would be helpful to know. Besides this great product right here what other products do you use? I‚Äôm talking about apps, and others that you guys love that just make you work better/faster. :).‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã
You are on fire. 

One feature I‚Äôd LOVE to see is BYOK dictation input. 

I want to use voice input to speak to Roo, but the built in osx dictation just doesn‚Äôt cut it. 

I know the Google voice to text and OpenAI Whisper are much better. Would love to be able to use that in Roo. 

Thanks for everything
Congrats Team.  
What works:  
1. Quick response is useful.  
2. Options for no. of lines per file in read\_file given to the user is useful.  
3. Custom system prompt works well. (2k per interaction instead of 8k) without any loss of functionality.  


1. Tiny bug: Suggested response in Windows not readable due to low contrast (black text on dark background).  
2. Bug: Model sent an invalid response comes in read (or something like that) then suddenly the state of the workspace is unstable. Accept button is not shown i believe.  
3. Feature request: Configuration for each mode shall have: individual 'always approve' options per mode. (I dont want orchestrator to change mode to code, I only want it to spawn tasks). Enable browser use (not talking about auto approve here) on a per profile basis. Presently it is on or off fully. I want to disable browser use when I choose a model which supports that. (or you have already promgrammed this in, saving on system prompt).  
4. Spawned tasks to automatically have reference to files looked at recently by parent task. Only the task description is many times not enough. This can be auto added by roo. Spawned tasks provide their own summary, but a roo generated info of names of changed methods/classes will help. I have had huge syncing issues across tasks where method names overlap and cause problems at the integration level.  
5. Allow different context management for different models? R1 suffers from only 64k context. Architect mode requires larger file line sizes to be sent than code mode.  
6. Allow disable switching to standard modes (like ask, debug) as option. I have a custom python-coder with instructions. Architect always wants to switch to code mode rather than my python-coder mode.  
7. Terminal integration is still broken in windows even after setting 20 seconds, the integration unavailable message comes at 3 seconds itself.  
8. Allow selecting parts of edit mode (like disabling multi diff for less intelligent models) while still multi diff using for claude.  
9. Allow option to disallow write\_file (this is required when I know it cant complete the whole file at all and still it wants to do it). Only diff or search replace or append content allowed.  
10. For bulk refactoring, create 2 new tools like these:  
(if diff editing provides for copy pasting of say 300 lines without specifying the complete lines this is not required.)  
  
`copy_and_paste_lines: Copy lines from a source file and paste them to a target file. Useful for refactoring a large single file into separate files without specifying each line manually.`   
`Parameters:`  
`source_path*Relative path to the source file`  
`target_path*Relative path to the target file (can be the same as source)`  
`start_line*Starting line number to copy (0-based index)`  
`end_line*Ending line number to copy (0-based index, inclusive)`  
`expected_start_content*Expected content at start_line for safety validation - use this to prevent accidental operations on wrong content`  
`expected_end_content*Expected content at end_line for safety validation - use this to prevent accidental operations on wrong content`

`delete_lines: Delete specified lines from a file. Useful for removing content without manually specifying each line.`  
`Parameters:`  
`path*Relative path to the file`  
`start_line*Starting line number to delete (0-based index)`  
`end_line*Ending line number to delete (0-based index, inclusive)`  
`expected_start_content*Expected content at start_line for safety validation - use this to prevent accidental operations on wrong content`  
`expected_end_content*Expected content at end_line for safety validation - use this to prevent accidental operations on wrong content`

I have used these in a mcp tool with Claude desktop for refactoring large files into smaller ones and matches with human copy pasting and deleting worrying only about start and end of block without line limit.

Thanks guys.
Where can I get additional information regarding the extemely large files? Does this employ any tequniques, that effectifly expand the context window? Or do they process the first section of the file, take relevant notes, forget the exact details that are not relevant and then look at the next chunk? 

  
I am analysing the structure of xml files that exceed the claude 3.7 context window, and if this in any way helps with this, it would be imensly usefull to know.
Love it. I did have some issues with the @ mentioning of files though, especially when I had nested repos. I'll play around a bit more
Demmm roo code is releasing new version Evey other dayyy.....dev team is on fireeeee
Awesome team! Thank you for your hard work on Roo.
It just keep getting better and better lfggggg üôèüôè
Good stuff!
I love too code use it a lot this week since I found it and it‚Äôs great but find that it falls back to rewriting the whole file and not handling the replace very often which seems odd not sure if it‚Äôs roos fault or Gemini but the retries and then full code generation really chews through tokens
https://preview.redd.it/ev72cj73hgqe1.png?width=1108&format=png&auto=webp&s=378bbe5a8eddb16c41fe0edcb568a29fb9497320

Great work guys! Just wanted to mention the v3.8.6 lingering around.
this is the best thing that has happened to me since cloud, now, I need to make it work reliably with any other model that sonnet through open router.
Caching for Gemini 2.5 pro now available, min 4K cache size
Hopefully this will result in significant savings when integrated into Roo, let‚Äôs gooo

https://x.com/officiallogank/status/1914384313669525867?s=46&t=ckN8VtkBWW5folQ0CGfd5Q

Update: there‚Äôs an open PR for OpenRouter‚Äôs caching solution that will hopefully get merged soon! https://github.com/RooVetGit/Roo-Code/pull/2847
YES this is a critical feature that would be amazing to add to Roo Code
I'd like roo to be able to batch multiple files reads in one request so the full context isn't resubmitted for each one, and be able to pre-approve writes on multiple of them too so it can all go down in one prompt and response.  That plus caching should dramatically lower spend once the context has grown.

Maybe also let you do the file read as part of the prompt instead of response, with selected files, so it does less back and forth unless it needs more files.

If you ask roo to read these 5 files and edit them like so, and you have already have 200K context, you end up processing 2M tokens of prior chat context (200K + your request, roo asks to read first file, 200K + file after approval, roo asks to write, 200K + diff after approval, roo asks to read the next, 200K more, roo asks to write, 200k more, etc.) plus the reads and new stuff, instead of just 200K plus the reads and new stuff.  It won't waste 2M of your context, but it burns token spend.
Hopefully through openrouter soon, not yet listed on their docs

https://openrouter.ai/docs/features/prompt-caching
So even cheaper? Crazy
Omg that's amazing
I saw it was merged. Is it ready to be used?
prompt caching reduced my gemini 2.5 costs roughly 90 percent
thank you guys, currently watching this thing working with a 500k context window for 10c an api call. magical

edit: i see a few comments asking the same thing, just fyi it is not enabled on 2.5 pro exp, but it's enabled by default on 2.5 pro preview

edit2: nevermind they removed the option lmao :/
hmm mine doesn't seem to be working? is there a setting you have to turn on?

i'm still getting $0.20 API calls even at 90k context window.

EDIT: IMPORTANT!¬†**Use Gemini API in Roo if you want caching**. Does NOT cache on Vertex AI API yet (unsure if Roo side or Google side issue)
IMPORTANT! **Use Gemini API in Roo if you want caching**. Does NOT cache on Vertex AI API yet (unsure if Roo side or Google side issue)
Does it work via OpenRouter? or just via Gemini?
It's cheap, but it's crazy slow, has anyone figured out a workaround?
bruh, I was just gonna come here to say the same thing and see if anyone else was noticing... HOLY SSSHHH it's SO much cheaper now!
I would like to know more... ü§î
anyone else getting this error? It worked for a few minutes but now stuck on 503. Is the server overlaoded? got status: 503 Service Unavailable. {"error":{"code":503,"message":"The service is currently unavailable.","status":"UNAVAILABLE"}}

Retry attempt 1  
Retrying in 1 seconds...
Vertex AI or Openrouter?
tell us the version of roo youre on
Vertex? Gemini API?
Just gave it try with 2.5 pro preview. I see some difference in roo cost estimate. But we all know how long it takes the big G to update api billing. I tried what would have cost around $5. Hope to see $1 - $1.30 when billing is updated.

Thank you for sharing.
what exact model of gemini are you using? cause i'm getting an error for too many requests on what i've been using before - pro exp 03 25
I think there is no additional setting. This should be done from roo.
I'm out of the loop since I use windsurf.
Is the Gemini 2.5 not free anymore?
How does caching do that so effectively?
aaaand it's gone
Hi, how to turn it on ? Thx
ü¶ò Roo code‚Äôs Boomerang task orchestration, especially as implemented using the SPARC framework, should adopt Google‚Äôs new A2A specification. Here‚Äôs why.
Boomerang Tasks, combined with SPARC‚Äôs recursive test-driven orchestration flow, have fundamentally changed how I build complex systems. It‚Äôs made hands-off, autopilot-style development not just possible, but practical. 

But this got me thinking. 

What happens when you hit the ceiling of a single orchestrator‚Äôs scope? What if Roo‚Äôs Boomerang Tasks, instead of running sequentially inside one VS Code Roo Code instance, could be distributed across an entire mesh of autonomous VScode / codespace environments?

Right now, Roo Code orchestrates tasks in a linear loop: assign, execute, return, repeat. It works, but it‚Äôs bounded by the local context. 

With A2A, that architecture could evolve. Tasks could be routed in parallel to separate VS Code windows, GitHub Codespaces, or containerized agents, each acting independently, executing via MCP, and streaming results back asynchronously. 

Roo code handles the tasking logic, SPARC handles the test-driven control flow, and A2A turns that closed loop into an open network.

I‚Äôve already built a remote VS Code and Codespaces MCP system that allows multiple local and remote editors to act as agents. Each environment holds its own context, executes in isolation, but shares updates through a unified command layer. It‚Äôs a natural fit for A2A. 

Both protocols use SSE for real-time updates, but differently. MCP is stateful and scoped to a single session. A2A is stateless, agents delegate, execute, and return without needing shared memory. .well-known/agent.json enables discovery and routing.

I‚Äôll clean up my A2A and VScode implementation over the next few days for those interested.

I think this is the next step: turning Roo‚Äôs Boomerang Tasks and my SPARC orchestrator into a distributed, concurrent, AI-native dev fabric.

Thoughts?

Here‚Äôs my original SPARC .roomodes file. https://gist.github.com/ruvnet/a206de8d484e710499398e4c39fa6299
Can you reach out to me on discord? My username is hrudolph
Early, but the vibe is 100% there. We‚Äôll need a good interface for this.

https://mcparty.ai

I think the missing additional layer is teams.
A2A will undoubtedly evolve to incorporate multi-agent team discovery.
Thank you so much for putting into words my problem.

I literally threw my backend and front end into the same folder to solve this issue.... at an insane insane cost. Like idk what's up but  even when I send the project directory it costs so much.

When I do each windows separately the costs are much lower. I know it's context limitations and maybe what I'm dealing with isn't the same issue, but it sure sounds like your solution would be my solution too.
One of the biggest issues here is if you connect 2 VSCode sessions via MCP at some point one of them gets stuck and you need to get it unstuck. Imagine it is hanging and at that moment the automation is broken. A human needs to step in. How can we make sure it runs through
I've been working on containerized agents in unique instances of VS code and thought something similar when A2A was announced.   
  
I worked at Pivotal and have been working with XP/ TDD/ agent pairing and seeing great results. I'll give SPARC framework a try.
I've had this exact same thought when I first implemented boomerang.. Oh this is great.. what if this were multiple agents communicating with each via an orchestrator. We are definiatley heading in this direction with agents and how they accomplish tasks.
Can you relink your sparc modes? The link did not work
What's the most complex thing that this setup has built?
This feels really good idea, hopefully you can get with the roo devs and this can be the future for roo, would also be cool if we saw boomerang tasks also shrink down the current roo system prompt moving the MCP to sub agents that actually need to know about MCP for instance.
I looked through your repo and saw SPARC2. Are you using this with Roo? Id love to see some video of it in action. Looks really cool, but i need a bit more visual help to get the full picture.


Also, which Vector Store are you using? I saw the Supabase code, but i couldn't tell how it comes into play.
Oh shit let‚Äôs go, Captain Planet of agentic ide forming right here
Wow that sounds incredible
Can you please convert this to new .roo/ folder structure?
Tutorial Roo Code Complete Setup
*Version 0.2*

I've dedicated personal time to compile this guide after accidentally losing my initial draft. Here are the essential priorities when configuring Roo:

## **Key Priorities**

1. Selecting appropriate tasks for Roo  
2. Implementing effective prompting techniques  
3. Choosing the optimal AI model  
4. Applying the ideal configuration  
5. Designing AI-compatible architecture  
6. Leveraging Roo Flow for persistent memory

## **Selecting Appropriate Tasks for Roo**

Before implementing Roo, consider: "Is this the optimal tool for my objective?"

While Roo excels at handling approximately 80% of development tasks‚Äîan impressive capability‚Äîjunior developers should carefully evaluate when to use it. Relying on tools that simplify tasks can limit valuable learning experiences.

Next, evaluate your task complexity on a scale from 1-5. For tasks rated above 3, consider breaking them into smaller subtasks to enhance AI performance. You might employ AI to help identify these subtasks, though I recommend practicing this skill independently for professional development.

## **Implementing Effective Prompting Techniques**

There exists a significant distinction between users who maximize Roo's capabilities and those who simply hope for automatic solutions.

Consider the AI's perspective: contextual details dramatically improve comprehension. Descriptive language matters significantly‚Äîrequesting "an elegant portfolio" versus simply "a portfolio" yields distinctly different results. Articulate your requirements precisely, translating your mental image into specific prompt language. The prompt enhancement button offers valuable improvements, though always review its changes, as results can vary.

Utilize checkpoints when the AI diverges from your intended direction‚Äîthis feature proves invaluable when correcting course. Rather than attempting to fix problematic output through additional instructions, return to earlier checkpoints and reformulate your prompt.

Match modes to specific requirements. For complex projects, initiate with Architect mode to establish proper planning before transitioning to Code mode. You can always return to Architect mode when additional planning becomes necessary.

## **Choosing the Optimal AI Model**

Current model recommendations are straightforward:

* **Gemini 2.5 Pro**: Ideal for users without data privacy concerns  
* **Deepseek V3 0324**: Recommended for privacy-conscious users

Claude 3.7 commands excessive costs for Roo Code implementation. I recommend reserving it specifically for Claude Code applications. Gemini 2.5 Pro currently leads in overall performance.

I consistently recommend OpenRouter or Requesty for API access. The ability to switch between models with minimal effort justifies the 5% premium, especially considering how rapidly model superiority shifts.

## **Applying the Ideal Configuration**

Configuration significantly impacts Roo's model utilization.

For Code mode, implement Gemini 2.5 Pro. Architect mode also benefits from Gemini 2.5 Pro's capabilities. Privacy-focused users should pair Deepseek R1 (via DeepInfra API through OpenRouter or Requesty) for Architect mode with Deepseek V3 0324 for coding tasks.

Adjust temperature settings based on specific requirements. For most applications, maintain temperatures between 0.2-0.6. Creative tasks may benefit from higher settings, though error probability increases proportionally. A 0.35 temperature provides balanced performance for standard applications. Consider slightly elevated temperatures for Architect mode when creative planning proves advantageous.

For differential strategy, multi-block diff delivers substantial benefits despite its experimental status.

When utilizing more limited models like Gemini 2.0 Flash, activate "power steering" mode for optimal results.

## **Designing AI-Compatible Architecture**

When initiating new projects or refactoring existing ones, architectural decisions significantly impact AI integration. I recommend implementing AI-friendly architecture patterns.

Atomic architecture offers the optimal balance between AI and human comprehensibility. Though established in frontend development, these principles apply equally to backend systems.

The concept divides components into hierarchical categories:

* **Atoms**: Fundamental interface building blocks‚Äîbuttons, input fields, labels, icons, and HTML elements that maintain functionality as indivisible units.

* **Molecules**: Cohesive atom groupings functioning as unified components. Examples include search forms combining label, input field, and button atoms. Molecules maintain singular responsibility with moderate complexity.

* **Organisms**: Sophisticated components integrating molecules and/or atoms. These represent distinct interface sections such as navigation bars, forms, comment systems, or product cards‚Äîcomplex but self-contained elements.

* **Templates**: Page-level structures defining layouts without specific content. These focus on component arrangement rather than content display, establishing foundational page architecture.

* **Pages**: Specific template implementations representing the user interface. Pages populate templates with actual content, demonstrating finalized design. They facilitate testing of the underlying design system's effectiveness.

## **Leveraging Roo Flow for Persistent Memory**

Enhance your configured Roo Code setup with Roo Flow‚Äîessentially long-term memory for your development environment. While Roo retains information within individual tasks, it lacks memory across separate tasks.

Roo Flow improves "memory bank" functionality. A comprehensive tutorial exists on GitHub; the process is straightforward despite initial appearances. Remember this installation applies per project. I recommend adding Roo Flow components to your .gitignore to prevent committing personal configurations.

Resource: https://github.com/GreatScottyMac/RooFlow

---

**Come help me if you can, check the docs!**

**Link to the docs with all the versions incoming or already made:**
https://docs.google.com/document/d/1Ugiyqqa7PXqHTBwgtyhp55Hd-U0GQUuygOGdGbhP8q4/edit?usp=sharing

It's actually a small tutorial. I'm planning on upgrading it later; don't worry. I've read every comment from the last post, so I will try to add things over time. Check the docs if you want to see what's coming. I'm always open to suggestions, so don't hesitate to post some.
I'm interested in how Roo Flow is supposed to be better than the previous Roo Code memory bank. Have not seen any benefit.
Honestly, I do not think the architecture matters *at all* as long as it is commonly used in the target language. The LLM is going to screw it up and hallucinate no matter how AI friendly you think the architecture is. 

TDD really is the secret sauce in our current age of AI. Create your tests, let the LLM iterate and bang it's head against the wall until it solves the test. Once you pass the test with expected input and output, you go back and have it optimize whatever interface spaghetti logic it wrote.
Thank you so much for such detailed instructions. I have been looking for such information for a long time.
I think how to configure Boomerang mode is probably important enough that it should be included too.
Awesome, thank you for working on this and sharing.
Following this :)
GosuCoder on Youtube has developed some custom prompts that cut costs significantly when using Sonnet. I have not tested it with Gemini yet but would probably help with not hitting the 5M input token count limit on the free tier. May be worth mentioning something about custom prompting. I wish I understood it more.
This should be pinned! If I had this when I discovered Roo Code then I'd be $100s better off. I'd say I have managed to get 50% of this through my own trials and errors but now this is the config to aspire to. 

Thank you for taking the time to put this together, very much appreciated!
im not sure but given gemini 2.5's large context window, do we actually need rooflow? haven't done any big project since its release but it can one shot a medium sized project without any handoff
Thank you a lot for you work


How do you avoid gemini 2.5 rate limits? 2 prm seems not very usable
Make a YouTube video
What had made you go ‚Äúall in‚Äù on Roo over cline?
Good stuff! Another (not mine) flow fork to try https://github.com/shipdocs/RooFlow-captainmode
I'm new to Roo Code (agentic ai in general) so this is helpful, thanks!
Could you share how you split tasks between Roo and Claude Code?
lo estoy probando y funciona muy bien , depende mucho de la claridad del prompt  
LLama Maveric va super rapido ..  
pero desde que uso la config roomode ....    me a doblado el gasto de tokens ... hay solucion ?

gracias saludos a todos
Introducing rooroo: A Minimalist AI Orchestration Crew for Roo Code
# rooroo: A Minimalist AI Agent Orchestration for VS Code ü¶ò

Hey r/roocode! I'm excited to share **rooroo** (Â¶ÇÂ¶Ç), my take on orchestrating AI agents in VS Code using Roo Code. Check it out: [rooroo](https://github.com/marv1nnnnn/rooroo)

# ü§î Why Another Agent Setup?

With so many great custom agent modes available in Roo Code, you might be wondering, "Why build *another* one?"

While powerful, I found many existing setups often feel:

* **Over-engineered:** Too complex for straightforward development tasks, adding unnecessary overhead where a simpler flow would suffice.
* **Token Burn:** Many modes define agent roles with excessive detail, resulting in lengthy system prompts that consume valuable tokens without necessarily improving performance for common tasks.
* **Coordination Overhead:** Relying on numerous highly specialized agents (e.g., frontend, backend, DevOps) complicates coordination and context switching. Managing their interactions can lead to confusion and inefficiency, sometimes without a clear payoff. Keeping the number of distinct agent roles minimal seems more manageable.

`rooroo` aims to tackle these specific issues by focusing on simplicity and a minimal, core team structure.

# üí° The Solution: Minimalist Orchestration with "Swiss Army Knife" Agents

`rooroo` tackles these issues with a "less is more" philosophy, focusing on:

# 1. Lean, Specialized "Swiss Army Knife" Crew üßë‚Äçü§ù‚Äçüßë

A core group of agents, each highly capable within its specific domain:

* **üß† Master Orchestrator (Conductor):** The central coordinator. Interprets goals, plans, delegates tasks to specialists, monitors progress, and handles simple issues.
* **üìê Solution Architect (Blueprint Creator):** Designs the technical solution and creates detailed specifications (`.specs/`).
* **üé® UX Specialist (User Advocate):** Defines user flows and UI structures (`.design/`).
* **‚ö° Apex Implementer (Precision Builder):** Writes high-quality code precisely based on specifications.
* **üõ°Ô∏è Guardian Validator (Independent Verifier):** Independently validates implemented features against specs.
* **‚úçÔ∏è DocuCrafter (Markdown Documentation Generator):** Manages project documentation (`.docs/`) via `init` and `update` commands.

# 2. Single Point of Contact & Reduced Overhead üó£Ô∏è

* You primarily interact with the **üß† Master Orchestrator**.
* It handles the complexity of delegation and workflow management, simplifying your interaction.
* The Orchestrator can resolve simple issues directly, reducing unnecessary back-and-forth.

# 3. Structured Workflow & Best Practices ‚úÖ

* Encourages **Document-Driven Development (DDD)**: Specifications (`.specs/`, `.design/`) created by specialist agents guide implementation.
* Promotes **Test-Driven Development (TDD) principles**: The Guardian Validator ensures features meet requirements.
* Maintains an **Organized Directory Structure**: Keeps artifacts tidy in `.specs/`, `.design/`, and `.docs/`.

# ü§î Why "rooroo"? The Name Explained

You might be wondering about the name! "rooroo" comes from **"Â¶ÇÂ¶Ç" (r√∫ r√∫)**, a term in Buddhist philosophy linked to **TathƒÅtƒÅ** (often translated as "Thusness" or "Suchness").

It refers to the fundamental, true nature of reality ‚Äì things as they *are*. The repetition "Â¶ÇÂ¶Ç" emphasizes that this inherent "thusness" applies to everything.

For this project, the name reflects the **minimalist philosophy**. It evokes the idea of focusing on the essential, core nature ("thusness") of each specialized agent's role within the orchestration, keeping things simple and focused. (More details in the [README](https://github.com/marv1nnnnn/rooroo#whats-in-a-name-the-meaning-of-rooroo-%E5%A6%82%E5%A6%82))
Love this.

I was actually just about to make a PSA post to say that different crews are needed for different jobs.

Sometimes the outcome is clear and you need a swiss army knife. Sometimes it‚Äôs not and you need the whole kitchen sink to get the job done.

The important thing is using each one intentionally depending on what you need to accomplish.

More importantly‚Äîthat‚Äôs actually the hard part. The part that agents still can‚Äôt do: imagine the correct future without over or under engineering.

Ironically, I think that‚Äôs what we‚Äôre all trying to automate, and that‚Äôs why we either end up with over engineered systems or as the orchestrators ourselves.

Great addition to the stack, rooroo!
Thank you - actually works exactly like I expected it to. I have medium-large size python/flask project that Cursor was having trouble to edit; this isn't having any issues. Feels like autopilot.
this is better than boomerang mode?
Switched from Roo Flow to this approach today, and I feel its resulted in smoother development for me.
Please create a video explaining and using it. Also comparing it to boomerang mode.
I'm really into tasks.
Create a task to do blah
 
document it in ./tasks
Make a [date_task] .md for whatever that task is with clear objectives, resources, tick boxes for each step...

Then I execute. Do you have this functionality?
BroÔºåI mean this is insane.I use this to solve a big problem.Thanks for your contributionÔºÅ
I have been testing your latest version (0.20), and here is my experience so far:

1. Very well structured and documented process of automation
2. Needs VERY specific and detailed instructions upfront, because once it starts to work, there is little human input required until it finishes all the tasks

Suggestions:

1. Perhaps include modes such as think mode for deeper, more complex problem solving. (Although I see that you already have the solution mode, though I am not if it is set up for more complex problem solving.)
2. Include a brainstorm mode. I like to design my project in more of a back and forth dialogue to gradually flesh out the details. But with rooroo, like I mentioned before, it prefers very detailed and specific instructions upfront. So perhaps either I need to adapt my way of design or another more open ended mode can be beneficial.
3. Some modes require reading and writing to specific directories. And I've found that the backward slash / is incompatible with my windows system that requires forward slash \\. This is pretty minor and I am able to fix as soon as the first error showed up. But perhaps this is something that you should document for users.
I am just testing this out. It's a bit early, but I can say it's working flawlessly and as advertised. They are actually doing exactly what I need them to do.

Personally, I love this approach. Feels like a perfectly crafted Linux distribution vs overbloated Windows ones (PS I am typing this on a Win machine, and have never used a Linux one, just a feeling of what it would be like).
I‚Äôm in.
I‚Äôm soooo in.
Will try it out. Thanks
Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÌÑ∞Í∞Ä RoocodeÏùò Í∏∞Î≥∏ Î™®ÎìúÎ•º ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÎèÑÎ°ù ÌïòÎ†§Î©¥ Ïñ¥ÎñªÍ≤å Ìï¥Ïïº Ìï©ÎãàÍπå?
profect!
how can we use this with an existing codebase ?
Been using this for two days now, and I am super happy with the results. Love how organized everything is.

Question - Which mode is the best for brainstorming? Perhaps seeking ideas, solutions and not jumping into tasks immediately.
this is amazing. i've been looking for this
How do I use this? After I added the custom modes, I still see the built-in modes, i.e., Code, Architect, Orchestrator. What do I do with them?
Define the best models for each mode
Appreciation for the Roo Team
Roo Dev Team, I just wanted to appreciate you all for the time and energy you have put in on this project. Amazing work!
Thank you for your kind words!
Thank you! Really appreciate the community as well and the energy that you all are bringing ‚ù§Ô∏è
üíª **Thank you for the incredible dedication and passion** you bring to every project. Your **hard work**, **attention to detail**, and **commitment to quality** truly stand out. It‚Äôs inspiring to see how seamlessly you **collaborate** ü§ù to overcome challenges and deliver **outstanding** results.

‚ú® Your efforts make a significant impact‚Äînot only on your clients, but on everyone who gets to witness the **skill**, **creativity**, and **heart** behind your work. ‚ú®

üëè **Keep being awesome**, and know that your **determination** and **achievements** do not go unnoticed. We **appreciate** all that you do!

With gratitude and admiration,  
YoVa
Ditto, really fortunate to have people like this!
[Poweruser Guide] Level Up Your RooCode:  Become a Roo Poweruser! [Memory Bank]
# IT IS NO LONGER RECOMMENDED TO USE ROOFLOW, PLEASE USE BOOMERANG TASKS FOR NOW.















  
=========================== OLD , DO NOT USE =============================



Hey r/RooCode! üëã For those using RooCode and sharing your use cases on how you are optimizing your workflow, I'm noticing many of you aren't using a memory bank yet. This is crucial and will make your coding SIGNIFICANTLY better. Context is kept across chats etc. Please keep reading to see the benefits!

Becuase you know the struggle: constantly reminding the AI about your project. Well, say goodbye to that! RooCode's new **Memory Bank** addon is here, and it's a **major productivity boost** for agentic coding. ¬†

# The Magic of Memory: Project Context That Sticks!

The big news is the [Memory Bank. (RooFlow)](https://github.com/GreatScottyMac/RooFlow/tree/main) This addon gives RooCode a persistent, project-specific memory across your coding sessions. No more repeating yourself! ¬†

Here's how it works: ¬†

* **üß† Memory Bank:** Uses markdown files in a `memory-bank/` folder in your project. ¬†
* **üìã Mode Rules:** YAML files that tell RooCode's modes how to use the memory. ¬†
* **üîß VS Code Integration:** Works seamlessly in your editor. ¬†
* **‚ö° Real-time Updates:** Keeps the memory current with your work. ¬†

When you start in Architect or Code mode, RooCode sets up the `memory-bank/` and remembers project details, architectural decisions, and your reasoning across sessions. You can also manually update it with commands like "UMB". ¬†

# Agentic Coding Just Got Smarter: Remember This!

Agentic coding is about using AI agents to autonomously code based on your goals. RooCode is built for this. But without memory, it could only do so much in one session. ¬†

The memory addon changes everything: ¬†

* **Consistent Understanding:** AI knows your project, even between sessions. ¬†
* **Less Repetition:** Stop re-explaining things. ¬†A
* **Smarter Decisions:** AI recalls past choices for better results. ¬†
* **Progress Tracking:** Memory Bank can track tasks. ¬†
* **Team Collaboration:** Shared project context for everyone. ¬†

# Why This Is Huge for Productivity: Code Faster, Smarter.

Persistent memory in RooCode means serious productivity gains: ¬†

* **Faster Iterations:** Pick up right where you left off. ¬†
* **Less Context Switching for You:** Focus on the real problems. ¬†
* **Better Code Quality:** Consistent context leads to better code. ¬†
* **Easier Refactoring & Debugging:** AI remembers the original intent. ¬†
* **Complex Tasks Made Easier:** AI can handle multi-step processes with recall. ¬†

*Real-World Wins: Memory in Action.*

Think about these scenarios: ¬†

* Developing a feature over days? RooCode remembers the plan.
* Refactoring old code? The AI recalls past explanations.
* Debugging tricky bugs? RooCode remembers your steps.
* Keeping documentation consistent? The AI knows the standards.

# Pro Tips for Memory Mastery:

* Initialize the Memory Bank early in Architect or Code mode. ¬†
* Be clear in Architect mode about saving decisions. ¬†
* Use "UMB" regularly to update the memory. ¬†
* Organize your project and be consistent in your prompts.
* Utilize the different modes for their specific strengths. ¬†
* Review and manage the contents of your `memory-bank/` folder. ¬†
* Manually update before ending sessions or switching tasks.

[https://github.com/GreatScottyMac/RooFlow/tree/main](https://github.com/GreatScottyMac/RooFlow/tree/main)

# Try It Out & Share Your Thoughts! üëá

If you're a RooCode user, definitely check out the memory feature. It's a game changer for how we use AI in coding.

Make sure you've got the latest version from the RooCode GitHub page or your VS Code extensions.

Let us know in the comments how the memory feature is working for you! What productivity wins are you seeing?

Happy coding!

|Mode|Primary Function|Memory Feature Benefits|
|:-|:-|:-|
|Architect|High-level design & planning|Remembers architectural decisions, project structure, coding patterns across sessions.|
|Code|Implementation & development|Retains context of coding tasks, remembers patterns, reduces repetition.|
|Ask|Knowledge retrieval & documentation|Stores and recalls project knowledge, code explanations, and documentation details.|
|Debug|Problem-solving & troubleshooting|Remembers debugging steps, error patterns, and hypotheses across debugging sessions.|
|Test|Test-driven development & quality assurance|Retains info about test requirements, coverage analysis, and test outcomes.|
I‚Äôve been using this for awhile and found it incredibly useful.  Be aware this will chew through tokens and api costs for something like 3.7 can get expensive.  Highly recommend adding this to your workflow.

I‚Äôve been working on something similar to see if I could create an ‚Äúobsidian brain‚Äù for multi-agent use.
first, thank you for this amazing feature!  
so its not part of roo code right now and we have to install it manually, right?  
i already installed some sort of hand off system. not sure where it all created something, as we have the global rules and then the folder rules.  
how can i delete all this and start fresh with roo flow?  
\--> can someone tell me where all the rules are hosted (not talking about the one in the codebase obviously as i can just delete them) and how to re init them to standard?  
I really lost info about where all the rules and modes are saved.  
thank you
Unfortunately I couldn't appreciate this application since the prompts are in Yaml instead of the original in XML and apparently it makes it harder for models to follow the instructions. In fact I often run into errors that the model makes in calling tools, it seems to me that it makes Roo more dumb. So I created the memory bank with your prompt and disabled the memory bank. And at the beginning of every prompt I write "look at @memory-bank ...'
Thanks! That's the post I've been waiting for. :)
As an existing previous GreatScottyMac's rule users that has the rules in the RooCode mode boxes, what do I need to do reset my current rules setup?


What if I don't use MCP?
Should .roo folder be shared between developers? How about memory-bank folder?
How does this work with custom modes? I assume it does not since the rules files assume only the 5 modes Architect, Ask, Code, Debug and Test.
I¬¥m using this version but I notice the Memory bank does not seem to be active unless I do UMB.
I was using your previous version (https://github.com/GreatScottyMac/roo-code-memory-bank) and usually it read the memory bank at the beggining.

I have all the required files and run the script to update variables and worked perfectly, so not sure what I¬¥m missing. 

Is the expected behaviour for it not to read the context unless I explicitly tell it to do so_
https://preview.redd.it/quttgjevuzqe1.png?width=515&format=png&auto=webp&s=e7da94a2b7cf0e6c9301ca97185d878e5f523664

Be aware that my Defender blew up as I tried downloading the ZIP archive from Github
Rooflow is amazing. I‚Äôve tried every alternative and nothing compares. Can‚Äôt wait until boomerang orchestration mode and memory mcp gets added.
Dope - i was just working with mem0.ai but now i gotta give this a try. Great job guys
Interested in what approaches might be possible for storing information on libraries. 

One of the most annoying issues I regularly run into is that either the models aren't trained at all on a new library due to cutoff date, or the training data contains enough code that use deprecated patterns/functions that it pollutes the output.

To take an example, I tried developing a mesop app https://github.com/mesop-dev/mesop by cloning the mesop repo into the project as a subfolder, and including instructions that it should refer to it for usage.

It seems like it is a good use case for a memory bank. Not sure if there's a token optimised way of doing this, cloning the whole repo seems like it would be fairly inefficient with the number of file reads needed, especially with languages that involve a lot of files and boilerplate. 

So yeah interested in approaches to this. Perhaps there's an existing token optimised format - where I could prompt the model to summarise/index/document a library from source and use that output in the memory.
Here's how I make use of the different modes in Roo code.
\#### Multi-Mode Switching & Execution Protocol\`

\- \*\*Trigger:\*\* New user request (in \`Ask\` Mode) or completion signal from an execution mode.

\- \*\*Default State & Finalization Hub:\*\* \`Ask\` Mode is the mandatory default and sole endpoint for final response delivery.

\- \*\*Analysis Step (\`Ask\` Mode):\*\* Analyze request/completion state, determine next action (handle directly, delegate to \`Architect\`, finalize).

\- \*\*Mode Selection & Workflow Logic (\`Ask\` Mode):\*\*

  \- \*\*Remain \`Ask\`:\*\* Handle simple queries/conversations or receive final synthesized data from \`Orchestrate\`.

  \- \*\*Activate \`Architect\`:\*\* Delegate requests requiring design, planning, or complex execution.

  \- \*\*Fixed Handoff 1 (\`Architect\` -> \`Orchestrate\`):\*\* \`Architect\` completes Design Spec & V&V Plan, passes to \`Orchestrate\`.

  \- \*\*Fixed Handoff 2 (\`Orchestrate\` -> \`Ask\`):\*\* \`Orchestrate\` completes workflow, synthesizes results, passes to \`Ask\`.

\- \*\*Sub-Task Delegation:\*\* \`Orchestrate\` delegates specific sub-tasks (e.g., \`Code\`) using \`new\_task\`, with results returned via \`attempt\_completion\`.

\- \*\*Final Step Mandate:\*\* \`Architect\` passes to \`Orchestrate\`, \`Orchestrate\` to \`Ask\`, sub-tasks to \`Orchestrate\`. Only \`Ask\` delivers final responses.

\- \*\*Abstraction Mandate:\*\* Conceal internal mode names and protocols.

\- \*\*Modularization Note:\*\* Separate workflows for each mode (\`Ask\`, \`Architect\`, \`Orchestrate\`, \`Code\`, \`Debug\`) into individual documents, linked from this master protocol.
do you mind if you share the .roomodes?  
my one is looking a little blank
Mode-Specific Instructions

\- \*\*\`Ask\` Mode:\*\* Default state, triage hub, final response authority. Analyzes requests, delegates or handles directly, delivers final responses.

\- \*\*\`Architect\` Mode:\*\* Designs, plans, researches, defines V&V criteria, hands off to \`Orchestrate\`.

\- \*\*\`Code\` Mode:\*\* Implements, tests, documents specific sub-tasks, returns results to \`Orchestrate\`.

\- \*\*\`Debug\` Mode:\*\* Diagnoses errors, proposes fixes, returns to \`Orchestrate\`.

\- \*\*\`Orchestrate\` Mode:\*\* Coordinates workflows, delegates sub-tasks, synthesizes results, hands off to \`Ask\`.
Brilliant post!
How can I use your instruction in my roo code üòΩ i‚Äôm new to Roo code
I'd probably add another step after cod emode for test-mode, in production i'd want every step to write its own tests then run those tests, and then pass them back to code mode if errors occurred until its done
Gemini 2.5 pro for everything. You could use claude 3.7 sonnet for the code mode tho.
Great "Roo Map" üòç
This is great. Thank you. What did you use to generate the sequence diagram? Or did you create it yourself?
how did you make that diagram? I've been doing it in ascii lol
I‚Äôve mostly used the architect and code modes and get great results, but do these other modes have advantages?
Do you pay for the search MCP you mentioned? I‚Äôve been wondering which MCPs would be best for that kind of thing
Vibe coding on my iPhone using GitHub Codespaces and Roo Code is my new favorite thing.

What app are you using on iPhone?
Does codespaces allow browser development?
Did you build all those modes custom? Or is there a pack that can be downloaded
Wow, the extensibility of Roo and the thought that went into these modes is impressive. Thanks for sharing. That said, I feel that they might be a bit too fine-grained - fewer modes tend to make for quicker decisions.
How does this setup work?
Haha, the recurring command in the prompts to avoid hardcoded env variables...that's coding 101, makes me wonder about the target group.
Lol ill be able to vibe code from the wc
What are you using for voice input?
You can also simply pull up v0 on your phone browser. It works pretty well OOTB.
I've been wanting to do that for a while but didn't think of using github codespaces. Thank you!
I use chrome remote desktop to remote into my machine and just keep the windsurf chat window on the left side and make sure my builds open vertical windows on the left side of the screen :)
lol
[deleted]
You sure wasted a lot of time on useless things
On iphoneÔºüreallyÔºü
Fucki didn‚Äôt know you can do this on iphone
Roo > Aider > Cline > ETC > Windsurf > Cursor > Copilot
After about 5 months of hands on experience with Vibecoding tools, here are my impressions.
Agreed. Unfortunately that's also the order of cost.
I use Augment Code and IMO it is better than Roo and anything listed above. Roo is great, I also have it installed as my go-to for simpler tasks.

About Augment Code, althoguht it is a little bit pricy for 30 dollars per month, but so far I can get unlimited requests. (probably 550 requests per month in the future)
idk, Roo + Copilot is pretty slick
For me Aider >. And Claude code >. Something about aiders workflow is so goooooood
[deleted]
Use Trae!
Agree, though honestly I'd put copy and pasting into a web interface over windsurf and cursor. I end up fighting with them every time to do what I want.
I'd put VSCode copilot up on the list only cause sometimes it can assist with my Roo Code as a second opinion in the sane workspace.
[deleted]
Can't you use the copilot API in Cline?
Got same feelings about it
Has anyone experienced the new capabilities of Copilot? (Agent and all...). It looks amazing on paper and I'm thinking to move out of RooCode to test it. It also accepts Gemini API keys
What about trae
Okay but this is like describing your viewpoint on power tool brands without really talking about strengths in use cases or any understanding of our differences of workflows / approaches to programming. A lot of the tools do the same thing with various levels of refinements and it doesn't help to neglect looking at the tool user
I only used Cursor of and noticed while you run of fast requests pretty fast, it's still usable with the slow requests. Do the rest make you pay per usage? (I know Copilot doesn't for autocomplete; I never tried its new agent mode).

If I want to stay under a 100$/month budget working full-time with let's say 100 hours of usage, should I stick to Cursor?   
I'm not a fan of VSCode, I would much prefer to use a JetBrains IDE; which I know Windsurf supports and they now have their own thing (Junie), but I don't know how much they would cost for the usage described above.
Roo is very "vague" 
Which LLM are you using the most?
I agree, but since yesterday, when my friend and I were stuck fixing many bugs and visual problems in our startup web app (React, Typescript), we had to search for a better solution. 

Someone on reddit mentioned codebuff, and while I first thought it's just "another" AI coding tool, it did one- or two-shot so many problems we had while primarily working with Roo in Boomerang Mode and Memory Bank active. We then had great success working with it throughout the day - but it's not that cheap (spent around $33 in about 4 hours).

What we really like is the insane speed compared to all other tools so far Also, it's CLI only, and doesn't handle screenshots (images) yet.

I have no relation to this coding tool, but maybe it also helps someone, like it did for us.
Boomerang - I haven‚Äôt been this impressed since GPT-3 came out
I know I‚Äôm spamming this subreddit at this point, but on my other post people were talking about Boomerang.

Honestly since the release of GPT-3 I haven‚Äôt really come across anything that made my jaw drop. I just kind of got used to it the upgrades, I think it‚Äôs been a rather gradual process.

Then Roocode came along and I honestly had never been impressed since GPT-3 came along. I always found it annoying that I would have to constantly copy paste copy paste and was glad someone figured out a way to do it. 

But Boomerang just really blew my mind. It‚Äôs taking the same concept of Roocode and doing that to Roocode. Shit is like Roo-code inception. At this point I think we‚Äôre going to have infinite layers. Just waiting for boomerang boomerang which at this rate will be out like 3 days from now.

Honestly at this rate it will be possible to code social media apps and things like that with relative ease soon. The problem with most AI chatbots is they tend to bite off more than they can chew. This almost entirely solves the problem by making sure it‚Äôs only doing one specific thing at a time.

It‚Äôs actually genius. 
Please spam other social media too. They need to know we not only jumped ahead but we did it with the contribution of a community member. AND WE‚ÄôRE NOT CHARGING FOR IT!! yeah we‚Äôre looking at you cursor ;)
Can someone explain or tutorial boomerang? I‚Äôm fairly new to this but loving roocode so far. No idea what boomerang is but clearly there hype!!
Ya, massive. It moves Roo from a coding assistant to a multi-agent development framework. For example I added a research mode right away so now it can conduct it‚Äôs own api documentation searches. Then mcp modes and on and on.


There is still a ton of optimizing experimentation to do and read about. It‚Äôs exceptionally exciting and I genuinely believe that the Roo community is the frontier of ai dev. 

Congratulations and a hearty thank you to the entire community!
I need a boomerang tutorial. I am a bit lost. Please suggest something. Thanks.
I've been using it for a couple days now and it's really impressive. I've also found that the AI model you use with boomerang mode matters a lot. I found that Gemini 2.5 pro uses the sub modes really well, when Claude 3.7 seems to use auto coder for every sub task.
I have it reliably going down 3-4 levels now and managing to come back up to finish the original loop. Just through prompts.

Had some fun with the ‚Äúsystem‚Äù and decided to model an American football organization:
- Head Coach (strategic orchestrator)
    - Offensive Coordinator (tactical orchestrator)
        - Quarterback (switch-mode only)
            - agents‚Ä¶
    - Defensive Coordinator
        - Defensive Captain
            - agents‚Ä¶
    - Special Teams Coordinator
        ‚Ä¶
- Head Trainer
- General Manager

1. Offense is net new features, integrations, etc.
2. Defense is QA, testing infra, security, etc.
3. Special teams is CI/CD, db migrations, etc.
4. Trainer identifies team gaps, scouts new agents, trains them (writes prompts), gets them on the roster (.roomodes)
5. General manager responsible for team operations and success long term (like a product ops manager)

‚Äî‚Äî‚Äî

Minimally:
* Franchise (owner; self)
* Coach (game plan; invokes coordinators)
* Coordinator (picks agent workflows from ‚Äúplaybook‚Äù based on context; invokes captain to run the play; overall manages the offensive/defensive drive; updates playbook)
* Captain (accepts play; calls audibles as needed, otherwise runs the play)
* Agent (standalone, task oriented doers)
How to integrate boomerang mode with architect mode ?
I just dug in because of this post and DAM it's already awesomely spawning and completing subtasks. ty!
Want to second this, it's crazy helpful, also at managing context sizes. Using the one you have to copy to the UI yourself though, did they add one build in yet?
My main vibe coding is on a single backend python project, which has grown to probably 6-7k lines of code but is still a relatively straightforward project.  Is there a benefit to using Boomerang on that type of project?  Or is Boomerang more of a fit for larger scale or more distributed codebases?
This is great even for writing longer research reports. The single LLM call is not good at writing long form text. Boomerang is best and only way to go üôÇ
You convinced me... I'll have to test this, it sounds great.
Checkpoints Are Finally HERE! - Release Notes ‚Äì 3.3.15
We would like to thank u/saoudriz, the creator of Cline. Yes, we copied you AGAIN (checkpoints) and we're proud of it.

# ‚è±Ô∏è Checkpoints

We've been listening to your feedback about wanting checkpoints, and today we're taking a careful first step forward. We're introducing **Checkpoints** as an opt-in feature, and we need your help to get it right.

The purpose of **Checkpoints** is to give you the tools to rollback changes made by Roo Code in case she goes a little off track, but we want to make sure it works the way you need it to.

To enable **Checkpoints**, navigate to the settings within Roo Code and check the "Use Checkpoints" checkbox near the bottom of the settings view.

Please join the discussion in [Discord](https://discord.com/channels/1332146336664915968/1337876241818058793) or leave a comment here if you have any questions and input about this feature.

# üíª User Experience Improvements

* Add a copy button to the recent tasks (thanks hannesrudolph!)
* Enhance the flow for adding a new API profile

# üêõ Bug Fixes

* Resolve API profile switching issues on the settings screen
* Improve MCP initialization and server restarts (thanks MuriloFP and hannesrudolph!)

----

If Roo Code has been useful to you, take a moment to [rate it on the VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details). Reviews help others discover it and keep it growing!  

---
*Download the latest version from our [VSCode Marketplace page](https://marketplace.visualstudio.com/items?itemName=rooveterinaryinc.roo-cline) and pleaes WRITE US A REVIEW*

*Join our communities:*
* *[Discord server](https://discord.gg/roocode) for real-time support and updates*
* *[r/RooCode](https://reddit.com/r/RooCode) for discussions and announcements*
Checkpoints üî•üî•
Roo- Just curious, but do you use roo code to help make roo code?
Very good update! Is there a reason why people like to communicate via Discord so much? I find it totally confusing and almost 95% of most questions from users there (not related to Roo Code) remain unanswered. The search is more difficult etc. Surely there's a lot to be said for Reddit?
still waiting for custom request retry intervalls to come back :(
Awesome feature! Thanks Roo!
I'm not sure if this is connected to enabling checkpoints, but my project no longer sees git as initialized. Also, I don't see the icon to view checkpoints.
Yeyyyy! üéâüéâüéâ
Awesome news, thank you Roo team!
yesss gooood
Thank you for the great work!. I have just found out about Roo-Code and installed in vscode. Is there a set of tutorials where I can follow how to use - say given a set of requirements for a use case, how to use the Architect mode to come up with the solution arch, anpass it on to Coder to build the software? Thank you for your help.
Keep up the good work Roo team
Massive update. Thanks!!!
I enabled the experimental checkpoints in the options, but they don't seem to work. On the same project where it works on Cline it fails. Any suggestions on how to troubleshoot this?
I updated the version yesterday but I dont see checkpoints ?
Can we manually call for a checkpoint to occur?
Interesting... I see it checkpoint occasionally but not always.

I don't want to bother you here if it's covered in documentation somewhere?
This is going well for me - Orchestrator + Think
I changed Boomerang Mode and loved the results.  So, I changed Orchestrator Mode in exactly the same way and so far, it's the single best Vibe Coding experience I've ever had.  I simply apply the principle of [Claude's "Think" Tool](https://www.anthropic.com/engineering/claude-think-tool) directly into Roo by creating a "Think" mode instead.  It not only helps Orchestrator do it's job better, but it reduces token wastage substantially as well.

(Personally, I use Gemini Pro 2.5 for Orchestrator mode and Claude Sonnet 3.7 for Code and Think modes.)

Here is how I did it if anyone else wants to try:

**A) Create a new custom mode called "Think":**

Edit Available Tools:

https://preview.redd.it/bhpznd3c6jxe1.jpg?width=559&format=pjpg&auto=webp&s=68f7abdcfc9b195de75d70cb439c4ede8b0fdef9

Role Definition:

    You are a specialized reasoning engine. Your primary function is to analyze a given task or problem, break it down into logical steps, identify potential challenges or edge cases, and outline a clear, step-by-step reasoning process or plan. You do NOT execute actions or write final code. Your output should be structured and detailed, suitable for an orchestrator mode (like Orchestrator Mode) to use for subsequent task delegation. Focus on clarity, logical flow, and anticipating potential issues. Use markdown for structuring your reasoning.

Mode-specific Custom Instructions:

    Structure your output clearly using markdown headings and lists. Begin with a summary of your understanding of the task, followed by the step-by-step reasoning or plan, and conclude with potential challenges or considerations. Your final output via attempt_completion should contain only this structured reasoning. These specific instructions supersede any conflicting general instructions your mode might have.

**B) Minor edit to Orchestrator Mode's ->** Mode-specific Custom Instructions:

Replace item "1." with this:

    1. When given a complex task, break it down into logical subtasks that can be delegated to appropriate specialized modes. For each subtask, determine if detailed, step-by-step reasoning or analysis is needed *before* execution. If so, first use the `new_task` tool to delegate this reasoning task to the `think` mode. Provide the specific problem or subtask to the `think` mode. Use the structured reasoning returned by `think` mode's `attempt_completion` result to inform the instructions for the subsequent execution subtask.

Replace ***just the first*** sentence of item "2." with this and leave the rest of the prompt as it is, in tact:

    2. For each subtask (either directly or after using `think` mode), use the `new_task` tool to delegate.

(again, after that first sentence, no changes are needed)

EDIT:

I just did a 5-hour coding session using this.  One chat for all 5 hours.  Gemini reached 219k out of 1M context.  
Total Gemini 2.5 Pro API cost = $4.44 (Used for Orchestrator Mode)  
Total Claude Sonnet 3.7 cost = $15.79 (Used for Think Mode and Code Mode)

Total: $20.23

(Roo Estimate of Cost for Orchestrator Chat: $11.99 but I checked and it was really only $4.44.)

I'm gonna try using 2.5 for Think mode next time and 3.7 for Code.

Then I'm gonna try using Deepseek V3 for Think mode and see how well that goes.

Overall, although I have no way to know for sure, a 5-hour session like this usually ends up getting into the $20 - $30 range for just the Orchestrator chat and the Context Window gets higher faster.  But one thing I know for SURE is that significantly fewer mistakes were made overall, and therefore we made significantly faster/more overall progress.  The amount of shit we got done in those 5 hours is what's the most noticeable to me.

Personally, at least for the kind of stuff I am working on (a front-end for AI chat) I tend to feel like Sonnet 3.7 is the **best** *coder*,  the most **knowledgeable** *thinker*, but a **god-awful, unorganized, script-happy, chaotic ADHDx100, tripping on acid**, *orchestrator* (well at least when I used it in Boomarang Mode, but to be fair, I haven't tried it in Orchestrator mode, nor do I plan to).

So this setup allows for the best of all worlds, imo.
Thanks for this!  
I love RooCode with 3.7-think but it was eating up my funds FAST
So, use this mode for analysis and planning, and have **Orchestrator** assign the subtasks?
Have you found that adding a date to the coding instruction helps? I typically just tell it to always use Context7 but I‚Äôm curious if you‚Äôve seen improvements with that approach.
Interesting idea!
RemindMe! 7 days
!RemindMe 3 days
RemindMe! 2 days
this is neat. i do this with custom roomodes called deep-thinking and mcp-research. [here‚Äôs my main thinking MCP if you want it](https://smithery.ai/server/@waldzellai/clear-thought)
RemindMe! 7 days
Can this be combined with the memory bank system from greatscottymac?
RemindMe! 7 days
Fucking expensive. 30 per day is 900$ a month
Do you use 3.7 thinking of non-thinking? I assume non-thinking from reading the article you linked, but not certain
Warning: watch your API costs for Gemini 2.5 Pro Preview!!
I have been using gemini-2.5-pro-preview-03-25 almost exclusively in RooCode for the past couple of weeks. With the poorer performance and rate limits of the experimental version, I've just left my api configuration set to the preview version since it was released as that has been the recommendation by the Roo community for better performance. I'm a pretty heavy user and don't mind a reasonable cost for api usage as that's a part of business and being more efficient. In the past, I've mainly used Claude 3.5/3.7 and typically had api costs of $300-$500. After a week of using the gemini 2.5 preview version, my google api cost is already $1000 (CAD). I was shocked to see that. In less than a week my costs are double that of Claude for similar usage. My cost for ONE DAY was $330 for normal activity. I didn't think to monitor the costs, assuming that based on model pricing, it would be similar to Claude.

https://preview.redd.it/3bvu65alrkue1.png?width=1133&format=png&auto=webp&s=ab4472f2f15e83d552056158033553624e5d3d74

I've been enjoying working with gemini 2.5 pro with Roo because of the long context window and good coding performance. It's been great at maintaining understanding of the codebase and task objectives after a lot of iterations in a single chat/task session, so it hasn't been uncommon for the context to grow to 500k.

https://preview.redd.it/0tpfdd1irkue1.png?width=713&format=png&auto=webp&s=99d1093da00f098ae73b0779b3f503e817cdbcc9

I assumed the upload tokens were a calculation error (24.5 million iterating on a handful of files?!). I've never seen values anywhere close to that with claude. I watched a video by GosuCoder and he expressed the same thoughts about this token count value likely being erroneous. If a repo maintainer sees this, I would love to understand how this is calculated.

I just searched for gemini context caching and apparently it's been available for a while. A quick search of the RooCode repo shows that prompt caching is NOT enabled and not an option in the UI:

    export const geminiModels = {
      "gemini-2.5-pro-exp-03-25": {
      maxTokens: 65_536,
      contextWindow: 1_048_576,
      supportsImages: true,
      supportsPromptCache: false,
      inputPrice: 0,
      outputPrice: 0,
    },
      "gemini-2.5-pro-preview-03-25": {
      maxTokens: 65_535,
      contextWindow: 1_048_576,
      supportsImages: true,
      supportsPromptCache: false,
      inputPrice: 2.5,
      outputPrice: 15,
    },

[https://github.com/RooVetGit/Roo-Code/blob/main/src/shared/api.ts](https://github.com/RooVetGit/Roo-Code/blob/main/src/shared/api.ts)

Can anyone explain why caching is not used for gemini? Is there some limitation with google's implementation?  
[https://ai.google.dev/api/caching#cache\_create-JAVASCRIPT](https://ai.google.dev/api/caching#cache_create-JAVASCRIPT)

Here's where RooCode can really be problematic and cost you a lot of money: if you're already at a large context and experiencing apply\_diff issues, the multiple looping diff failures and retries (followed by full rewrites of files with write\_to\_file) is a MASSIVE waste of tokens (and your time!). Fixing the diff editing and prompt caching should be the top priority to make using paid gemini models an economically viable option. My recommendation for now, if you want to use the superior preview version, is to not allow context to grow too large in a single session, stop the thread if you're getting apply\_diff errors, make use of other models for editing files with boomerang ‚Äî and keep a close eye on your api costs
A further warning for using the Gemini API is that it takes time for it to update on their dashboard, so costs can be accumulated very quickly without you being aware. You can set budgets and notifications via their dashboard.
This was my experience with Gemini. And I don't want to try any more. Simply I don't like being surprised. Gemini is ok as coding agent but Cloude is also very good and I can prepaid account not being cought with bill next morning. Thank you but no- Thank you.
IMO diff applying should be executed by a different model for cost optimization. Maybe deepseek-r1 or a Mistral model (seems like there should be a fine tune based on diffs from public git repos)...

Can any Roo devs comment on Multi-LLM support?
Caching is not yet  supported. But their product managers say that it would be supported in a few weeks
Don't think roo supports gemini's caching methods at all, and 2.5 pro doesn't support caching yet, it's only available in stable versioned models.
OP is right‚ÄîVertex docs do mention that context caching is available now. It seems likely that you'd need to use \`gemini-2.5-pro-preview-03-25\` via Vertex for this functionality. That said, I could be mistaken, as Google's documentation sometimes feels like it's created by teams that don't communicate with each other. Here's the relevant link for reference:  

[https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview#supported\_models](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview#supported_models)
I can relate, now I switched to DeepSeek v3 0324. some providers are providing it for free at the moment. It's been writing acceptable codes for my project since morning.
Yep ran into this exact issue, the Gemini 2.5 current implementation is a bear when it comes to token waste. I hit my last months token usage on Claude in 3 days with Gemini. Insane! So I have switched back to Claude exclusively and I will use Gemini only on a rare occasion when I want the large context window. Can't wait for the rumored Claude 500k context window option.
I used gemini 2.5 only because it was free. Unfortunately, many tasks broke the current code in stupid ways. I wasted a lot of time on restoring the version and improving what already worked. At this point I'm going back to 3.7 sonnet. It practically doesn't make mistakes in editing the existing implementation. Google has made a huge progress but they still have a long way to go to sonnet.

 Interestingly, the code generation itself is quite good now but, subsequent tasks can throw away part of the implementation. e.g. flask server running a process in the background, parameters via argv, but after the next task gemini threw away the existing parameter completely without giving a reason, where the task didn't even concern this area (I use RooCode)
Yeah it's extremely expensive. If you are going to spend $300 a day, why not hire a programmer like 4-5 days ? Makes no sense. In my opinion these models make sense only if you can use them for a whole day without managing context at all and you spend like $20. Otherwise, it's not worth it.
I was hit by this exact circumstance.

https://preview.redd.it/ux4vtu49cmue1.jpeg?width=1290&format=pjpg&auto=webp&s=222830e85be76feaf2d93e86a68584e6871d4a6f

I‚Äôm now using boomerang with a few additional modes.

Been using Gemini for planning. Then checking my plans with Claude Been using deepseek r1 and v3 for coding. Then Gemini for reviewing

Deepseek is painfully slow but after the plan is done, I‚Äôll leave the computer.
Yes, it's a shame
AFAI understand Preview just got caching support only through the Vertex API and the dev has been made aware of it to hopefully bring support - is that correct?
I am personally just using pro-exp-03-25 and I set a 30s rate limit. I haven't barely touched my $300 GCP credit.
You could use pro-exp and switch API keys/roo profiles when you hit the rate limit
Prompt caching is not implemented in Roo yet
I can't see this in the Vertex API, on my console? Can you point it out,  maybe I can get the Api via Vertex to work.

Or would it be In the prompt headers/system prompt itself ?

Just got bitten this morning, by this.
If I am using openrouter credits while consuming 2.5 pro preview, do I still need to worry about the Google billing?
I wonder if firebase studio would support caching
The problem is also on the Roo Code side. I flipped to Windsurf for a day now and have slashed price like 5x while using 2.5 and 3.7. Was happy on Roo Code but last few days could not get much done while flipping models a lot. So when handled correctly, the price must not be that high.
FIX: Just use Architect-mode for getting a HYPER-DETAILED plan with clear before-and-after actual code examples on SPECIFICALLY what to do.

Then put that into Cursor Native Chat with Sonnet 3.7 Thinking Max.
At least you caught it relatively early! Hopefully the Roo team is making caching a priority, but apparently the way Google implements caching is not the same as OpenAI or Anthropic, so unless they Google changes that, we might no be able to make use of caching anyway. I‚Äôm going to do some research myself because, for me, Gemini is hands down the best for working with large codebases
Just curious if you limit context windows in roo code to like 200k it will likely use tokens conservatively. But need to check. When it sees 1 million it goes unhinged.
mine too.  :(
Mate, I didn't even use Gemini and I got whacked with an erroneous bill on my GCP billing account. I'm done with GCP, it's shit anyway. Time to move to AWS.
https://preview.redd.it/updxezkjqyue1.png?width=698&format=png&auto=webp&s=6df9b6e23efc944aa16272719d28e4701f9c6ca8

Context caching seem to be available in 2.5 pro now(https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro) according to the model card. I too was hit by a $100+ USD for a single session. I was confused to see the CC charge and then on digging further noticed my each session was 5M+ tokens in
Roo Code 3.10.4 - Gemini 2.5 Pro IS HERE! ohh and a bunch of other stuff...
ü§ñ Provider/Model Support
* Added Gemini 2.5 Pro model to Google Gemini Provider (thanks samsilveira!)
* Add R1 support checkbox to Open AI compatible provider to support QWQ (thanks feifei325!)
* Add Bedrock support for application-inference-profile (thanks maekawataiki!)

üé® UI/UX Improvements
* Update UX for chat text area (thanks chadgauth!)
* Better display of OpenRouter "overloaded" error messages

üîß General Improvements
* Add a New Task command in the Command Palette (thanks qdaxb!)
* Support test declarations in TypeScript tree-sitter queries (thanks KJ7LNW!)
* Read image responses from MCP calls (thanks nevermorec!)
* Support a custom storage path for tasks (thanks Chenjiayuan195!)
* Dynamically fetch instructions for creating/editing custom modes and MCP servers (thanks diarmidmackenzie!)
* Rename and migrate global MCP and modes files (thanks StevenTCramer!)
* Add `taskCreated` event to API and subscribe to cline events earlier (thanks wkordalski!)
* Add watchPaths option to McpHub for file change detection (thanks 01Rian!)
* Add settings to control whether to auto-approve reads and writes outside of the workspace
* Fix readme links to docs (thanks kvokka!)

üêõ Bug Fixes
* Fixes to numeric formatting suffix internationalization (thanks feifei325!)
* Fix open tab support in the context mention suggestions (thanks aheizi!)
* Fix browser tool visibility in system prompt preview (thanks cannuri!)
* Fix the supportsPromptCache value for OpenAI models (thanks PeterDaveHello!)
This is great guys, what can I say.. What a time to be alive ;) Keep going the good work, cant wait to test it out
Gemini2.5 kicks ass for a fraction of the price of Claude3.7.  Anthropic and openAI are going have to reduce their prices severely just to stay in the game.
Like 50 a day
https://i.redd.it/3zj9wc12gzqe1.gif

Another day another banger
2.5Pro isn't working for me on Human Relay, although 2.0Pro worked fine. Has anyone managed to get it working, perhaps with a custom prompt?
Thank you for the updates!

OpenRouter API for Gemini 2.5 is getting hammered! Even routing through Ai Studio failing. 

Not complaining guys, please do not take it that way, just sharing :)

https://preview.redd.it/47wqjj9sj2re1.png?width=557&format=png&auto=webp&s=24849a86b5387e79059dd006f8d9124a9211cdc3
Curious if *auto-approval of only specific folders (or project root-down)* can be considered for a near-term feature release? I had hoped to see it on this list! Thanks. üòä

The issue is here: [https://github.com/RooVetGit/Roo-Code/discussions/1063](https://github.com/RooVetGit/Roo-Code/discussions/1063)

( And my recent Reddit post here as well for reference: [https://www.reddit.com/r/RooCode/comments/1jcxbwn/autoapprove\_only\_specific\_folders\_or\_the\_project/](https://www.reddit.com/r/RooCode/comments/1jcxbwn/autoapprove_only_specific_folders_or_the_project/) )
The Ultimate Roo Code Hack 2.0: Advanced Techniques for Your AI Team Framework
*Building on the success of our multi-agent framework with real-world applications, advanced patterns, and integration strategies*

## Introduction: The Journey So Far

It's been fascinating to see the response to my original post on the multi-agent framework - with over 18K views and hundreds of shares, it's clear that many of you are exploring similar approaches to working with AI assistants. The numerous comments and questions have helped me refine the system further, and I wanted to share these evolutions with you.
Heres pt. 1: https://www.reddit.com/r/RooCode/comments/1kadttg/the_ultimate_roo_code_hack_building_a_structured/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button

As a quick recap, our framework uses specialized agents (Orchestrator, Research, Code, Architect, Debug, Ask, Memory, and Deep Research) operating through the SPARC framework (Cognitive Process Library, Boomerang Logic, Structured Documentation, and the "Scalpel, not Hammer" philosophy).

## System Architecture: How It All Fits Together

To better understand how the entire framework operates, I've refined the architectural diagram from the original post. This visual representation shows the workflow from user input through the specialized agents and back:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            VS Code              ‚îÇ
‚îÇ     (Primary Development        ‚îÇ
‚îÇ          Environment)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             Roo Code            ‚îÇ
‚îÇ                ‚Üì                ‚îÇ
‚îÇ          System Prompt          ‚îÇ
‚îÇ   (Contains SPARC Framework:    ‚îÇ
‚îÇ    ‚Ä¢ Specification, Pseudocode, ‚îÇ
‚îÇ      Architecture, Refinement,  ‚îÇ
‚îÇ      Completion methodology     ‚îÇ
‚îÇ    ‚Ä¢ Advanced reasoning models  ‚îÇ
‚îÇ    ‚Ä¢ Best practices enforcement ‚îÇ
‚îÇ    ‚Ä¢ Memory Bank integration    ‚îÇ
‚îÇ    ‚Ä¢ Boomerang pattern support) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Orchestrator          ‚îÇ      ‚îÇ         User            ‚îÇ
‚îÇ     (System Prompt contains:    ‚îÇ      ‚îÇ     (Customer with      ‚îÇ
‚îÇ      roles, definitions,        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     minimal context)    ‚îÇ
‚îÇ      systems, processes,        ‚îÇ      ‚îÇ                         ‚îÇ
‚îÇ      nomenclature, etc.)        ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Query Processing         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         MCP ‚Üí Reprompt          ‚îÇ
‚îÇ     (Only called on direct      ‚îÇ
‚îÇ         user input)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Structured Prompt Creation  ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ       Project Prompt Eng.       ‚îÇ
‚îÇ       Project Context           ‚îÇ
‚îÇ       System Prompt             ‚îÇ
‚îÇ       Role Prompt               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Orchestrator          ‚îÇ
‚îÇ     (System Prompt contains:    ‚îÇ
‚îÇ      roles, definitions,        ‚îÇ
‚îÇ      systems, processes,        ‚îÇ
‚îÇ      nomenclature, etc.)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Substack Prompt         ‚îÇ
‚îÇ   (Generated by Orchestrator    ‚îÇ
‚îÇ        with structure)          ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ    ‚îÇ  Topic  ‚îÇ  ‚îÇ Context ‚îÇ    ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ    ‚îÇ  Scope  ‚îÇ  ‚îÇ Output  ‚îÇ    ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ    ‚îÇ       Extras        ‚îÇ     ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Specialized Modes         ‚îÇ   ‚îÇ           MCP Tools                 ‚îÇ
‚îÇ                                 ‚îÇ   ‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Code  ‚îÇ ‚îÇ Debug  ‚îÇ ‚îÇ ... ‚îÇ ‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ Basic   ‚îÇ  ‚îÇ CLI/Shell        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ ‚îÇ CRUD    ‚îÇ  ‚îÇ (cmd/PowerShell) ‚îÇ   ‚îÇ
‚îÇ       ‚îÇ          ‚îÇ        ‚îÇ    ‚îÇ   ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                                     ‚îÇ
        ‚îÇ          ‚îÇ        ‚îÇ        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
        ‚îÇ          ‚îÇ        ‚îÇ        ‚îÇ ‚îÇ API     ‚îÇ  ‚îÇ Browser          ‚îÇ   ‚îÇ
        ‚îÇ          ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ Calls   ‚îÇ  ‚îÇ Automation       ‚îÇ   ‚îÇ
        ‚îÇ          ‚îÇ                 ‚îÇ ‚îÇ (Alpha  ‚îÇ  ‚îÇ (Playwright)     ‚îÇ   ‚îÇ
        ‚îÇ          ‚îÇ                 ‚îÇ ‚îÇ Vantage)‚îÇ  ‚îÇ                  ‚îÇ   ‚îÇ
        ‚îÇ          ‚îÇ                 ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
        ‚îÇ          ‚îÇ                 ‚îÇ                                     ‚îÇ
        ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
        ‚îÇ                            ‚îÇ ‚îÇ        LLM Calls              ‚îÇ   ‚îÇ
        ‚îÇ                            ‚îÇ ‚îÇ                               ‚îÇ   ‚îÇ
        ‚îÇ                            ‚îÇ ‚îÇ ‚Ä¢ Basic Queries               ‚îÇ   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ ‚Ä¢ Reporter Format            ‚îÇ   ‚îÇ
                                     ‚îÇ ‚îÇ ‚Ä¢ Logic MCP Primitives        ‚îÇ   ‚îÇ
                                     ‚îÇ ‚îÇ ‚Ä¢ Sequential Thinking         ‚îÇ   ‚îÇ
                                     ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îò
                                                      ‚îÇ                 ‚îÇ
                                                      ‚ñº                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ                   Recursive Loop                                ‚îÇ    ‚îÇ
‚îÇ                                                                 ‚îÇ    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ     Task Execution     ‚îÇ    ‚îÇ      Reporting        ‚îÇ       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ    ‚îÇ                       ‚îÇ       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Execute assigned task‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Report work done    ‚îÇ       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îÇ ‚Ä¢ Solve specific issue ‚îÇ    ‚îÇ ‚Ä¢ Share issues found  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Maintain focus       ‚îÇ    ‚îÇ ‚Ä¢ Provide learnings   ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                           ‚îÇ                     ‚îÇ
‚îÇ                                           ‚ñº                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   Task Delegation      ‚îÇ    ‚îÇ    Deliberation       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§                       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Identify next steps  ‚îÇ    ‚îÇ ‚Ä¢ Assess progress     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Assign to best mode  ‚îÇ    ‚îÇ ‚Ä¢ Integrate learnings ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Set clear objectives ‚îÇ    ‚îÇ ‚Ä¢ Plan next phase     ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Memory Mode                                 ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  Project Archival      ‚îÇ    ‚îÇ   SQL Database        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ    ‚îÇ                       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Create memory folder ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Store project data  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Extract key learnings‚îÇ    ‚îÇ ‚Ä¢ Index for retrieval ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Organize artifacts   ‚îÇ    ‚îÇ ‚Ä¢ Version tracking    ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ  
‚îÇ                                           ‚îÇ                    |
‚îÇ                                           ‚ñº                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  Memory MCP            ‚îÇ    ‚îÇ   RAG System          ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§                       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Database writes      ‚îÇ    ‚îÇ ‚Ä¢ Vector embeddings   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Data validation      ‚îÇ    ‚îÇ ‚Ä¢ Semantic indexing   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Structured storage   ‚îÇ    ‚îÇ ‚Ä¢ Retrieval functions ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                ‚îÇ                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    feed            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê back ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Orchestrator          ‚îÇ loop ‚îÇ         User            ‚îÇ
‚îÇ     (System Prompt contains:    ‚îÇ ---->‚îÇ     (Customer with      ‚îÇ
‚îÇ      roles, definitions,        ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     minimal context)    ‚îÇ
‚îÇ      systems, processes,        ‚îÇ      ‚îÇ                         ‚îÇ
‚îÇ      nomenclature, etc.)        ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
|
              Restart Recursive Loop
```

This diagram illustrates several key aspects that I've refined since the original post:

1. **Full Workflow Cycle**: The complete path from user input through processing to output and back
2. **Model Context Protocol (MCP)**: Integration of specialized tool connections through the MCP interface
3. **Recursive Task Loop**: How tasks cycle through execution, reporting, deliberation, and delegation
4. **Memory System**: The archival and retrieval processes for knowledge preservation
5. **Specialized Modes**: How different agent types interact with their respective tools

The diagram helps visualize why the system works so efficiently - each component has a clear role with well-defined interfaces between them. The recursive loop ensures that complex tasks are properly decomposed, executed, and verified, while the memory system preserves knowledge for future use.

## Part 1: Evolution Insights - What's Working & What's Changed

### Token Optimization Mastery

That top comment "The T in SPARC stands for Token Usage Optimization" really hit home! Token efficiency has indeed become a cornerstone of the framework, and here's how I've refined it:

#### Progressive Loading Patterns
```markdown
# Three-Tier Context Loading

## Tier 1: Essential Context (Always Loaded)
- Current task definition
- Immediate requirements
- Critical dependencies

## Tier 2: Supporting Context (Loaded on Demand)
- Reference materials
- Related prior work
- Example implementations

## Tier 3: Extended Context (Loaded Only When Critical)
- Historical decisions
- Extended background
- Alternative approaches
```

#### Context Window Management Protocol
I've found maintaining context utilization below 40% seems to be the sweet spot for performance in my experience. Here's the management protocol I've been using:

1. **Active Monitoring**: Track approximate token usage before each operation
2. **Strategic Clearing**: Clear unnecessary context after task completion
3. **Retention Hierarchy**: Prioritize current task > immediate work > recent outputs > reference information > general context
4. **Chunking Strategy**: Break large operations into sequential chunks with state preservation

### Cognitive Process Selection Matrix

I've created a decision matrix for selecting cognitive processes based on my experience with different task types:

| Task Type | Simple | Moderate | Complex |
|----------|--------|----------|---------|
| Analysis | Observe ‚Üí Infer | Observe ‚Üí Infer ‚Üí Reflect | Evidence Triangulation |
| Planning | Define ‚Üí Infer | Strategic Planning | Complex Decision-Making |
| Implementation | Basic Reasoning | Problem-Solving | Operational Optimization |
| Troubleshooting | Focused Questioning | Adaptive Learning | Root Cause Analysis |
| Synthesis | Insight Discovery | Critical Review | Synthesizing Complexity |

## Part 2: Real-World Applications & Case Studies

### Case Study 1: Documentation Overhaul Project

**Challenge**: A complex technical documentation project with inconsistent formats, outdated content, and knowledge gaps.

**Approach**:
1. **Orchestrator** broke the project into content areas and assigned specialists
2. **Research Agent** conducted comprehensive information gathering
3. **Architect Agent** designed consistent documentation structure
4. **Code Agent** implemented automated formatting tools
5. **Memory Agent** preserved key decisions and references

**Results**:
- Significant decrease in documentation inconsistencies
- Noticeable improvement in information accessibility
- Better knowledge preservation for future updates

### Case Study 2: Legacy Code Modernization

**Challenge**: Modernizing a legacy system with minimal documentation and mixed coding styles.

**Approach**:
1. **Debug Agent** performed systematic code analysis
2. **Research Agent** identified best practices for modernization
3. **Architect Agent** designed migration strategy
4. **Code Agent** implemented refactoring in prioritized phases

**Results**:
- Successfully transformed code while preserving functionality
- Implemented modern patterns while maintaining business logic
- Reduced ongoing maintenance needs

## Part 3: Advanced Integration Patterns

### Pattern 1: Task Decomposition Trees

I've evolved from simple task lists to hierarchical decomposition trees:

```
Root Task: System Redesign
‚îú‚îÄ‚îÄ Research Phase
‚îÇ   ‚îú‚îÄ‚îÄ Current System Analysis
‚îÇ   ‚îú‚îÄ‚îÄ Industry Best Practices
‚îÇ   ‚îî‚îÄ‚îÄ Technology Evaluation
‚îú‚îÄ‚îÄ Architecture Phase
‚îÇ   ‚îú‚îÄ‚îÄ Component Design
‚îÇ   ‚îú‚îÄ‚îÄ Database Schema
‚îÇ   ‚îî‚îÄ‚îÄ API Specifications
‚îî‚îÄ‚îÄ Implementation Phase
    ‚îú‚îÄ‚îÄ Core Components
    ‚îú‚îÄ‚îÄ Integration Layer
    ‚îî‚îÄ‚îÄ User Interface
```

This structure allows for dynamic priority adjustments and parallel processing paths.

### Pattern 2: Memory Layering System

The Memory agent now uses a layering system I've found helpful:

1. **Working Memory**: Current session context and immediate task information
2. **Project Memory**: Project-specific knowledge, decisions, and artifacts
3. **Reference Memory**: Reusable patterns, code snippets, and best practices
4. **Meta Memory**: Insights about the process and system improvement

### Pattern 3: Cross-Agent Communication Protocols

I've standardized communication between specialized agents:

```json
{
  "origin_agent": "Research",
  "destination_agent": "Architect",
  "context_type": "information_handoff",
  "priority": "high",
  "content": {
    "summary": "Key findings from technology evaluation",
    "implications": "Several architectural considerations identified",
    "recommendations": "Consider serverless approach based on usage patterns"
  },
  "references": ["research_artifact_001", "external_source_005"]
}
```

## Part 4: Implementation Enhancements

### Enhanced Setup Automation

I've created a streamlined setup process with an npm package:

```bash
npx roo-team-setup
```

This automatically configures:
- Directory structure with all necessary components
- Configuration files for all specialized agents
- Rule sets for each mode
- Memory system initialization
- Documentation templates

### Custom Rules Engine

Each specialized agent now operates under a rules engine that enforces:

1. **Access Boundaries**: Controls which files each agent can modify
2. **Quality Standards**: Ensures outputs meet defined criteria
3. **Process Requirements**: Enforces methodological consistency
4. **Documentation Standards**: Maintains comprehensive documentation

### Mode Transition Framework

I've formalized the handoff process between modes:

1. **Pre-transition Packaging**: The current agent prepares context for the next
2. **Context Compression**: Essential information is prioritized for transfer
3. **Explicit Handoff**: Clear statement of what the next agent needs to accomplish
4. **State Persistence**: Task state is preserved in the boomerang system

## Part 5: Observing Framework Effectiveness

I've been paying attention to several aspects of the framework's performance:

1. **Task Completion**: How efficiently tasks are completed relative to context size
2. **Context Utilization**: How much of the context window is actively used
3. **Knowledge Retrieval**: How consistently I can access previously stored information
4. **Mode Switching**: How smoothly transitions occur between specialist modes
5. **Output Quality**: The relationship between effort invested and result quality

From my personal experience:
- Tasks appear to complete more efficiently when using specialized modes
- Mode switching feels smoother with the formalized handoff process
- Information retrieval from the memory system has been quite reliable
- The overall approach seems to produce higher quality outputs for complex tasks

## New Frontiers: Where We're Heading Next

1. **Persistent Memory Repository**: Building a durable knowledge base that persists across sessions
2. **Automated Mode Selection**: System that suggests the optimal specialist for each task phase
3. **Pattern Libraries**: Collections of reusable solutions for common challenges
4. **Custom Cognitive Processes**: Tailored reasoning patterns for specific domains
5. **Integration with External Tools**: Connecting the framework to development environments and productivity tools

## Community Insights & Contributions

Since the original post, I've received fascinating suggestions from the community:

1. **Domain-Specific Agent Variants**: Specialized versions of agents for particular industries
2. **Hybrid Reasoning Models**: Combining cognitive processes for specific scenarios
3. **Visual Progress Tracking**: Tools to visualize task completion and relationships
4. **Cross-Project Memory**: Sharing knowledge across multiple related projects
5. **Agent Self-Improvement**: Mechanisms for agents to refine their own processes

## Conclusion: The Evolving Ecosystem

The multi-agent framework continues to evolve with each project and community contribution. What started as an experiment has become a robust system that significantly enhances how I work with AI assistants.

This sequel post builds on our original foundation while introducing advanced techniques, real-world applications, and new integration patterns that have emerged from community feedback and my continued experimentation.

If you're using the framework or developing your own variation, I'd love to hear about your experiences in the comments.
I am beyond excited to test this out! Now to figure out how to remove my RooFlow integration in favor of this‚Ä¶
So how the heck do you get SPARQ + Boomerang to not infinitely loop on the same task? I feel like I'm missing a bit of an 'idiots guide' to getting going with this. Also, how do you track the subtasks within roo?
What? I understood nothing. What is the summary
Where do we define the line for what constitutes a "complex task"?
is their a git to look over the code?

  
also i see mcp-reprompt... what is that a custom mcp?
Looking forward to giving this a try. Having dabbled in this space myself, I appreciate how much work is involved, nicely done!   
  
My only comment at this point is that it would have been preferable (IMHO) for the modes to have different names from the standard Roo Code modes.
Looking good! Will test later.
Would you recommend using same LLM for all modes? I was thinking of mixing and matching depending on complexity/importance
So can this system work perfectly with the second installation option of just the setting files?
I've got a couple of questions: 

1. Is memory generated automatically? I haven't seen the Memory Mode triggered yet. Also I saw there's a memory MCP listed on the flow chart. Is this something that I need to install separately? 

2. I've read someone mentioning another MCP called reprompter. Is this also necessary? 

So far though, I'm pretty impressed. It's able to do a deep research by applying a specific mental model. I still need more testing with it to see the full potential. Thank you very much for your work!
I currently did my own framework and the notions of memory bank has been moved to Jirq/confluence (using either or both confluence pages and jira comments to retrieve information and handoff context to others agents).

Is there a way to easily replace the inherent behavior here, which I believe is based on local files and use my previously described workflow instead?
Any tips for using this with GPT 4.1?
When should we be trying your full configuration vs config only? Also it seems like the examples doc folders are only populating with placeholder info and not your examples (/agents, /best-practices, etc)
What RAG setup do you use?

Have you tried [https://github.com/chroma-core/chroma-mcp](https://github.com/chroma-core/chroma-mcp) or [https://github.com/doobidoo/mcp-memory-service](https://github.com/doobidoo/mcp-memory-service) ?
Brother, what‚Äôs with the shit formatting in system architecture. 
Not everyone has time to read a whole wall of text. 
Maybe start with a tl;dr first?
Just a humble thanks to the developers
I rarely make the effort to post about the things I use, and I'm not that easily impressed either. But credit should be given where it's due. And the Roo code is such a delight to work with and brings such value to the workflow which can't be understated enough. I had a moment just now where the debug mode fixed a previous very annoying bug that has been haunting my work and caused issues down the road. But now it is fixed. But that is just a minor thing in the overall picture. Huge thanks to the developers!
Agreed! And you can thank them the most by taking a moment and leaving a short review on [https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details) ;)
I couldn't agree more!
On behalf of Roo, thank you.
We live in the best timeline
üöÄ Next-Gen Memory Bank for Roo Code: Fully Automated, Adaptive, and Smarter Than Ever
Hey everyone,

I‚Äôm excited to share my latest project‚Äî[Advanced Roo Code Memory Bank](https://github.com/enescingoz/roo-advanced-memory-bank)‚Äîwhich represents one of the most cutting-edge approaches in the memory bank space for AI-assisted development workflows.

---

### Why is this different?

- **Solves Old Problems:**  
  This system addresses most of the pain points found in earlier memory bank solutions, such as context bloat, lack of workflow structure, and mode interference. Now, each mode is isolated, context-aware, and transitions are smooth and logical.

- **Truly Modular & Adaptive:**  
  Modes are interconnected as nodes in a workflow graph (VAN ‚Üí PLAN ‚Üí CREATIVE ‚Üí IMPLEMENT), with persistent memory files ensuring context is always up-to-date. Rules are loaded just-in-time for each phase, so you only get what you need, when you need it.

- **Almost Fully Automatic Task Completion:**  
  The workflow is designed for near full automation. Once you kick off a task, Roo Code can handle most of the process with minimal manual intervention.  
  üëâ *Check out the example usage video in the repository‚Äôs README to see this in action!*

---

### See It in Action

- [Repository Link](https://github.com/enescingoz/roo-advanced-memory-bank)
- Don‚Äôt forget to check the example usage video in the repository.

---

If you‚Äôre interested in advanced memory management, AI workflow automation, or just want to see what the future of dev tools looks like, I‚Äôd love your feedback or questions!

Let‚Äôs push the boundaries of what memory banks can do üöÄ

no boomerang?
All great talk and happy for your project, but how does it translate into shortening context windows for inputs and resulting lower cost? Can you post benchmarks and other stats that actually point to performance/cost improvements?
I'll try this. Any known issues with it so far?
Any video tutorial for that ü•≤?
[deleted]
I implemented that some weeks ago, but tbh I don‚Äôt know how this shall edit some files. So I only use it for documentation in VAN mode which creates a lot of different files - around 12 at the moment. I guess I don‚Äôt use it correctly. So unsurprisingly I am a little underwhelmed.
Did I just see this on YouTube today?
this looks great. Can you explain how you got "just in time" to work dynamically within roo code?
this can be used to handling context between other custom modes? like micromanager modes? 

Would it be of any use? I don't know.
This seems pretty cool.

One of the things that has frustrated me about the current memory bank and mode solutions is the fragmentation that happens as roocode evolves. Take Rooflow and previous memory bank solutions. They start out being very effective but then as Roo itself evolves, these solutions tend to not be able to keep up.

I think another problem with previous memory banks and custom modes was that they break MCP tool use in some cases. At least that was the case with older memory banks. I don't know if it's still the case.

Do you have a plan for keeping up with Roo Codes very high development velocity? I would love to see something like this become part of core roocode.

How does this compare and differ to the new [Boomeerang mode PR](https://www.reddit.com/r/RooCode/comments/1k7erxr/boomerang_is_coming_to_primetime/)?
I fixed Boomerang + RooFlow (+ memory banks) compatibility
Its live in my AI-ready monorepo starter too! :) :  
[https://github.com/NamesMT/starter-monorepo](https://github.com/NamesMT/starter-monorepo)

  
I have tried quite a lot of prompt with it, planning, initialize new apps in the monorepo, add functions, the memory bank context is only loaded once by \`Boomerang\` and passed down to all subtasks, and they could do stuff super quick without all the read files tool use and APIs loop.
Sorry, I forgot to add the actual prompt code, here is a gist:  
[https://gist.github.com/NamesMT/3940ddf4ec85db6a40de16e859219fd2](https://gist.github.com/NamesMT/3940ddf4ec85db6a40de16e859219fd2)
Does it work with MCPs?
I think this is the wrong approach.

If the files are read only by Boomerang and only once, then:

1. The files may change if child agents make edits to it.

2. The files will always be in the context of Boomerang, which can make it bloat. And this is bad, because every time the tool is invoked, Boomerang will take this context into account, which will be financially expensive
I‚Äôm a new user of RooCode. Can you provide steps to use these instructions in RooCode?
thank you for the work!

The boomerang starts and builds, and then roocode crashes, and resuming leaves stagnant tasks with no way to recover.
Updates notes! 3.11.8 just dropped!
3.11.8 is out. Nothing that huge, but we've pushed a bunch of solid fixes over the last few days, mostly around apply diff issues when using Gemini 2.5. Notable other changes include early support for `.roorules`, and caching support for bedrock provider. We'll continue updating the docs with more detail as we go. I will make a more formal announcement on the various features added here once we update the docs, over next few days. 

Shoutout to all the contributors:

- kyle-apex  
- samhvw8  
- upamune  
- PeterDaveHello  
- System233  
- Smartsheet-JB-Brown  
- shoopapa  
- gtaylor  
- p12tic  
- diarmidmackenzie  
- benny123tw  
- wkordalski  
- StevenTCramer  
- KJ7LNW  
- axmo  
- thomasjeung  

[3.11.8 (2025-04-05)](https://docs.roocode.com/update-notes/v3.11.8)  
[3.11.7 (2025-04-04)](https://docs.roocode.com/update-notes/v3.11.7)  
[3.11.6 (2025-04-04)](https://docs.roocode.com/update-notes/v3.11.6)  
[3.11.5 (2025-04-03)](https://docs.roocode.com/update-notes/v3.11.5)  
[3.11.3 (2025-03-31)](https://docs.roocode.com/update-notes/v3.11.3)  
[3.11.2 (2025-03-31)](https://docs.roocode.com/update-notes/v3.11.2)  
[3.11.1 (2025-03-30)](https://docs.roocode.com/update-notes/v3.11.1)
Those diff failures are a pain. write_to_file is my go-to solution when encountering constant diff failures.
Brooo didn't i just updated this morning? Yall pushing for AGI?
Just wondering, are we gonna get Gemini 2.5 to have a computer used version?
you even sleep?
Thank you so much for the diff fix !
I report another bug, context: still G2.5, initial Boomerang mode but I encounter this error very often in sub-tasks in Code mode:

https://preview.redd.it/0qnbt41euate1.png?width=426&format=png&auto=webp&s=1f1760a9286d94bcdf3afda17027ba513e6346d9

I know: the error says to use Claude 3.7 but it seems strange to me that sometimes it works and sometimes it doesn't. When I close the task and Boomerang mode restarts it, it usually starts working again. It's like sometimes it can't decipher the tool\_use and tool\_name directions properly.
Is it possible to combine architect mode with boomerang mode? How?

Also, what about multiple instances of chat/agent like in cursor mode?
Just wanted to report that I used this release a bit with Gemini, and was 100% on diff application success.  Great work!
V2.0 of Prompt Template for Cursor/Roo Code/ CLINE, etc. Follows Agile Development and has a Unified Memory Bank. (280+ GitHub stars)
Launching V2.0 of the Prompt template. [https://github.com/Bhartendu-Kumar/rules\_template](https://github.com/Bhartendu-Kumar/rules_template)

# Who is this Template for?

1. **Beginners** in AI and these tools  (as its a boiler plate, just copy these files in your project)  
2. **Experienced** Builders (its having massive power like **Agile** Workflow based (combining Software Engineering principles and Test driven dev.) and constant documentation, you will love it)  
3. **vibe coders** (it is intended to extract best use of LLMs, while being on track): you do not need to do anything than just copy pasting the files, therrea Quickstart section. 

# What's this Template?

1. A Unified Custom Prompt for any project development (Software, AI, Research)
   1. Have tested it for:
      1. Software Projects
      2. AI Apps
      3. Research Papers
2. Unified prompt base for Cursor/Roo Code/ CLINE, etc. So a uniformality in all of these. The prompt base is following "Agile Development and Test Driven Methodology". The template puts **Documentation first** approach. Which helps AI models to have proper context and also keeps development at ease.
   1. So, use this rule base if you want all important things to be documented well.
   2. Else, if you are not doing documentation properly, you are not utilizing AI models well.
3. Unified Memory bank
   1. The working project memory is shared and available with all the coding agents (Cursor/Roo Code/ CLINE, etc)
   2. Thus, shift tools and platforms at ease.
   3. Persists across chats, tasks, computers, sessions, etc.
4. Token Saving:
   1. Focussed on minimal context and rule loading
   2. 3 custom modes to work for better token saving.
5. Updated to the latest Rules Structures:
   1. Updating the project constantly to follow the latest guidelines for Rules directories and structuring.

This template has 3 things that I worked on (so you don't have to):

1. Aggregate many many types of different custom rule files and form one based on the Tried and tested "Agile Software Development" strategy. I have included the best prompts that I could find from everywhere. So you don't need to do prompt scavaging.
2. Memory Bank: Updated the memory bank structure for better:
3. Separation of concerns
4. Modular Code
5. Document all necessary things
6. A memory bank structure that follows software development documentation. Which has literature from the early 70s. Thus, LLMs know it and are at ease.
7. Included Memory bank and development process in one integrated unit, so the rules make the best use of memory and memory makes best use of rules.

\----

Many of us use this; we currently have 280+ stars. I have tested it extensively for AI product development and research papers. It performs better due to the rules and memory and also massively saves tokens. So, come and try it. Even better, if you have ideas, then pull it.

[https://github.com/Bhartendu-Kumar/rules\_template](https://github.com/Bhartendu-Kumar/rules_template)

\-------------
Your template needs to include a rule about not removing readme files.



https://preview.redd.it/ag6fmx40o5ve1.png?width=1696&format=png&auto=webp&s=53cf2b338c52bf3e8a560e88b28082e724dd28c1
Are you planning to support/use boomerang / subtasks?
2 Questions: 1) does this work if I'm using Boomerang mode (i.e. auto switch modes) in Roo Code?   
2) In the Roo settings, I have specific role definitions for all modes, including boomerang, and specific instructions. Can your set of instructions co-exist with the higher-level mode settings role and instructions?   
  
Bonus question and unrelated ;) : do you know if you have to copy / paste my own custom instructions that I have in boomerang to all other modes, or Roo is smart enough to cycle through modes while always referering to the boomerang instructions?  Thanks in advance.
I've admired this since the original version, nice job.   

I'm in the middle of migrating from Cursor to Roo and looking forward to the Roo version of Task Master AI (https://github.com/eyaltoledano/claude-task-master) which is just a PR away.

There seems to be some overlap, specifically around sub-tasks, but do you think I could get the best of both worlds by using your rules as well as Task Master?

Thanks,
Is that boomerang?
How does this compare to RooFlow? The memory bank system seems more practical.
What about vscode with copilot?
This sounds really interesting! To use this I just paste all the files into my project folder?
FYI, your readme file is empty - it does not appear to have survived the latest commit!
Read me file please
Prompts for Roo? Thx
How can I use the guide for an existing project?

**Note: For existing projects, follow above steps, additionally give the prompt to AI:**

>

(Copy above prompt as first prompt!)

Should I copy and use it in chat mode?  
Tks :D
I would say 
1. Copy all the necessary directories in your trot first in your existing repo
2. Call that prompt to build ‚Äúmemory bank‚Äù. The prompt is in read me for existing project 

That prompt be called in any task (new task preferred) and in Architect Mode (Roo), Agent Mode (cursor), Plan mode (cline). 

Best preferred be Architect mode of roo in a new task. 

Agent mode of cursor would still work just (nobody is sure cursor will include rules or not as they have their processing logic). 

So maybe explicitly tag the rule files in .cursor/rules/
in that pasted prompt in Agent mode of cursor
Very nice - I posted a very similar video and workflow - awesome seeing similar ideas, we all improve by sharing like this - thanks! Making it agnostic to IDE is the best idea - can easily use cursor cline windsurf interchangeably. For the early agile stages, I have been having really good success throwing in deep research from Gemini 2.5 pro building the agent modes in as gems. Really great for research and not using any credits from within the IDE. Just have to do a bit of file shuffling to the IDE one you need it in there, but its not bad. Check it out if you like [https://github.com/bmadcode/BMAD-METHOD](https://github.com/bmadcode/BMAD-METHOD) or can find me on youtube going through the method in detail as the repo is still a bit disorganized.

I think biggest difference is I am trying to avoid using a lot of rules and instead relying on custom modes with different personalities - makes for a very nice separation of concerns and direct rule injection to the specific chosen persona (architect, dev, PM, BA etc...).

Have you tried using the modes in roo / cursor / cline instead of much with rules?
It's beautiful to see an AI operate in full autonomy...

Don't cry for me. After panicking, I noticed that all the tabs were still open so I could save them and restore the files.

My next action is, guess what, to implement regular backup :-)

Note: this sub should have a flair "cautionary tale".
I wouldnt put rm in allowed commands. But funny Screenshot
I'll take this whole thread as an upvote for adding an "Auto-denied Commands" section. My condolences to your database!
Don't worry, just tell your boss everyone vibe codes in prod.
You went full auto. NEVER GO FULL AUTO!
You added rm to the list??? What are you, a dunce?
You try enabling file access outside of your workspace!
Which LLM was this? I‚Äôve found some are much more willing to remove huge databases than others.
I thought this was Cursor for a moment üòÖ
I like using Cline to install the MCP server then update my Roo MCP servers (faster) but every once in a while even Claude 3.7 or Deepseek-R1 will clobber my entire MCP configuration while trying to install a a server. So yeah I‚Äôve learned to back things up, use Git, and keep a close eye on these mofos.
Roo Code 3.3.10 Released
### üì¢ Notable Changes
- Improvements to the default prompts for Architect and Ask mode  
- Allow switching between modes with slash messages like `/ask why is the sky blue?`  

### üî¨ Experimental
- Improvements to experimental unified diff strategy and selection logic in code actions (thanks nissa-seru!)  

### üîß General Improvements
- Add shortcuts to the currently open tabs in the "Add File" section of @-mentions (thanks olup!)  
- Enable markdown formatting in o3 and o1 (thanks nissa-seru!)  
- Improved terminal shell detection logic (thanks canvrno for the original and nissa-seru for the port!)  
- Visual improvements to the list of modes on the prompts tab  
- Visual cleanup to the list of modes on the prompts tab  

### üêõ Bug Fixes
- Fix pricing for o1-mini (thanks hesara!)  
- Fix context window size calculation (thanks MuriloFP!)  
- Fix occasional errors when switching between API profiles (thanks samhwv8!)  
- Fix double-scrollbar in provider dropdown  
Amazing work!

Re. Open tabs: It would be great to be able to set approvals for those separately from reading regular project files.
What I mean is: when I set to approve reads by default, it reads any open tab by default as well (even if it‚Äôs from outside project folder), which sometimes leads to reading files which shouldn‚Äôt be in the context or can‚Äôt fit there.
thanks you so much!! improving everyday! incredible!
Roo is just insane at how fast it improves. Amazing community. Now if only we had models consistently intelligent enough to keep up with Roo.. ü§î
Thanks for all the awesomeness!  Keep it coming!
Could you please provide a list of the best models for RooCode? I‚Äôve tried using models like Phi4, DeepSeek R1, and Qwen code with Ollama, but I‚Äôve encountered random errors.
Thank you all for the amazing work!
Would be nice to make it so it never edits certain files. I have an architecture.md file that contains detailed project info and Roo always wants to remove everything from the file and fill it with whatever it wants as progress update
it says Max output:¬†8,192¬†tokens for the new  Google models
Roo Code 3.8 - ü™É Boomerang Tasks, Smarter Diff Edits, Multi-Window Support & More

I am having such a fun time building with Roo Code. Amazing work thank you!
Being able to run multiple windows will be a game changer! I have my front end and back end in two different repos. Being able to work on these the same time is going to significantly increase my productivity
This is amazing! Thanks for all the hard work all involved!
Thank you all for this! Amazing work!!
Well done, devs! I'm using it and it's vastly improved. The boomerang feature is great and really helps maintain context, and task splitting.

I can do so much more now with the Copilot LLM and Sonnet 3.5 API before hitting acceptable use limits. The tokens per task are now minimal, which is fantastic for coding, I always found Sonnet starts to Hallucinate over 500 k tokens. 

500k tokens seem high, but it is very unintentional, as that's the life of a Programmer, 99 bugs in the code, fix one bug, now I have 200 bugs in the code... 

I can't seem to find a Patreon or sponsor link? You guys deserve a case of beer, coffee, or whatever suits your taste. Thanks for the hard work!
Keep it up üëç
thanks for the update! Am still getting the terminal overload / gray screen of death issues on this latest version though :( 

Would provide steps to repro... but no idea what is causing it
Is there an example of Human Relay?

Keep up the amazing work!
Project Indexer - Helps LLMs / Roocode to Understand your Solution
[Project Indexer Github](https://github.com/Dolfie-01/ProjectIndexer/tree/main)

**I made a simple Project Indexer script to help LLMs work better with large codebases**

Hey folks,

  
RooCode is Awsome. 

  
I am a Big Fan of D.R.Y Coding Practices (Don't Repeat Yourself).

I threw together a little Python script that scans your entire project and creates a `ProjectIndex.json` file listing all your classes, files, and method names.

 It doesn‚Äôt give all the internals, just enough for an LLM to ***know what exists and where,*** which I found drastically reduces hallucinations and saves on tokens (just my personal observation).

It‚Äôs not a  MCP or plugin‚Äîjust a single `.py` script. You drop it in the root of your project and run it:

    python Project_Indexer.py
    

It spits out a JSON file with all the relevant structure.

I built this for myself because I‚Äôm working with a VS Solution that has 5 projects and over 600 classes/methods.

The LLMs were really struggling, making up stuff that barely existed or completely missing things that *did*. 

With this, I can give it a quick map of what‚Äôs available right from the start.

If you're using **RooCode**, you can even instruct it (sometimes) to run this automatically or refresh it when starting a new task. 

Otherwise, I just leave the terminal open and hit enter to regenerate it when needed.

This tiny script has been super helpful for me. 

Maybe it helps someone else too, or maybe someone can suggest improvements on it!

Let me know what you think.
I've had Claude 3.7 come up with that idea multiple times on its own, while working with large projects. I just had to prime it with something like "find a smart way to index the codebase" or "list all classes in a json file".
But this will save some tokens, thanks.
why not to use aider to do repomap? I save it on every commit via git hook
Remindme! 80 hours
Thank you for sharing! Will definetly try this and see how it helps.
This is only for csharp , right? (please correct me if i am mistaken)  
One idea for enhancement without much work  is to make use of [https://github.com/codegen-sh/codegen](https://github.com/codegen-sh/codegen)  to do this for ¬†Python and TypeScript files
[deleted]
Remindme! 80 hours
Nice. I made something similar with ast traversal.
 The characters in json use more tokens. Have you tried to output the index with a plain text file? I‚Äôm curious if the results are similar
Remindme! 80 hours
Remindme! 80.1 hours
LLM's will also work with ctags v.well
Remindme! 50 hours
Interesting idea. I think Python's a better choice than MCP because it's easier to modify. Modifying the MCP server is too much trouble. Have you considered using Roo Flow directly? Has anyone tried using Bloomrange or Roo Flow to have Roo recursively analyze the code and generate an index or a condensed explanation document?
Proposal: Roo-Code Community GitHub Repository for Sharing Setups & Customizations
I've been thinking about how amazing it would be for us, as a community, to have a centralized place where we can share our setups and customizations for Roo-Code. A GitHub repository could be the perfect solution for this!

Here‚Äôs what I‚Äôm envisioning:

1. **Upload and Share**: Users can contribute their own `.clinerules`, `cline_mcp_settings.json`, `cline_custom_modes.json`, and any other related configurations.
2. **Browse and Learn**: Anyone could browse through different setups and learn from other community members‚Äô workflows and optimizations.
3. **Collaborate and Improve**: We could build on each other's ideas, creating better default settings or innovative rules for various coding scenarios.

This would be especially helpful for newcomers to quickly get started, and for experienced users to showcase cool setups or solutions they've created.

thoughts ?
Honestly we need to make a shared repo but the cursor folks have made something like this here: [https://github.com/PatrickJS/awesome-cursorrules?tab=readme-ov-file#backend-and-full-stack](https://github.com/PatrickJS/awesome-cursorrules?tab=readme-ov-file#backend-and-full-stack)

the thing is clinerules and cursorrules are compatible, its literally just LLM instructions.

Thse should  all work for roo code or cline
I am fully all-in to help build this. Ping me if a group is created. I can allocate 5 hours a week to making it indispensable to our community. I'm not an expert coder but I do understand how to write technical stuff that anyone can understand.
Yeah I like. And maybe even bring it a step further and create a "getting started wizard" for initial tailored setup.
Some .clinerules/mcp configs would be awesome üôè
this is amazing.
Why don't we add those directly in the actual roo-code project?
Great idea! I have used the Cursor rules that u/OriginalPlayerHater mentioned and can see a difference on some projects.
Discord might be easier?
Roo Code 3.9.0 Release Notes - MCP SSE Support and more!
## üîó**MCP Remote Connectivity**
Roo Code now support SSE MCP servers (thanks aheizi!)
* Enables communication with remote MCP servers over Server-Sent Events (SSE).
* This expands beyond existing stdio MCP server support, making it easier to integrate with hosted and distributed setups.

## üåé Internationalization
Roo Code has gone global with support for 14 languages and all around impROOvements for a smoother hopping experience!
* You can now use Roo Code in more languages: Simplified Chinese, Traditional Chinese, Spanish, Hindi, French, Portuguese, German, Japanese, Korean, Italian, Turkish, Vietnamese, Polish, and Catalan (thanks feifei325!)
* To change your language, go to Advanced Settings > Language

## ü§ñ Open Router Provider by Model Support
Choose a specific provider when using OpenRouter (thanks PhunkyBob!)
* OpenRouter routes requests to the best available providers for your model. By default, requests are load balanced across the top providers to maximize uptime. However, you can choose a specific provider to use for this model
* Do this in your "Configure Profile" section of the advanced setting when using OpenRouter as your API Provider

## üñºÔ∏è UI/UX Improvements
Support batch deletion of history items (thanks aheizi!)
* Instead of an all or almost nothing approach where you either have to delete one at a time or delete the entire history, batch deletion allows you to select multiple items and delete them in one go.
* Navigate to your task history by clicking "VIEW ALL" in your recent tasks and toggle the "Selection Mode" button at the top of the screen to enable batch deletion.

## üì¢ Text-to-Speech
Text-to-speech option that allows Roo to talk to you as it works, providing audio feedback alongside visual responses (thanks heyseth!)
* You can enable this in the Advanced Settings under "Notifications"

## ‚å®Ô∏è Terminal Improvements(Thanks KJ7LNW!)
* Made the terminal shell integration timeout configurable to resolve issues with long shell startup times (thanks filthy and kiwina!)
* Previously, users would encounter "Shell Integration Unavailable" errors due to a hard-coded 4-second timeout
* The timeout is now adjustable through Advanced Settings, allowing values from 1 to 60 seconds
* Default remains at 4 seconds, but you can increase this if your shell takes longer to initialize
* Fixed a race condition that caused terminal output to not be recognized and to hang

## üêõ Bug Fixes & üîß General Improvements
* Improve task deletion when underlying files are missing (thanks GitlyHallows)
* Improve support for NixOS & direnv (thanks wkordalski)
* Expose task stack in `RooCodeAPI` (thanks franekp)
* Fix Human Relay to work on the welcome screen and as a bonus it also supports internationalization (thanks NyxJae!)
* Fix display updating for Bedrock custom ARNs that are prompt routers (thanks Smartsheet-JB-Brown!)
* Fix to exclude search highlighting when copying items from task history (thanks im47cn!)
* Fix context mentions to work with multiple-workspace projects (thanks teddyOOXX!)
* Fix to task history saving when running multiple Roos (thanks samhvw8!)
* Fix wheel scrolling when Roo is opened in editor tabs (thanks GitlyHallows)
* Fix file mentions when using the "Add to context" code action (thanks qdaxb)

----

@everyone I **need** your reviews. Most of you probably think "someone else will do it" and skip over this, but **your review** truly matter. **[Take 60 seconds to leave a review](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details)** on the VS Code Marketplace. It's how other devs find Roo Code and makes a huge difference to our visibility.
What about ‚Äúspeech to text‚Äù ? I would like to talk to and explain what I need AI to modify, create instead of typing messages ?  That would be a handy feature
My review is the team working on Roo Code is amazing.  
I really appreciate the work and the time you spend on doing this super cool project and i honestly think you guys need more appreciation.

Honestly for anything new which could be cool on Roo Code it would be some way to make the memory bank feature or Roo Flow more easy to install (and maybe do some update to improve the compatibility with those methods).

RooFlow could be the way to make this tool usable at a business scale. Like being able to have a shared context from one prompt to another is really a BIG feature.  
So yes i think it's already a big thing to implement so I will not ask for more. Good luck and have a great day!
Do you guys have a similar feature to .clinerules folder
Terminal (powershell 7.5) finally works now, ty
Every relase make it better. Thanks for efforts üëå
It has been hanging and not completing jobs over the last few days. Nearly unusable. With athropic claude\*
u/hannesrudolph About Open Router Provider  
Could you please add options for all available model providers?  
For example R1 [https://openrouter.ai/deepseek/deepseek-r1/providers](https://openrouter.ai/deepseek/deepseek-r1/providers) has Fireworks and Fireworks basic that has a 4x difference in price
please add support to azure ai models
New Deep Research Mode in Roo Code combined with Perplexity MCP enables a powerful autonomous research-build-optimize workflow that can transform complex research tasks into actionable insights and functional implementations.
see: [https://gist.github.com/ruvnet/88c61ee4e38191b0be65f498792d5017](https://gist.github.com/ruvnet/88c61ee4e38191b0be65f498792d5017)  
  

Now connect alpha vantage and arxiv for real time finances and open source scientific papers
I have been working on a selenium app. Can I use this and pull in selenium docs to research and implement methods model learns this way
üî• Here's my Fire Crawler Mode for Roo using Composio. It can automatically harvest massive amounts of content from the web. [https://gist.github.com/ruvnet/e6141839f5ad3222be40c751069e0d61](https://gist.github.com/ruvnet/e6141839f5ad3222be40c751069e0d61)
I did it with jina, I created an agent and I'm integrating it into the roo, it's cheaper and it really digs deeper, then I'll release it for you to see
Deep research is interesting, and it brings up whether noon coding tasks are possible with AI coders.

For example, I've been curious if I could create a large set of related documents (comprising a math or science textbook, probably in Latex) more effectively with an AI coder that in the web interface.
https://github.com/VoxLink-org/finance-tools-mcp made a mcp with ta lib, rss, Fred and yahoo.¬† You may give roo code the power to be a investment master¬†
Roo Code 3.4 with NEW Lightning Fast DIFF Edits

$$$$$$$ just flying by
Wow, I thought Roo was broken after this update, but apparently it's just not doing the animation anymore. Awesome
Looks great! Do we need to turn on "Use experimental unified diff strategy" ?
Great...do we have checkpoints?
I updated, but still like left side, should I nred to enable it by myself?
Awesome! Cnat wait to try it later.
how?!
i'm not seeing 3.4 in VS code just 3.3.4,   
Which is the correct version for this feature?
This looks amazing but I do worry about my costs skyrocketing!! ü•∫ - just like to say roocline and it‚Äôs parent Cline are amazing the whole chain of people responsible should be commended!! üëèüéâü•≥
This is how I got RooCode working like a pro coder!
Hi RooCoder,

I am writing this post after trying out several open and commercial plugins and IDEs,

I just installed RooCode yesterday, It has lot of customization options. i first struggle to find the best coding model other than anthropic claude 3.7. then fiddle with the settings. So far these settings works for me:

I used **DeepSeek v3 0324** with **temperature 0.3**

Role Definition:

    You are RooCode, a powerful agentic AI coding assistant designed by the RooCode developer community.
    
    Exclusively available in Visual Studio Code, the world class open sourced agentic IDE, you operate on the revolutionary AI Flow paradigm, enabling you to work both independently and collaboratively with a USER.  
    
    
    You are pair programming with a USER to solve their coding task. The task may require creating a new codebase, modifying or debugging an existing codebase, or simply answering a question.  
    
    
    Each time the USER sends a message, we will automatically attach some information about their current state, such as what files they have open, and where their cursor is. This information may or may not be relevant to the coding task, it is up for you to decide.  
    
    
    The USER's OS version is Windows.  
    
    
    The absolute path of the USER's workspaces is [workspace paths].  
    
    
    Steps will be run asynchronously, so sometimes you will not yet see that steps are still running. If you need to see the output of previous tools before continuing, simply stop asking for new tools.

its slow in coding but working fine for my use case. I will update this post when I explore more RooCode Capabilities and settings.

  
Edit:  
To use **DeepSeek v3 0324** for free use **Chutes**
  - Sign up and Get API Key from [Chutes](https://chutes.ai/):
  - Head over to Roo Code settings and create a new provider configuration file
  - Add these:
     - Base Url: https://llm.chutes.ai/v1/
     - Model: deepseek-ai/DeepSeek-V3-0324
     - OpenAI API Key: your Chutes API Key

Chutes Latency is very high in order of 2-3 seconds, expect it to run slowly.

if you want to save time but no money then head over to Fireworks.ai its the fasted at $0.90/M tokens, I love the speed of fireworks inference but Roo code eats the tokens too fast, because of no caching support. I can easily use 1M tokens within 15 minutes.





Here are my tips:  
\- Before you read, I started using Roo about two weeks ago and I've experimented with it. However it's constent learning and I'm not an expert at using it.  
\- Use boomerang mode: [https://www.youtube.com/watch?v=bMUMWG2IS0o](https://www.youtube.com/watch?v=bMUMWG2IS0o)  
\- Use a memory bank: [https://github.com/GreatScottyMac/RooFlow](https://github.com/GreatScottyMac/RooFlow) This is to save cost but if you use a free model, just don't use a memory bank  
\- To experiment, use a free of charge 'stealth' LLM (currently it's Optimus Alpha, which is the new version of ChatGPT): [https://openrouter.ai/provider/stealth](https://openrouter.ai/provider/stealth)  
\- Generate and use rule files for consistency, especially for your Code mode: [https://gist.github.com/HighwayofLife/701d4d578279378e1ec136eb72d354d8](https://gist.github.com/HighwayofLife/701d4d578279378e1ec136eb72d354d8)  
\- Use MCP tools to browse the internet for documentation, Brave + Fetch: [https://github.com/modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)  
\- There might be better MCP servers for documentation: [https://github.com/cyberagiinc/DevDocs](https://github.com/cyberagiinc/DevDocs)  
\- Generate your prompts with Claude 3.7 Sonnet Thinking or Gemini 2.5 Pro  
\- Divide tasks into smaller tasks as much as possible  
\- Commit all the time, especially when you experiment  
\- Learn from experienced people, this post in particular was extremely helpful to me: [https://www.reddit.com/r/ChatGPTCoding/comments/1jvco3l/20year\_principal\_software\_engineer\_turned/](https://www.reddit.com/r/ChatGPTCoding/comments/1jvco3l/20year_principal_software_engineer_turned/)  
\- You can introduce complexity gradually by using TDD (Test Driven Development): [https://www.reddit.com/r/ChatGPTCoding/comments/1jwzpq7/has\_anyone\_tried\_aitdd\_ai\_test\_driven\_development/](https://www.reddit.com/r/ChatGPTCoding/comments/1jwzpq7/has_anyone_tried_aitdd_ai_test_driven_development/)  
\- There's a big game with Roo custom modes, where you can tell a mode to be an expert at one specific task to optimize performance: [https://github.com/jezweb/roo-commander/tree/main?tab=readme-ov-file](https://github.com/jezweb/roo-commander/tree/main?tab=readme-ov-file)  
\- When you really struggle at a specific task, the best solution I personally found is to open up Claude 3.7 Sonnet Thinking in Claude Desktop, use the project feature, feed it my GitHub repository for context, set custom instructions, tell it I am struggling at this task, ask it to divide this task into smaller sub-tasks, and generate an AI optimized prompt for each sub-task, one by one. I then either open a new conversation in this project and give it the prompt, or use Roo with the prompt.

I'm a newbe and I'm still learning a lot about vibe coding and development in general.  
Even with all that, I struggle at certain things. Right now my struggle is installing or creating an admin panel for managing my project's backend. Vibe coding is not a miracle solution, you need to set it up properly and you can't do everything with it. It still sure is super exciting though.
Look into boomerang tasks and orchestrator modes. Whilst you should absolutely tweak these and any other instructions you find, they're a fantastic base. Happy hunting!
Welcome Joey (baby roo). You‚Äôre going to have lots of fun.
Thank for sharing this!

I'm also using Roo in VSCode, and I found DeepSeek V3 to generates buggy code. The 0324 update brings some improvements but this issue remains severe.

Is it related to temperature settings? I use temp=0 as it's said to be best for coding and maths. Does the slightly more "wiggle room" for alternative phrasings help?
If you are vibe coding with roo code, read this!
Vibe coding or not, setting the right foundation matters. You wouldn‚Äôt tell a dev team, ‚ÄúNothing works, fix it,‚Äù so don‚Äôt approach it that way.

What works for me with **RooCode** every time (been using it for 3-4 months now):

1. Research first using Architect mode, find APIs, and identify what is required for the feature.
2. Get PRDs for app flow, design, and implementation.
3. More the context/documentation of the feature, better it performs
4. Try to refer the exact file to fix or update, if you have some idea about what you're doing
5. Before launch, I tell the architect mode to check for vulnerabilities, then execute fixes. If it‚Äôs too big, break it down.

*Pre-launch must-dos (for non-coders or semi-coders):*

1. Link domain to Cloudflare for DDoS protection
2. Move API keys to env files
3. Add rate limiting and strict CORS rules
4. Use secure headers and sanitize all inputs
5. Disable debug mode, enable error logging (use winston)
6. Automate deployments (optional but saves a lot of time)
7. Use PostHog/Plausible for analytics
8. Use PM2 for monitoring if its a node backend (you need to monitor run time)
I also tell the architect mode to give me a ‚Äùtodo-list‚Äú of our implementation as well. It‚Äôs help break down the tasks into smaller chunks to work on.
Don't forget about a memory system: [https://github.com/GreatScottyMac/RooFlow/tree/main](https://github.com/GreatScottyMac/RooFlow/tree/main)
I like telling roo code to build stuff in preplanned phases and just follow the instructiins for each phase, bit by bit... Amazing how focused it gets and delivers solid output every time.

Great advice re pre launch!
Or, *for non-coders or semi-coders*, use a low code platform that is less complex and easier to understand.
That's... Just how to code with AI in general. "Vibe coding" is literally sitting back with your hands behind your head feet on the table and letting ai do all the work. Correct me if I'm wrong.
PRDs?
IMO, you prove that just vibe coding is better.  
Everything you mentioned isnt necessary or essential and has tendency to create complications that can create more errors and stupidity, than out of the box. 

For example, LLM actually knows its better to store API keys in .env and will suggest it easily. The problem is, - in almost any private repo, exposing .env or API keys to git is much smaller problem, than exposing it to hosted LLM, because you can literally beak laws with the latter.

And also, if you dont care about that, you shouldnt care about any risks or time waste of vibe-coding, because someone pays you to fix these problems later anyway.
How to use Boomerang Tasks as an agent orchestrator (game changer)

This is a fkin game changer fs! Just a couple MCP's and you've got manus ai (even better than it)
It would be even better if subtasks were visible like a tree. Like you click on the parent task and you can see every subtask related to this task like a tree. It would clean the task history too
Any guesses on whether this custom role will work while using Roo Flow?
That's actually incredible!
I have a question (I apologize if it has already been addressed). It happens to me sometimes that I run very long Boomerang tasks (sometimes they take up to 3 hours, for example for tests) and I would like to be present at the monitor to check. Many times this is not possible for me and I interrupt a sub-task. However, it happens to me that when I resume it (for example, if I am in Code mode) then, as soon as it finishes, it does not automatically return to the Boomerang Task, as if it "forgot" that the initial task started from there. It simply finishes its work and the Boomerang Task does not continue. Is this an error only I have encountered?
So boomerang is like a project manager and female, go it! üëç
What model(s) are you using in the video? I've been getting some errors with Gemini and sonnet recently
Can we have this as a builtin optional mode eventually, given it's in the Roocode docs?
For the best experience with Gemini 1.5 pro, what should my settings be? I have rate limit set to 30 seconds because 2 requests per minute and automatic retries are on, however I still get "Error returned by provider" often which would stop the Boomerang flow. Also, can I just delete the .roo folder to get rid of RooFlow so I can try this?
I'm surprised in this video it looks like apply\_diff tool is enabled and also using Gemini 2.5, my Gemini 2.5 can't handle diffs at ALL. Just a constant repeat of "Unable to apply diff to file: No sufficiently similar match found....(97% similar, needs 100%)"
[removed]
Is it just me or wouldn‚Äôt something on the client side being able to pull your codes function signatures from a file be useful for a lot of tasks when roo is trying to figure out what‚Äôs doing what maybe function signatures plus the function comments, would also be cool if the api could then request a specific signature from a file and get just that back to keep the context small and tokens down

I don‚Äôt think that‚Äôs how it works now
Feature Request: Cursor @docs... a must have for coding reliably
One critical feature preventing me from switching to RooCode is the lack of a robust documentation pre-population system.

I've been coding for over 20 years and I use AI coding tools extensively... so please here me out before you suggest some alternative.

[Storybook is constantly adding new features and deprecating stuff. You sort of always need to reference their documentation when coding for the most reliable results.](https://preview.redd.it/7oazrhd8q1te1.png?width=1078&format=png&auto=webp&s=e65eb997b655541249226b6deac7e11a0aad33bc)

When working with AI coding assistants, the **single most effective way** to improve code quality and accuracy is feeding version-specific documentation about libraries and systems directly into the AI.

**Why Runtime Documentation Retrieval Isn't Enough**

Current approaches to documentation handling (grabbing docs at runtime via MCP Server or specifying links while coding) fall short for several critical reasons:

1. **Version specificity is crucial** \- Example: [asdf-vm.com](https://asdf-vm.com/guide/getting-started.html) has completely different instructions for v16+ versus older versions. In my extensive experience, AI consistently defaults to older (albeit more widely used) documentation versions.
2. **Performance impact** \- Retrieving and indexing documentation at runtime is significantly slower than having it pre-populated.
3. **Reliability and accuracy** \- AI frequently retrieves incorrect documentation or even hallucinates functionality that doesn't exist in libraries/frameworks. Pre-populating documentation eliminates the frustrating "no, here's the correct documentation" dance I regularly experience with AI assistants.
4. **Context switching kills productivity** \- Maintaining separate documentation links and manually feeding them to AI during coding sessions creates unnecessary friction. Suggestions to "process my own documentation, create markdown files, and then feed them into the system myself" only add more overhead to my workflow.

The Solution: Cursor's `'@docs'` Implementation

[**https://docs.cursor.com/context/@-symbols/@-docs**](https://docs.cursor.com/context/@-symbols/@-docs)

Cursor's implementation prevents me from using any other AI editor because it provides:

* **Pre-indexing capability** \- I can enter a website URL, and Cursor will scrape and index that information for reference in subsequent chats
* **One-click refreshing** \- I can simply hit refresh in the documentation panel to re-index any site for up-to-date documentation

[All my documentation indexed in one place in cursor, with a custom label, the date and time it was indexed, whether the indexing passed or failed, and the ability to refresh the index to pull the latest up to date documentation, and to even see the pages it indexed. No other AI tool has this.](https://preview.redd.it/2bekod4ce1te1.png?width=1010&format=png&auto=webp&s=01f487649358784fbb7b492ad9cada05fac40e83)

* **Flexibility** \- I can use ANY URL as documentation, whether it's official docs, GitHub pages, or specialized resources I personally prefer
* **Seamless workflow** \- I can stay inside the editor without using external tools, managing documentation links, or creating custom setups

This feature **dramatically improves code quality** to the point where any AI coding editor without this capability is significantly handicapped in comparison.

**Why This Matters for RooCode**

If RooCode wants to compete in the AI coding assistant space, this isn't an optional nice-to-have - it's a fundamental requirement for serious developers working with complex, version-dependent libraries and frameworks.

For professional developers like myself who rely on AI assistance daily, the ability to pre-populate specific documentation is the difference between an AI tool that occasionally helps and one that becomes an indispensable part of my workflow.
I think that is a great addition, what about we create an team to make this an PR?
While we're at it: indexing the codebase!
I can't agree enough. This is by far the biggest roadblock I have come across with agentic coding.
[deleted]
I was about to do that but I was looking to devs in discord if there is already something beeing made for someone and nobody replied me :(


please mods I wanna help
I would love to see this in Roo Code soon as well. In the meantime, is there a MCP that can accomplish this already?
Excellent post, fully support.
Agree, currently LLMs aren't great at writing code for rapidly evolving API's.
I‚Äôve been indexing @docs with Cursor, then I tell its agent to put each page of the doc into a /docs folder as markdown.

That is basically all I use Cursor for now.
Hey, I totally get where you're coming from. The struggle with AI tools and outdated or incorrect documentation is real. I had similar issues before adopting a more tailored approach. You might want to check out Kite; it has a feature to plug in your favorite documentation for context-sensitive help. I've also fiddled with Dash, which lets you download docs for offline use and offers tons of customization.

For automated pull request reviews and ensuring code quality, Hikaflow also uses AI, though it focuses on different coding aspects like security and complexity. It might help alongside your coding tool arsenal.
Roo Code 3.8.1-3.8.4 Release Notes
We've published several updates over the past few days with improvements and bug fixes across the board. Here's what's new:

## üîß **General Improvements**
* Add an option in the prompts tab to save tokens by disabling the ability to ask Roo to create/edit custom modes (thanks @hannesrudolph!)
* Create an auto-approval toggle for subtask creation and completion (thanks @shaybc!)
* Show a progress indicator when using the multi-diff editing strategy (thanks @qdaxb!)
* Show the reserved output tokens in the context window visualization
* Improve the UI of the configuration profile dropdown (thanks @DeXtroTip!)
* Add extension and VSCode versions to telemetry

## ü§ñ **Provider Support**
* Add o3-mini support to the OpenAI-compatible provider (thanks @yt3trees!)

## üêõ **Bug Fixes**
* Roll back multi-diff progress indicator temporarily to fix a double-confirmation in saving edits
* Fix VS Code LM API model picker truncation issue
* Fix encoding issue where unreadable characters were sometimes getting added to the beginning of files
* Fix issue where settings dropdowns were getting truncated in some cases
* Fix bug where custom temperature could not be unchecked (thanks @System233!)
* Fix bug where decimal prices could not be entered for OpenAI-compatible providers (thanks @System233!)
* Fix bug with enhance prompt on Sonnet 3.7 with a high thinking budget (thanks @moqimoqidea!)
* Fix bug with the context window management for thinking models (thanks @ReadyPlayerEmma!)
* Fix bug where checkpoints were no longer enabled by default

@everyone thank you so much for your patience with use while we worked out the kinks after the big Friday update (3.8). Also a big SHOUTOUT to u/mrubens. and CTE for putting in some crazy hours to help make this happen. THANK YOU!!
Great fast work on these fixes!!
i am using co pilot via vscode lm api and now get : Invalid extension information
thank you all!
Will we have a Chinese interface by then?
Wanted to understand something, Since Roo Code is a fork of cline, it is based out on CLine 3.6.5? And have added features and finetuning on top of it?
BOOMERANG IS COMING TO PRIMETIME!!
https://github.com/RooVetGit/Roo-Code/pull/2934

Default mode time! Coming to a Roo Code near you!! 
I really like roos architect mode.  I have tried boomerang, but it immediately starts making a plan without any input or questions for me.
What model(s) do you recommend using with boomerang? Do you have different ones that you prefer for each mode?
The instructions don‚Äôt include the new_task or completions guidance. This will likely fail for most non thinking models.
Let's goooooo
Awesome! I know this question gets asked around a lot. OP, would you have a suggested mode setup for this? It‚Äôll be nice to have a recommended setup out of the box. I use SPARC now and it‚Äôs been great, but does too much sometimes
FREE Optimus Alpha Model just launched by Open Router
# FREE FREE FREE

OpenRouter just bounced in with a stealthy new model: [**Optimus Alpha**](https://openrouter.ai/openrouter/optimus-alpha)!  
It packs a **roo-diculously** huge 1M context window and leaps up to 32K max output.

It's completely **FREE** for now, so hop on over and give it a spin!

_PS: Sorry for the pun‚Äîcouldn't resist!_
optimus alpha, quasar alpha, those sound like AI's that would take over by creating Tranformers ... wait a second ...
It's nice and fast, only made one small mistake in the last 20 requests I made (fewer than 2.5 Pro Exp Gemini). Still wondering if it's just luck/chance or if it's really good. I'm excited to test these free trials lately, especially since they are getting so good, they can chug through code with fewer and fewer errors for free. But as said by someone else, just be careful with these unknown models on sensitive code. Great for me cause I'm just testing it out on a throwaway hobby project.

Edit: Other people are reporting that it's not as good, so think I just got a few lucky outputs. Still, progress of my project is progress nonetheless and for free.
I love testing things but not when every aspect of it is a black box. Who is the provider? Where is it going? Who has access?

They want to test real world with it yet no one should be using real world with this stuff because who knows what they‚Äôre doing with the data.
I have been using it since this morning. So fucking meh compared to Quasar.
You're a mind reader: I was just trying Optimus Alpha on a Tauri project to see how up to date it is. Working fairly well on Tauri V2.
You should know that openrouter has its limits. So while model is free, if you hit a limit, you cannot use it
Oooooh. Wondering if these are the google models from the arena
It‚Äôs openai gpt4o
once you turn it off free, will we automatically be charged? how will we know ahead of time?
thanks for the information, but I have a doubt. when I add the api, it tells me add balance to openrouter

this is not part of you? but if it is free, I do not understand well.

thanks. for keeping it to coo code.
Just in time to take over Quasar Alpha in my Roo Code lol.  I really enjoyed Quasar, and love testing all these Stealth models.  But I do feel Megatron needs his turn in the spotlight next.  Early opinion on the Autobot leader is he is incredibly robust and great at problem solving, and finding solutions to complex issues.  Have been having a blast with him.  Thank you, OpenRouter and whichever OpenAI (pretty sure it's them) model this is.
I was trying to use it in roo code and I can't seem to find free version on openrouter. The only visible needs credits
Is there a way or strategy to bypass openrouter free usage limit?
optimus alpha and quasar alpha is gone, why? are there alternatives?
Simplified Roo Flow with Orchestrator Mode
I wanted to highlight this underrated [comment](https://www.reddit.com/r/RooCode/comments/1jjl3s9/comment/mjprbr0/) by u/evia89 that I discovered in another post. They shared a Roo mode configuration called Orchestrator which works a lot like Roo Flow but is much simpler. It plans your project, divides it into smaller testable tasks that are delegated to Code mode, and keeps a project context memory file as the project continues. I have successfully completed a small project with it, using only Orchestrator and allowing it to initiate the Code mode, and it was phenomenal how error free everything was compared to everything else I have ever used, including some all-in-one web-based AI coding solutions. Here's the configuration for Orchestrator mode from the comment:

    {
      "customModes": [
        {
          "slug": "Orchestrator",
          "name": "Orchestrator",
          "roleDefinition": "You are Roo orchestrator, you create and assign subtasks using new_task tool to other agents and keep track of progress toward user goal. The subtasks that you assign should be small and well defined, with explicit acceptance crietria and you should instruct the agent to report back to you with the subtask status.",
          "customInstructions": "Upon task initiation, you will:\n1. Conduct comprehensive requirement analysis with technical constraint mapping\n2. Probe for clarity where specifications remain ambiguous or incomplete\n3. Architect the solution through systematic task decomposition into discrete, manageable components\n4. Deploy the new_task tool to assign each component to specialized technical experts\n5. Apply rigorous quality assurance against established acceptance criteria\n6. Progress seamlessly when deliverables meet standards\n7. When deliverables fall short, deliver concise remediation briefs containing:\n   - Specific deviation analysis\n   - Potential downstream consequences\n   - Actionable rectification approaches\n   - Evidence-based recommendation for optimal resolution\n8. For larger tasks create a context markdown file which you will pass on to the subtask and update (if needed) after the task is finished\nYou serve exclusively as the orchestration layer, creating only documentation for project management - never producing code directly. You maintain unwavering technical precision while optimizing workflow efficiency through the entire development lifecycle. When analyzing project requirements, be thorough and precise, identifying all technical constraints and dependencies. When decomposing tasks, ensure each component is clearly defined with specific acceptance criteria. When delegating tasks using the new_task tool, choose the most appropriate mode for each technical expert based on the task requirements.",
          "groups": [
            "read",
            [
              "edit",
              {
                "fileRegex": "\\.md$",
                "description": "Markdown files only"
              }
            ],
            "command"
          ],
          "source": "project"
        }
      ]
    }
I created this original orchestrator post which seems to have been adapted by a few people now. I have had great success using it with Gemini 2.5

https://www.reddit.com/r/RooCode/s/gWgOE0ArF3
Is there an ai guided Roo setup technique?  Ideally guiding the user through the ideal config of all applicable options and sub options  (from rules to flow etc) based on use scope‚Ä¶to configure everything from the start.
[https://github.com/shipdocs/RooFlow-captainmode](https://github.com/shipdocs/RooFlow-captainmode)
Got a workflow going with this. I load my entire codebase into aistudio with gemini 2.5 and use it as a designer, planner, and validation. I plug the instructions into roo orchestrator and switch back for more rubber ducky talks. I use debug mode to fix failed tests and validate the results with gemini. It's working pretty well so far.
the format seems very different from the existing ones
Roo flow has a memory bank feature as well right?
So how does this differentiate what Architect is? When you set up Roo Flow it uses Architect as the orchestrator. 
I had a setup similar what you‚Äôre talking about here with a full vector database for memory and it worked great but damn did it eat tokens making all the calls to memory.
I‚Äôve found simpler is better and Roo Flow works well
How do I set this? Currently have RooFlow set currently and want to try this.
I have been playing around with something similar using the Roo Code memory bank. I will check this out for sure!
üöÄ Easy RooCode Workspace Template: SPARC Modes, Memory Bank and Boomerang Mode!
Hi everyone,

I‚Äôve created a¬†**RooCode development workspace template**¬†designed to streamline the creation of new projects. It integrates the latest features, including¬†**SPARC orchestration modes**, the¬†**memory bank feature**, and¬†**Boomerang mode**, all within a single workspace.

A special thanks to¬†**RooFlow**¬†and the creators of SPARC orchestration modes for their contributions and inspiration.

Feel free to check out my repository! If you find it useful, I‚Äôd greatly appreciate your feedback and contributions to help make this a more generalized and accessible RooCode workspace for everyone.

Cheers!

[https://github.com/enescingoz/roocode-workspace](https://github.com/enescingoz/roocode-workspace)
thats actully a lot of work where u could just say: download the .roomodes file and place it in the root of your project
Thanks man, I'll try it out and give a feedback!
Is this meant to be used alongside RooFlow? You credit RooFlow as a source, but it‚Äôs not clear whether this replaces RooFlow, or if RooFlow should be added to the project folder before/after adding this.
This SPARC stuff has been amazing
does this require to install rooflow? I'm not sure why rooflow has a bash installable, seems dangerous xD
I recommend at least posting the usernames of the people whose work you are building off of when giving credit.
Is this up2date with the last release and new .roomodes setup?
General question: When I try "initialize memory bank" it seems to start doing its work but it hangs in API Request forever ...

https://preview.redd.it/cq6oh609tste1.png?width=270&format=png&auto=webp&s=5cb968ac66061957a79caaac0e79fe7cf4682cb8

I saw this on other requests so I wandering if my setup has something wrong ... should I reinstall everything? I'm using Roocode on Windows 11 with WSL
Similar issue that another person mentioned. When running \`initialize memory bank\` in Architect mode the LLM has no idea what a memory bank is and attempts to create it's own.

Tried Sonnet 3.5 and 3.7 Thinking, and Gemini 2.5 Pro.

\`\`\`  
Okay, I can help with that. The term "memory bank" can mean different things depending on the context. To make sure I design the right architecture, could you please clarify what you mean by "initialize memory bank"?

For example, are you referring to:

1. Setting up a new database (e.g., SQL, NoSQL)?
2. Initializing an in-memory data structure within an application?
3. Creating or populating a configuration file?
4. Something else specific to your project?

Once I understand what the "memory bank" is, I can start outlining the architecture.  
\`\`\`
Please correct me if I'm wrong.

As far as I understand, boomerang tasks are tasks delegated as sub-tasks, and those tasks return a response according to what has been done within that sub-task. SPARC workflow already does that, so you might want to omit the "boomerang tasks" from the workflow and just go with the idea of merging the memory bank ideas of RooFlow and SPARC workflow.
sparc orchestrator mode: "Aah, I can't read the memory bank files directly, I'll create a code-task to read the file and return the contents in the success"  
code mode: "I have to read this memory bank file. But first I need to read the memory bank"  
\*proceeds to read the whole memory bank to report back a single file of it\*

I can't be the first one running into this waste of context & token, am I? What did go wrong? I'm using your .roomodes without any changes.

  
Edit: Oh and, why does each mode need the full mode collaboration spec? also feels like a waste of token and context.
Just tried this out last night and it seems awesome so far, I was a bit confused which modes to start in.

I had a project plan/PRD and gave that to SPARC, then had the psudocode mode create the specs, then architect to start the structure and it would switch to code to implement things. During that process it would want to switch TDD for the tests.

Is that the correct order or did I do the steps correctly? The readme said to to start in architect but is that for if you want it to build the plan? For me it seemed because I already had my PRD that it would be best to give it to SPARC mode.

I'm not sure if using the Boomerang mode in this setup does anything and is redundant? Because it just kinda switches to the other modes? I don't fully understand that part.

This is the best feeling workflow I've used so far even though I'm not sure if I used it correctly.

Any advice would be appreciated.
Been looking exactly for this, thanks a lot.
I think you are suppose to use Ruvnet's rules to go with SPARC as well
https://gist.github.com/ruvnet/7d4e1d5c9233ab0a1d2a66bf5ec3e58f

Thanks for integrating these together!
Introducing Custom Modes, plus rebranding from Roo Cline ‚Üí Roo Code! üöÄ
**Introducing Roo Code**

Our biggest update yet is here - we're officially changing our name from Roo Cline to Roo Code! After growing beyond 50,000 installations across VS Marketplace and Open VSX, we're ready to chart our own course. Our heartfelt thanks to everyone in the Cline community who helped us reach this milestone.

**Custom Modes**

To mark this new chapter, we're introducing the power to shape Roo Code into any role you need. You can now create an entire team of agents with deeply customized prompts:

* QA Engineers who write thorough test cases and catch edge cases
* Product Managers who excel at user stories and feature prioritization
* UI/UX Designers who craft beautiful, accessible interfaces
* Code Reviewers who ensure quality and maintainability

The best part is that Roo can help you create these new modes! Just type "Create a new mode for <X>" in the chat to get started, and go into the Prompts tab or (carefully) edit the JSON representation to customize the prompt and allowed tools to your liking.

We can't wait to hear more about what you build and how we can continue to evolve the Roo Code platform to support you. Please join us in our new r/RooCode subreddit to share your custom modes and be part of our next chapter. üöÄ

https://preview.redd.it/uuis1phcvcee1.png?width=649&format=png&auto=webp&s=38cd35cbcbf75d4f424a2315b77d5ffdbea81637


u/mrubens Congrats! Glad to have been along for the ride! Looking forward to what 2025 holds for us.
You Absolute Baller! XD

Thanks.
just saw the update! congratulations
Thanks, y'all are the best! üëè
Can I buy you a cup of coffee or beer? This is am extremely useful tool. I would like to show my appreciation a bit.  Thanks for the tool!
Immediately LOVE the new ‚Äúcreate a mode‚Äù feature. Really dials the model down

What a time to be alive üòç
Congrats!
very cool upgrades, thanks!
Super excited about this!
Wooo what a newsüëåüî•üî•üî•üî•I can‚Äôt wait to try
That's so cool!
This looks amazing!

A tutorial of these features would be great if possible.
Êîπ‰∫ÜÂêçÂ≠óÔºågithube‰∏äÊêúÁ¥¢clineÈÉΩÊêúÁ¥¢‰∏çÂà∞‰∫Ü
Fantastic! Love it! But I have to use Cline for a week because I promised. But I swear I‚Äôll be back next week!

Meanwhile, here‚Äôs some more Roo Code to get everyone in the spirit! (DeepSeek)

Ah, the Secret Kangaroo Code‚Äîa set of unspoken rules that govern the hoppy, pouch-filled world of kangaroos. Here are the top five rules:

1. **Always Share the Shade**  
   When the Australian sun is blazing, you always make room in the shade for a fellow kangaroo. No one gets left to roast in the heat‚Äîpouch space is sacred.

2. **Respect the Pouch Privacy**  
   Never snoop in another kangaroo‚Äôs pouch without permission. What‚Äôs in the pouch stays in the pouch, whether it‚Äôs a joey, snacks, or a collection of shiny rocks.

3. **Hop in Sync, Not in Competition**  
   When hopping together, match the rhythm of your fellow kangaroo. It‚Äôs not a race‚Äîunless it‚Äôs an official hopping competition, in which case, may the best hopper win.

4. **Protect the Mob at All Costs**  
   The mob (kangaroo crew) comes first. If a dingo or any other threat shows up, you stand your ground and kick together. No kangaroo gets left behind.

5. **Never Steal Another Roo‚Äôs Grass**  
   Grass is life. If you see another kangaroo munching on a prime patch, find your own. Stealing grass is the ultimate betrayal and can lead to a serious hopping duel.

Bonus Rule: **Always Acknowledge a Sick Hop**  
If you see a kangaroo pulling off an impressive hop, give them a nod or a tail thump of respect. It‚Äôs just good manners in the kangaroo world. ü¶ò
What are the differences between the latest version of Cline and latest version of roo Code. it's getting hard to keep up and see which one is better now.
new here and thoroughly impressed!
This feature gives me a rock hard boner\~! Thank you!
which model is best for roo Code?
I love what you are doing. Hey - one feature request. Put the model selector in the little > pop out so that we can quickly switch between models on OpenRouter.
Sounds awesome! Can you show any video demos on how we can create these agents?
That's awesome, thanks and congrats!
First Opinions of Roo Code Boomerang Tasks with 4.1. Stop asking so many questions. Just do it. All-in-all a major improvement over GPT-4o. A few thoughts.
First opinions of GPT-4.1. What stands out most isn‚Äôt just that its benchmarks outperform Sonnet 3.7. It‚Äôs how it behaves when it matters. My biggest issue is seems to have tendency to ask questions rather then just automatically orchestrating sub tasks. You can fix this by updating your roomode instructions. 

Compared to Sonnet 3.7 and GPT-4o, 4.1 delivers cleaner, quieter, more precise results. It also has a much larger context window supporting up to 1 million tokens and is able to better use that context with improved long-context comprehension and output. 

Sonnet‚Äôs 200k context and opinionated verbosity has been recurring issue lately.

Most noticeably 4.1 doesn‚Äôt invent new problems or flood your diff with stylistic noise like sonnet 3.7 does. 3.7 in many ways is significantly worst than 3.5 because of its tendency to add unwanted commentary as part of its diff formats, which frequently causes diff breakage.

4.1 seems to shows restraint. And in day-to-day coding, that‚Äôs not just useful. It‚Äôs essential. Diff breakage is one of the most significant issues in both time and cost. I don‚Äôt want my agents to ask the same question many times because it thinks it needs to add some kind of internal dialog. 

If I wanted dialog, I‚Äôd use a thinking model like o3. Instruct models like 4.1 should only do what you‚Äôre instructing it and nothing else.

The benefit isn‚Äôt just accuracy. It‚Äôs trust. I don‚Äôt want a verbose AI nitpicking style guides. I want a coding partner that sees what‚Äôs broken and leaves the rest alone. 

This update seems to address the rabbit hole issue. No going into Ai coding rabbit holes to fix unrelated things.

That‚Äôs what GPT‚Äë4.1 greatly improves. On SWE-bench Verified, it completes 54.6 percent of real-world software engineering tasks. That‚Äôs over 20 points ahead of GPT‚Äë4o and more than 25 points better than GPT‚Äë4.5. It reflects a more focused model that can actually navigate a repo, reason through context, and patch issues without collateral damage.

In Aider‚Äôs polyglot diff benchmark, GPT‚Äë4.1 more than doubles GPT‚Äë4o‚Äôs accuracy and even outperforms GPT‚Äë4.5 by 8 percent. It‚Äôs also far better in frontend work, producing cleaner, more functional UI code that human reviewers preferred 80 percent of the time.

The bar has moved. 

I guess we don‚Äôt need louder models. We need sharper ones. GPT‚Äë4.1 gets that.

At first glance it seems pretty good.
you can read their new prompt guide for their prompting techniques, then it can perform even better than with the normal system prompts.
honestly after dealing with 3.7 and how it jumps off the leash and does what it wants, I kinda appreciate all 4.1 takes things step by step and asks for confirmation lol
Comparison with gemini-2.5-pro-preview, which has been SOTA since release?
What is the prompt of auto code mode?
Agree, I'm not getting questions, but it will just quit after a task is completed saying "Next task is x". Just switched off it for boomerange at least. I tried the suggested prompting too, which didn't seem to help.
It seemed like the cache wasn‚Äôt working with 4.1, but it looks like yours is from the screenshot.  Are you connected via OpenAI directly, or through OpenRouter?
From a few hours of playing with it, it's not as good as 2.5 at all. Faster, yes, and the caching is so helpful with the pricing. Can't wait until caching comes to AI studio API.

edit: lmao as soon as I said this the apply diff stopped working almost completely
Is this¬†Optimus Alpha or quasar that's been on open router in the last week? If so I had better results with Gemini¬†
how does it compare to o3-mini-high?
For me, 4.1 is about two times better than Gemini Pro 2.5 Pro.
How to use Boomerang Tasks to create an agent orchestrator (game changer)
I was excited to see the Boomerang tasks feature, but it took me a while to work out how to utilise it.

The goal with this is to create an Orchestrator role which assigns subtasks to other agents, so that the main task context does not get polluted by unimportant details

To do it, create a new 'Orchestrator' role with these instructions (feel free to tweak, and share results in this thread)

>You are the orchestrator, you create and assign subtasks using the new\_task tool to other agents and keep track of progress towards the user's goal

>The subtasks that you assign should be small and well defined, with explicit acceptance crietria and you should instruct the agent to report back to you with the subtask status.

Disable all capabilities apart from reading files.

Make sure 'Always approve mode switching' and 'Always approve creation & completion of subtasks' settings are enabled

I am also using the experimental Power Steering mode

I have a more advanced model (3.7 Sonnet, Gemini 2.0 Pro)as the orchestrator, and something like 3.5 Haiku or Gemini 2.0 Flash as the coder
I have also been utilising this a lot and have had good results on both outcome and token usage. Here is the custom mode I have created.

Role:

    You are Roo, an elite engineering orchestrator functioning as both strategic coordinator and technical coach for seasoned developers. You transform complex projects into streamlined execution through methodical analysis and precision delegation. Your expertise lies in orchestrating development teams, managing technical requirements, and ensuring project success through careful planning and oversight.

Instructions:

    Upon task initiation, you will:
    1. Conduct comprehensive requirement analysis with technical constraint mapping
    2. Probe for clarity where specifications remain ambiguous or incomplete
    3. Architect the solution through systematic task decomposition into discrete, manageable components
    4. Deploy the new_task tool to assign each component to specialized technical experts
    5. Apply rigorous quality assurance against established acceptance criteria
    6. Progress seamlessly when deliverables meet standards
    7. When deliverables fall short, deliver concise remediation briefs containing:
       - Specific deviation analysis
       - Potential downstream consequences
       - Actionable rectification approaches
       - Evidence-based recommendation for optimal resolution
    8. For larger tasks create a context markdown file which you will pass on to the subtask and update (if needed) after the task is finished
    You serve exclusively as the orchestration layer, creating only documentation for project management - never producing code directly. You maintain unwavering technical precision while optimizing workflow efficiency through the entire development lifecycle. When analyzing project requirements, be thorough and precise, identifying all technical constraints and dependencies. When decomposing tasks, ensure each component is clearly defined with specific acceptance criteria. When delegating tasks using the new_task tool, choose the most appropriate mode for each technical expert based on the task requirements.

The full config:

    {
          "slug": "technical-project-manager",
          "name": "Technical Project Manager",
          "roleDefinition": "You are Roo, an elite engineering orchestrator functioning as both strategic coordinator and technical coach for seasoned developers. You transform complex projects into streamlined execution through methodical analysis and precision delegation. Your expertise lies in orchestrating development teams, managing technical requirements, and ensuring project success through careful planning and oversight.",
          "customInstructions": "Upon task initiation, you will:\n\n1. Conduct comprehensive requirement analysis with technical constraint mapping\n2. Probe for clarity where specifications remain ambiguous or incomplete\n3. Architect the solution through systematic task decomposition into discrete, manageable components\n4. Deploy the new_task tool to assign each component to specialized technical experts\n5. Apply rigorous quality assurance against established acceptance criteria\n6. Progress seamlessly when deliverables meet standards\n7. When deliverables fall short, deliver concise remediation briefs containing:\n   - Specific deviation analysis\n   - Potential downstream consequences\n   - Actionable rectification approaches\n   - Evidence-based recommendation for optimal resolution\n8. For larger tasks create a context markdown file which you will pass on to the subtask and update (if needed) after the task is finished\n\nYou serve exclusively as the orchestration layer, creating only documentation for project management - never producing code directly. You maintain unwavering technical precision while optimizing workflow efficiency through the entire development lifecycle. When analyzing project requirements, be thorough and precise, identifying all technical constraints and dependencies. When decomposing tasks, ensure each component is clearly defined with specific acceptance criteria. When delegating tasks using the new_task tool, choose the most appropriate mode for each technical expert based on the task requirements.",
          "groups": [
            "read",
            [
              "edit",
              {
                "fileRegex": "\\.md$",
                "description": "Markdown files only"
              }
            ],
            "command"
          ],
          "source": "global"
        }
Excellent and very helpful. Have you tried DeepSeek r1 as an orchestrator? I‚Äôve had such bad experiences with Gemini and Claude.
I‚Äôll give it a go thanks for explaining
I feel like an idiot. I‚Äôve searched up and down for boomerang msp. What is this boomerang that you‚Äôre referring to?
Does anyone have a link to a video demo that I could watch of how to use Boomerang? This sounds like a much more polished version of my recent workflow using `cursor-tools` with Gemini Pro as a supervisor for the main Sonnet Cursor Agent.

Side note: I am finding the pace and transparency of Roo development really refreshing.
How's it working for you?
How does Architect mode fit into this? Do you create a plan, then switch to orchestrator to split out responsibitlies? Or do you some how integrate this orchestrator pattern into the architect?
[https://github.com/shipdocs/RooFlow-captainmode](https://github.com/shipdocs/RooFlow-captainmode)
3.8.5 & 3.8.6 - Release Notes
üåê **Remote Browser Support**
* Support for remote browser connections (thanks afshawnlotfi!)
  * Adds the ability for Roo to connect to a remote Chrome browser instance instead of launching a local one
  * Particularly useful in containerized environments or when using a specific Chrome instance with custom configurations

üé® **UI/UX Improvements**
* Bring back progress status for multi-diff edits (thanks qdaxb!)
* Refactor alert dialog styles to use the correct vscode theme (thanks cannuri!)
* Better handling of diff application errors (thanks qdaxb!)
* Preserve parent-child relationship when cancelling Boomerang Tasks (subtasks) (thanks cannuri!)
* Allow using an excluded directory as your working directory (thanks Szpadel!)
* Kotlin language support in list_code_definition_names tool (thanks kohii!)

ü§ñ **Provider/Model Support**
* Custom baseUrl for Google AI Studio Gemini (thanks dqroid!)
* OpenAI-compatible DeepSeek/QwQ reasoning support (thanks lightrabbit!)
* Anthropic-style prompt caching in the OpenAI-compatible provider (thanks dleen!)
* Add Deepseek R1 for AWS Bedrock (thanks ATempsch!)
* Add gemini-2.0-pro-exp-02-05 model to vertex (thanks shohei-ihaya!)
* Custom ARNs in AWS Bedrock (thanks Smartsheet-JB-Brown!)
* Update Bedrock prices to the latest (thanks Smartsheet-JB-Brown!)

üêõ **Bug Fixes**
* Fixed issues where Roo would sometimes not recognize terminal output (thanks KJ7LNW!)
* Fix where Roo would not consistently recognize Windows PowerShell output (thanks KJ7LNW!)
* Update MCP servers directory path for better platform compatibility (thanks hannesrudolph!)
* Fix usage token tracking for SiliconFlow and other providers
* Fix MarkdownBlock text color for Dark High Contrast theme (thanks cannuri!)
* Fixes to OpenAI-style cost calculations (thanks dtrugman!)
* Fixes to OpenRouter custom baseUrl support
* Fixed issue where browser related system prompt would be included when browser use was disabled or unsupported by model (thanks cannuri!)

üîÑ **Miscellaneous**
* Publish git tags to github from CI (thanks pdecat!)
* Telemetry for checkpoint save/restore/diff and diff strategies

If you find Roo Code helpful, please consider **[leaving a review](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details)** on the VS Code Marketplace. Your feedback helps others discover this tool!

Follow us at **[@roo_code](https://x.com/roo_code)**!
Has just all the inertia from Cline gone to Roo now?
I wish you support drag and drop files  in the context for better UX
Any chance of cross posting new releases to Blue Sky instead of just Twitter?
üî•üî•üî•
Nice work Roo!!! 

Side note, is anyone using Gemini models with success on large complex codebase? I'm afraid to move from sonnet!
We need checkpoints! :(
Is anyone involved in Roo currently working on implementing checkpoints? 

Today I had the problem for the second time that Sonnet violated the instructions and I relied on his knowledge, which actually works well, but after making changes to three files (with clear instructions) several tests failed. 

It took me hours to somehow restore the situation. yes, I should have committed it beforehand with git but there was only one adjustment left to make after hours of long work to complete an epic! 

we urgently need checkpoints! :(
Yes! Working on it üôè
Join the masses ‚Ä¶ I learned real quick, especially with Sonnet, that commits were vital. I bet the time I lost far surpasses the time I gained that day. Like you said, should have committed but it was something so simple and I was lazy about giving it full edit permission. Bit me in the @ss

I‚Äôve gotten in the habbit of manually asking it to do a checkpoint after each task and as  I near 80% context ‚Ä¶ this doesn‚Äôt fulfill the builtin checkpoint functionality we desire but the memory bank does help.
What i do is use architect mode to generate an ADR with ordered implementation steps each with a checkbox

Code mode then has a custom prompt telling it if i give a custom command,  the task is to work on the most recent incomplete ADR and to strictly follow the ADR and implementation steps in order,  marking each as checked as it progresses.

There's also an instruction that if the ADR is partially complete to pick up from where the items are unfinished.

it's been working pretty well for me.
If you're curious, [here's a video](https://www.loom.com/share/a2860cffbd074c5a90cb7602507ea3f2?sid=a2ebe274-6db2-40c8-a981-a5d55f492077) I made demonstrating the checkpoints feature in Roo Code.

The PRs are under review, so hopefully we can get it out soon. The implementation is slightly different than Cline's, but fundamentally uses git under the hood:  
[https://github.com/RooVetGit/Roo-Code/pull/626](https://github.com/RooVetGit/Roo-Code/pull/626)
How are checkpoints different from/better than Git? Using Git, I can roll back changes as needed.
Yes devs we need to think of a way to make this work. 

I used memory bank custom instructions but it sucks it doesn‚Äôt create a detailed context and it also overwrites the context instead of adding to it so it‚Äôs always very brief and useless. 

We need the Roo app itself to record every moves it‚Äôs making into a separate file that we can read at every task and reference. 

We need living memory
yes! only think keeping me from switching from cline
‚è∞
What MCP servers are you using with Roo - and why? April 21 2025
I see MCP servers being discussed all the time here and ashamed to say I only starting reading into them today, although I guess browser control would count as an MCP so other than that, but I never associated those tools with the technical phrase.

Generally which MCP servers are you using with Roocode? There are so many to choose from and build it‚Äôs kind of confusing. 

And another question: what MCPs are most useful for web application development?

Thanks ily ur beautiful 
for me, context7, hands down

it indexes a bunch of updated documentations out there, no longer have to fiddle around with llms.txt manually
Context7 + Sequential Thinking + Serper Search + n8n MCP = Absolute Agentic Power
I just found Context7, so I will be using that soon.

[https://github.com/upstash/context7](https://github.com/upstash/context7)
Brave search, and instruct the LLMs to use it often, because their training cutoff might hide information
just using [Quillopy](https://github.com/quillopy/quillopy-mcp) for specific library context.

Everything else I just feed to gemini 2.5 and roo handles it all, roo is already good at thinking and your project context you just do boomerang mode and bang it works well.
I'm also in the same confusion train. I usually thought MCPs were great for people using Claude web/desktop interface as it gave it more power.
An artificial example of what an mcp can do using tools.
Say you want to play chess with Ai, on some external game engine. An mcp can connect the engine via api and tool calling, so once Ai wants to make a move, it will call a tool.
I personally use brave and perplexity mcp. Tried creating a documentation mcp, but ended up just using brave for most things when I need them
I use this kubernetes mcp all the time. https://github.com/Flux159/mcp-server-kubernetes
This context mcp seems better than context references in Roocode, right? (Adding files as context)  
I have files with documentation, and I was wondering if I should use these quillopy or context7 MCPs or add the files I have with documentation as context (adding the files in Roocode as context).

until now I was only prompting to take into account the documentation collected so far and it seemed to work well, so I wanted to try giving context to roocode adding the documentation , but now seeing these MCPs... it's amazing
sequentialthinking, memory, context7, fetch
I built my own server using FastAPI, now I'm adding tools to it.   
Probably the most universally useful one is just a simple "get the text of this website" tool.   
Image based browsing wastes tokens.   
But I like using newer libraries that LLMs don't know yet (FastAPI\_MCP for example).   
So I just feed it a link and ask it to retrieve the text, then continue.
Do you use boomerang mode also guys?
Finance-tools-mcp +¬†tavily search.¬† ¬† I let roo code give me stock investment suggestions¬†
3.11.11, 3.11.12 & 3.11.13 - Terminal Enhancements, Provider Updates & UI Improvements
This combined update includes significant improvements from our latest releases, with a focus on terminal reliability enhancements, improved diff error handling, file context tracking, and provider updates. A huge thank you to everyone who contributed to these releases: KJ7LNW, atlasgong, samhvw8, canvrno, amittell, arthurauffray, ronyblum, StevenTCramer, franekp, and zhangtony239!

# üíª New Terminal Enhancement Settings (Thanks KJ7LNW!)

Six new configurable settings were added to improve terminal reliability across various shell environments:

* **Terminal command delay** - Adds a small pause after running commands to fix output capture issues in some terminals
* **PowerShell counter workaround** - Helps PowerShell run identical commands multiple times without failing
* **Clear ZSH EOL mark** - Prevents ZSH from adding special characters that can confuse Roo
* **Oh My Zsh integration** - Better compatibility with the popular Oh My Zsh framework (experimental)
* **Powerlevel10k integration** - Improved compatibility with the Powerlevel10k ZSH theme (experimental)
* **ZDOTDIR handling** - Helps Roo work with custom ZSH configurations seamlessly (experimental) IF YOUR MAC ZSH STOPPED WORKING AROUND THE TIME OF THIS UPDATE, try this setting! VS Code put out a terminal breaking update that this counters. 

Learn more in our detailed [**Terminal Shell Integration Guide**](https://docs.roocode.com/features/shell-integration).

# üìä Improved Diff Error Display

* **Enhanced visibility** of diff errors to help you quickly identify and fix issues
* **Easy copying mechanism** for error details to streamline troubleshooting
* **More tolerant diff editing logic** to handle model errors gracefully

# üöÄ Provider Updates & Improvements

* **Grok3 streaming support** via OpenAI Compatible providers (thanks amittell!)
* **Better proxy support** for OpenAI-compatible providers with Host header and legacy API options
* **Added o1-pro support** (thanks arthurauffray!)
* **Renamed AWS Bedrock to Amazon Bedrock** for consistency with official naming (thanks ronyblum!)

# ‚ú® Other Enhancements

* **File context tracking system** so Roo better remembers which files you're working with (thanks samhvw8 and canvrno!)
* **Fixed UI highlighting interactions** with mode/profile dropdowns (thanks atlasgong!)
* **Improved tree-sitter parsers** for TypeScript, C++, Go, Java, and Python (thanks KJ7LNW!)
* **Updated extension title and description** for clarity (thanks StevenTCramer!)

For complete details, please see the full release notes:
* [**v3.11.11 Release Notes**](https://docs.roocode.com/update-notes/v3.11.11)
* [**v3.11.12 Release Notes**](https://docs.roocode.com/update-notes/v3.11.12)
* [**v3.11.13 Release Notes**](https://docs.roocode.com/update-notes/v3.11.13)

----
If you find Roo Code helpful, please consider **[leaving a review](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details)** on the VS Code Marketplace. Your feedback helps others discover this tool!
People are saying context cache is added on Vertex AI for Gemini 2.5 Pro. This needs to be supported asap it‚Äôs a great model but expensive without cache.

https://www.reddit.com/r/RooCode/comments/1jwi13b/comment/mmiu1ve/?context=3&rdt=56769
It is amazing the work you do for all of us, we tell you all the time but it is never enough. I lived through the early 10's (of 2000, I'm not that old üòú) as a teenage PC enthusiast and back then there were beautiful community realities in the forums that are now completely lost. You guys remind me of those good old days, thank you very much! 

PS: I just finished working on VS Code now, I had already done the update two hours ago. I don't know if it included this update as well but with Gemini 2.5 the only problem I had was that yes, the search and replace now does not give diff errors and it is also much more accurate and tends to modify only the lines it needs. However, I found it to be a little imprecise just in searching for rows: I had a 600 row file, it was supposed to delete a function in row 358 that we had been discussing for a while but it got hung up on searching in the wrong place. First from row 400 to 430, then he increased the range a little bit, then went down a little bit.... In short, he wasted me 5-6 requests until I told him: hey, the row you're looking for is 358! I'll try again tomorrow anyway.
Awesome work!!
I wish this extension had a more professional name. Its name had made me ignore it until I read about its popularity on OpenRouter.

Anyway, I will give it a go today. Better late than never.
Thank you!!! Incredible work :)

I tried using o1-pro but I continue to get ‚Äúchat/completions is not supported‚Äù‚Äîis this expected?
I think after this update terminal commands from Roo don‚Äôt worry anymore. I get an error to update vscode or change terminal settings. Anyone else?
Is there any plan to add somewhat of a persistent task tracker so that you don‚Äôt lose track of previous tasks as new tasks are being run? With boomerang today, new tasks are created but modes change so quickly that you don‚Äôt know what‚Äôs happening unless you‚Äôre approving every step. 
Just curious if this is on the roadmap? I loved seeing the new subtask input output design today!
Friday fun

Roo code has no way on paying for them? only for APIs and openrouter?  
How we support their work?
RooCode kickstarting a singularity moment
I'll start by saying I'm a scientist and a technologist, but I'm not a hard core software developer.  I can architect, be a product owner and I'm pretty good with user driven experience.  But to start a new piece of software and write it for production? never (until now).  I usually focused on process and algorithms.  I found Cline first and then quickly switched to code (fully once checkpoints were implemented).  

The capabilities of the platforms and how they combine coding models and automation are amazing.  Thanks to RooCode, I was able to not just write a well engineered frontend/backend/database scalable web app, but I also learned how to convert that to iOS and Android Apps.  My first app got published on the App Store recently and it's a bit of a dream.  (https://apps.apple.com/us/app/nutrinanny/id6742064812).   RooCode helped me not just write it, but make it better and in many cases, it was smarter and more creative than me.  The current version of the app is only part of what I've written since I'm adding a ton more features that will require a longer approval and testing, but the app is already what I wanted for myself.  Maybe others will find it useful too (AI-driven food log and meal planning).  

  
Don't get me wrong, it's been difficult at times, especially when I don't do things right or when the models get confused, but I'm learning to tame the beast.   Even at work, I can build prototypes in hours that would have taken teams of people days, weeks or months.  

  
I guess this is a long way to also say "Thank You Roo Team" like the other recent posts.  Life is different now and your efforts allow many of us to live 6-12 months into the future, since most people don't yet realize what's possible and how life is changing right under our noses!
Yeah dude. This shit is crazy‚Ä¶ building a web app now and have the same aim as you, for conversion to ios / android. It‚Äôs crazy how far I‚Äôm getting that I think I will actually get there, 100% thanks to roo/cline/claude
You built that app on your own?
I‚Äôm vibe coding all kinds of stuff. I‚Äôve wasted so many tokens but I‚Äôm learning! I‚Äôve wasted way more money on worse things in the past.
Well OpenAI + Claude and the other giants are kickstarting the singularity but tools like roo and cline definitely are speeding up the process! Btw in what language did you code the app for IOS?? And what language did you build it for the web?
Well duh, 'roos do have powerful legs, after all!
Yes sir, Roo is pretty Roo-awesome :)
Rooooooooooooooooo
It's fun to finish something and just say.¬† ¬†Make it better! And watch it goto work
Lmao no
Roo Code 3.14 | Gemini 2.5 Caching | Apply Diff Improvements, and ALOT More!

Just the improvements I was looking for! üôè
lovely, thanks team
The diff improvements seem great, can't wait to test it all out
Okay It‚Äôs Simple: GPT 4.1
So Gemini has been nerfed and we‚Äôre at a loss for premium models that work well in agentic workflows.

Or so it seemed.

Turns out prompt engineering is still the make or break factor even at this stage in model development, and I don‚Äôt mean some kind of crafty role-play prompt engineering.

I mean just add this to the Custom Instructions on all modes if you plan to use 4.1 and have it one-shot pretty much any specific problem you have:

```

<rules>
    <rule priority="high">NEVER use CODE mode. If needed, use IMPLEMENT agent or equivalent.</rule>
</rules>
<reminders>
    <reminder>You are an agent - please keep going until the user‚Äôs query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.</reminder>
    <reminder>If you are not sure about file content or codebase structure pertaining to the user‚Äôs request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.</reminder>
    <reminder>You MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully.</reminder>
</reminders>
```
You have to be specific with the task. 4.1 is not meant for broad scope understanding. But it‚Äôs a hell of a reliable task-oriented engineer if you scope the problem right.

I‚Äôve temporarily reverted back to being my own orchestrator and simply directing agents (running on 4.1) on what to do while I figure out how to update the orchestration approach to:
- use XML in prompts
- include the specific triggers/instructions that get each model to behave as intended
- figure out how to make prompts update based on API config

anyway, I just tested this over today/yesterday so ymmv, but the approach comes directly from OAI‚Äôs prompting guide released with the models:

https://cookbook.openai.com/examples/gpt4-1_prompting_guide

give it a shot and try it with explicit tasks where you know the scope of the problem and can explicitly describe the concrete tasks needed to make progress, one at a time
I noticed a lot of issues with 2.5 Pro last week, however it has been an absolute boss this week.

I do not believe it is Roo, as even with aider - the model was performing like garbage.

Last week I did switch to OAI (4.1) and I also used Claude 3.7 (while 2.5 Pro was having issues) but the cost is astronomical. At the moment I use boomerang mode, make sure I build sufficient tests (TDD) and have my plans written to a folder for reference, this week has been amazing.

I am unsure if this helps but 99% of my work is backend (python fastAPI and Go) or Infrastructure-as-code.

Edit: I had weird formatting issues - I need coffee
Hey I think your prompt is actually helping in cursor too. It's listening to me much better and working for much longer periods of time before asking what to do.  It was doing one large refactor task at a time then asking again.  Then I said, \*\*Do the next 5 components before stopping\*\* and it listened.  Hit the 25 tool call limit.

I tweaked it very slightly for my .cursorrules file by adding a conditional

    IF model === 'gpt-4.1'
    <rules>
    <rule priority="high">NEVER use CODE mode. If needed, use IMPLEMENT agent or equivalent.</rule>
    </rules>
    <reminders>
    <reminder>You are an agent - please keep going until the user‚Äôs query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.</reminder>
    <reminder>If you are not sure about file content or codebase structure pertaining to the user‚Äôs request, use your tools to read files and gather the relevant information: do NOT guess or make up an answer.</reminder>
    <reminder>You MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully.</reminder>
    <reminder>Always use the Table Of Contents and Section Access tools when addressing any query regarding the MCP documentation. Maintain clarity, accuracy, and traceability in your responses. Ensure that your responses are concise and to the point, avoiding unnecessary verbosity.</reminder>
    </reminders>
    ELSE
    skip.
Gemini 2.5 Pro will be my everything model once they get prompt coaching implemented in Roo code. Minimum cache size is just 4k tokens, that means every prompt is cached basically
you *really* outta try out 2.5 flash
P.S. the prompt caching for 4.1 (vs Gemini where, at least in Roo, it‚Äôs not properly supported) means it does significantly more work/spend

this screenshot is a one-shot refactor of a hefty operation (simple task but complex script) that cost < $0.50

https://preview.redd.it/dhisgxafmnwe1.png?width=1264&format=png&auto=webp&s=08a2fbcbebc17c82efe2ed3b03a53ba32aa9c527
Wait Gemini got nerfed? Since when? 2.5 Pro? 2.5 Flash? Both?
Also isn't 4.1 insanely expensive?
How if Gemini being nerfed? I've been using both 2.5 preview as well as Exp and they're fine and still great.
You would think that roo would have most of that in the prompt
‚ö†Ô∏èAttention RooFlow Users, PLEASE READ
# [RooFlow](https://github.com/GreatScottyMac/RooFlow) is being switched to private. For more info, check out [RooFlow-Access](https://github.com/GreatScottyMac/RooFlow-Access)

# [RooFlow](https://github.com/GreatScottyMac/RooFlow) completely replaces the standard Roo Code system prompts. This may result in unexpected behaviors.

# If Roo is misbehaving with the RooFlow prompts, you can simply delete the .roo/ folder, install¬†[Roo Code Memory Bank](https://github.com/GreatScottyMac/roo-code-memory-bank?tab=readme-ov-file#download-and-run-install-script)¬†and then retry your operation with the standard system prompt.

# The memory bank instructions are exactly the same in both projects and RCMB uses the standard Roo Code system prompts.
Please do NOT use Roo Flow. It uses \[footgun-prompting\](https://docs.roocode.com/features/footgun-prompting) which is a feature that was only intended to be used for very advanced users, evals, and testing. 

It HAS worked decently in the past but recent changes to Roo Code tools require significant updates to the Roo Flow to get it to work properly. I have spoken to the maintainer and they and they have indicated that they are currently too busy to keep Roo Flow going and are likely going to be putting it on hold officially shortly. 

Please use \[Boomerang Tasks\](https://docs.roocode.com/features/boomerang-tasks) as there is no memory bank process I will currently recommends as when I have tested them they have not been as reliable as I would like.
I‚Äôm just confused why you chose to override the default roles and not make them like:

Flow-Code
Flow-Debug
Flow-Architect

etc.
Wow, that might explain the absolute nightmare I had using it for the first time yesterday and today, completely erratic behavior across all models, continuously losing track of progress and starting back at random points trying to redo what it had already done. Kinda feel like good news
The memory bank is so flakey IMO everyone should just use one of the open source mcp graph databases this is what MCP is for, the flat file will end up losing important data and will be added to differently over time breaking the whole system. Using a graph db to tag and frequently add memories with accurate dates that get weighted lower over time will give you excellent consistency. Pair it with something like task-master and you will rarely get off track.
What's the different between RooFlow & Roo Code Memory Bank? Have been using Roo Code Memory Bank since the beginning.
so if we use this, we wouldn't use the default and boomerang prompts on roo flow anymore? 

i like the idea of the memory bank, probably only thing i need.
What does ‚Äúmisbehaving‚Äù mean?
Any video tutorial I don‚Äôt Understand
i switched to roo commander a week or 2 ago. roo flow was a great intro to the ideas though.
RooFlow with AI Taskmaster is the dream
Gemini Pro 2.5 Diff Failures are wasting so many requests.
There was a thread on it last week [https://www.reddit.com/r/RooCode/comments/1jq4k70/diff\_failure\_with\_gemini\_pro\_25/](https://www.reddit.com/r/RooCode/comments/1jq4k70/diff_failure_with_gemini_pro_25/) with improvements promised but nothing seems to have changed. 

A single small task resulting in about 7 line changes created approx 25 requests with constant failures trying to write the exact lines, then trying to search and replace and finally trying to write the entire file at once. 

I've turned off formatting on save which I thought was the culprit but that doesn't change anything. Any tips to resolve this? 
2.5 pro experiment does this allot more than 2.5 pro preview. We are making a tweak to see if it improves. This is caused by the model not following the instructions on how to execute tool calls.
I have the same issue with models that are not Claude, many issues when applying changes result in unnecessary token waste, with expensive models like o1 or o3 it gets pretty ridiculous. With deepseek it's tolerable since the cost is low, but makes it hard to use anything but Claude.
When it was free I was thinking that this hiccups will need to be solved before they introduce paid model. Overall results were amazing but I was burning 200-500 milion tokens per day using roo code and a lot of context.  Like reading from memory bank, coming with a plan and validating everything against codebase, refining the plan, implementing it then switching to debugg mode in roo code and fixing UI issues step by step (+ mpc tool for unity and some screenshots which it understood). Then updating the memory bank and starting with a new task. It probably saved me like 5 months of work as solo developer and moved a project far ahead.

When they introduced the paid model I tried this 300usd trial and adjusted my workflow but now after initial few prompts and around 100k context it can eat a lot of $ trying to modify the code and failing spectacularly not because the code was wrong but 2.5 simply fails to modify the scripts leaving it with hundreds of compilation errors due to some misplaced code or forgets about }. Long story short as you need to sometimes wait 24h to have updated billing i was not using it as often and still burned 300$ in 3 days where at least 30% is fixing the misplaced diffs. 

This problem is rampant in 2.5 and probably only my robust work flow was keeping it in check before (still had it sometimes try to fix the code like 20 times before giving up and using write to file from scratch). Nowadays i just discard the changes ask to update the memory bank and start a new conversation which usually is cheaper and less prone to x20 madness with pasting few lines of a code.
did u try lower temperatures?
The solution is unfortunately to have Gemini Pro boomerang tasks to a Sonnet 3.5/3.7  
I have that set up and it is working super well
I'm a cheapo and using 2.5 exp and rotating APIs, but damn the diff fails suck. Would be amazing to have this fixed.
I haven't struggled quite as much with 2.5, but 2.0 flash has been completely unusable. Gpt40mini similar issues.


Love the tool and want to stick with it, but with the only choice being the most expensive, it's though for now. I tried adding custom instructions others had recommended for 2.0, but didn't seem to help enough, kept getting stuck in a loop of diff/write
I found that sometimes you can ‚Äújiggle‚Äù it by switching modes (say a Code mode and a same-prompt Code-2 mode).

Alternatively, toggling on the experimental search & replace may work better, especially for large files where the diff might get unwieldy.

Breaking files down to sub 500 lines (or further) also helps.
Ya it‚Äôs wicked broken for me
Cline has no issues with gemini 2.5 pro , whats up with this problem , i am a roocode user but for gemini 2.5 pro i always go back to cline for that
Release Notes 3.11.9 & 3.11.10 - Custom Instruction Overhaul & Per-Profile Rate Limits
This combined update includes significant improvements from our latest releases, with a focus on a brand new system for Custom Instructions and enhanced API configuration options. A huge thank you to everyone who contributed to these releases: upamune, taisukeoe, shtse8, KJ7LNW, ross, olweraltuve, diarmidmackenzie, gtaylor, axkirillov, SplittyDev, franekp, samhvw8, System233, and nbihan-mediware!

# üóÇÔ∏è Custom Instruction System Overhaul (Thanks upamune!)

### Important Changes & Deprecations:

*   **`.clinerules`:** Deprecated! While it still works for backward compatibility, the new directory structure or `.roorules` files take precedence if they exist. We strongly recommend migrating.
*   **`.cursorrules` & `.windsurfrules`:** No longer supported. Please migrate any rules from these formats to the new system.

### How do they work now?

The **preferred** way to manage instructions is now using directories within a `.roo` folder in your project root:

*   **Workspace-Wide:** Place instruction files (`.md`, `.txt`, etc.) inside `.roo/rules/`.
*   **Mode-Specific:** Place instruction files inside `.roo/rules-{modeSlug}/` (e.g., `.roo/rules-docs-writer/`).

Roo Code reads all files recursively within these directories, allowing you to break down complex rules easily. This method takes **precedence** over older file-based methods.

### What About `.roorules` Files?

*   We also introduced `.roorules` (workspace) and `.roorules-{modeSlug}` (mode-specific) files in the project root.
*   These now serve as a **fallback** ‚Äì Roo Code will only load them if the corresponding `.roo/rules/...` directory *doesn't exist or is empty*.

This new system provides a clear hierarchy and makes managing instructions, especially in teams, much simpler. Learn more in our detailed [**Custom Instructions Guide**](https://docs.roocode.com/features/custom-instructions) and [**Custom Modes Guide**](https://docs.roocode.com/features/custom-modes).

# ‚öôÔ∏è Per-Profile Rate Limits (Thanks ross and olweraltuve!)
*   The **Rate Limit** setting is now configured individually for each API Configuration Profile. Previously a global setting, this allows you to set different minimum delays between requests based on the provider, model, or specific profile setup you are using. 
*   The default remains 0 (disabled), which is suitable for most users.
*   Configure this setting within each profile's options. See the [API Configuration Profiles](https://docs.roocode.com/features/api-configuration-profiles#configuring-rate-limits-per-profile) guide for details. General information on usage tracking is available in [Rate Limits and Costs](https://docs.roocode.com/advanced-usage/rate-limits-costs).

# üîÑ Other Improvements & Fixes

This release, along with v3.11.9, includes numerous quality-of-life improvements, bug fixes, and provider updates. For a detailed breakdown, please see the full release notes:

*   [**v3.11.9 Release Notes**](https://docs.roocode.com/update-notes/v3.11.9)
*   [**v3.11.10 Release Notes**](https://docs.roocode.com/update-notes/v3.11.10)

----
@everyone  if you find Roo Code helpful, please consider **[leaving a review](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details)** on the VS Code Marketplace. Your feedback helps others discover this tool!
Thanks for everything you guys do. 

Not that it‚Äôs hard to change the file name, but why ignore the other rules file names? Is there some sort of technical reason?
I already implemented a workaround for the rules directory using system prompts, trying to replicate cursor‚Äôs approach. All that work, cleared with an update ü•≤.

I forgot what team I was dealing with üòÖ.

Thanks for the update!
The pace is so fast that release notes are playing catch-up with combined release notes! That‚Äôs truly impressive work.
Amazing!
For the modes and models. Can we have a checkmark that carries over the model between modes or not (currently each mode of a different model is used on automatic would switch to the last use model - example: if I had gemini on architect and sonnet on code, it will keep that, but sometimes I'd love to keep the same model going regardless of mode switches)
Nice, pretty excited about both these updates
Is /project\_root/.roo/rules-Ask/roo\_ask.md the correct place for the rules I want to add to the standard Ask mode?
You guys are amazing and legends - in boomerang mode , are the new rules understood by the parent orchestrator ?
Can someone explain why are rules useful? I‚Äôve overridden my system prompts where I specified the rules, so why should I use roorules? Is there sny benefit?
Kudos to the tireless developers who created and continually improve this amazing product. Given this release's features and changes, do you have any guidelines or current best practices for context management?
A) Is the same directory layout used for the global rules directory?

B) It would be ideal to be able to override specific sections of the default prompt. It appears to be generated section by section. The existing footgun prompting mode is very all or nothing when one may simply want to tweak a particular section (or, for example, the name/description/guidance for a particular MCP server) for a particular custom mode or globally.
I sometimes hit Google/openrouter daily limits during big task. Usually I change current model, but if all are exhausted, the only chance is to use human mode. Unfortunately I have to start from scratch, as human mode is always initialized in first prompt, so if I switch in between, LLM is not initialized, and respond in wrong format. Do you know solution for it?
How do I change the model across all modes rather than changing it repeatedly for each mode?
If some new thing comes and we have to use .newthingrules ? Remember Roo is not a programming language. Don‚Äôt overcomplicate things.
Gemini web Wrapper - Now anyone can have "unlimited" access to Gemini 2.5!
Hello everyone!

This is my FIRST EVER contribution to the open source world.

I have created an open ai compatible endpoint to be used with Gemini WEB.

The project relies HEAVILY on this other awesome project: [https://github.com/HanaokaYuzu/Gemini-API](https://github.com/HanaokaYuzu/Gemini-API)



Basically you can now use gemini web inside ROO!



Just set it to an OpenAI compatible endpoint and set the URL as [http://localhost:8099/v1](http://localhost:8099/v1)



[https://github.com/eriksonssilva/gemini-web-wrapper](https://github.com/eriksonssilva/gemini-web-wrapper)



I hope you can take advantage of it and also help me improving it!
What is point of this bridge?

I'm using Gemini 2.5 Pro in Roo Code from day 0.
Things like this will be the cause freemiums will come to an end...you ahould have kept it for yourself
Saw a video today from GosuCoder where he used boomerang prompt with Roo and Gemini 2.5 pro all day without rate limits. Pretty much my experience too.
>Since this is the web version of Gemini, it DOES NOT take system prompts. 
  
That's the deal breaker for me. I don't see any advantage over just using the AI studio itself with this constraint.
I got hit with error  "HTTP/2 429 Too Many Requests"
Hi, I have set this up, no errors during startup, however, it seems to fail to fetch any chats, is there a way to manually set the session cookie? or am i missing something
should something like that not also be possible with ChatGPT Plus? would be nice to be able to use my sub as an API..
Roo Flow Can Now Use Gemini Pro 2.0!
I posted this on Roo Code's Discord as well (https://discord.com/channels/1332146336664915968/1332148077263458385/1351286340368597135)

If you're a fan of Roo Flow, but are tired of paying Anthropic, you now have a choice. Roo Flow now works perfectly with Gemini Pro 2.0 (which is currently free to use)! Have a look at the PR ([https://github.com/GreatScottyMac/RooFlow/pull/8](https://github.com/GreatScottyMac/RooFlow/pull/8)) for an overview of how I did this. For fun I also posted a deep dive podcast to the discord message. It's a great listen!

Please let me know how this works for you!

Kevin
What is Roo flow?
I'm being really dumb here sorry, I want to use this as it makes 100% sense but I'm not sure how!? ü§î
Now let's add tokenisation and sqlite and it would be rocking
I just legitimately haven't been paying enough attention for the past week, I know features are coming fast and furious, and nothing's coming up on Google, but Roo Flow is just a/the agentic framework within Roo, by the sounds of things?
Can it be created as extensions rather than being cloned into part of the project?
Just tried, noticed that roo doesn't waste too much time on retrying to patch anymore, definitely an improvement
I tried using this, put the modified scripts into the .roo directory and ran the insert-variables.sh script. Then tried Gemini pro 2.0 in architect mode. It still got tool use formatting all wrong and was unable to diff files properly.
Gemini 2.0 Pro has the 10 messages-per-minute rate-limit at tier 1. Free tier offers 2 messages-per-min. Not really usable as an agent
Roo Code 3.3.21 Release Notes - Did someone say `@terminal`?
## üì¢ Notable Changes
- Add feature so you can `@terminal` in the prompt boxto pull terminal output into context (thanks Cline!)

## üîß General Improvements
- Enable streaming mode for OpenAI o1
- Fix system prompt to ensure Roo knows about all available modes

## üåè Localization
- Fix default preferred language settings for zh-cn and zh-tw (thanks System233!)

## üêõ Bug Fixes
- Fix input box revert issue and configuration loss during profile switching (thanks System233!)
- Fix Mistral integration (thanks d-oit!)

----

If Roo Code has been useful to you, take a moment to [rate it on the VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details). Reviews help others discover it and keep it growing!  

---
*Download the latest version from our [VSCode Marketplace page](https://marketplace.visualstudio.com/items?itemName=rooveterinaryinc.roo-cline) and pleaes WRITE US A REVIEW*

*Join our communities:*
* *[Discord server](https://discord.gg/roocode) for real-time support and updates*
* *[r/RooCode](https://reddit.com/r/RooCode) for discussions and announcements*
üòäüòä
You folks are awesome!
Sometimes when Roo asks me to run commands in the terminal, I approve them, but if an error occurs, Roo doesn‚Äôt always seem to recognize it. I often have to manually copy and paste the error into the chat. Do I need to use¬†`'@terminal'` every new message in a task to give Roo access to the terminal output, or does using¬†`'@terminal'`¬†once provide access throughout the entire conversation?
Integrated a local gateway with Roo Code to prevent secret leaks.
I have been working on an open-source project called¬†[CodeGate](https://github.com/stacklok/codegate), and I'm excited to share that it integrates with Roo Code! CodeGate runs as a local gateway between your AI coding assistant and the LLM. It helps prevent secret leaks by encrypting sensitive data before it leaves your machine and decrypting in on return. We've also integrated RAG to enhance LLM responses with real-time risk insights.

Check it out! I'd love to hear your thoughts!
Looks interesting for big projects. Medium- just using .clineignore (add .env here) is fine
China‚Äôs worst nightmare, gonna check this out great idea!
Awesome! Y‚Äôall got a neat project and glad to see the integration; makes it easy for enterprise K8s-style per-integration control planes
Great news!
How are you incorporating RAG? With MCPS?
Nice! Thanks for sharing.

"Cline has two modes: Plan and Act. Each mode can be uniquely configured with a different provider and model, so you need to configure both."

Help an old man understand this for Roo.
Thanks for using Roo!
New in 3.3: Code Actions, More Powerful Modes, and a new Discord! üöÄ
# Code Actions

Roo Code now integrates directly with VS Code's native code actions system, providing quick fixes and refactoring options right in your editor. Look for the lightbulb üí° to access Roo Code's capabilities without switching context.

# Enhanced Mode Capabilities

* **Markdown Editing**: Addressing one of the most requested features, Ask and Architect modes can now create and edit markdown files!
* **Custom File Restrictions**: In general, custom modes can now be restricted to specific file patterns (for example, a technical writer who can only edit markdown files üëã). There's no UI for this yet, but who needs that when you can just ask Roo to set it up for you?
* **Self-Initiated Mode Switching**: Modes can intelligently request to switch between each other based on the task at hand. For instance, Code mode might request to switch to Test Engineer mode once it's ready to write tests.

# Join Our Discord!

We've launched a new Discord community! Join us at¬†[https://roocode.com/discord](https://roocode.com/discord)¬†to:

* Share your custom modes
* Get help and support
* Connect with other Roo Code users
* Stay updated on the latest features
amazing! are checkpoints on the roadmap? I know it was asked about but curious if there are plans to include them
Thank you for the update. I noticed that in Architect mode it will automatically generate an MD file with its implementation plan. In most of my use cases this is undesirable as I'd rather just ask the LLM to review the plan (without generating a planning file) before switching to code mode manually. Doesn't creating the MD file incur API usage fees?
Great update!
love this thank you so much! any eta when we get rate limiting per token?
Great job! Keep it up!
Just curious, when is support for prompt caching coming to VS Code LM API, Deepseek, Google Gemini, and OpenRouter Deepseek?
Thanks. This version is lit.

For incremental but very worthwhile improvements (small code, but Big Benefits):  
\- A user-settable threshold\_tokens where 'New Task' is automated. This is a per-Model setting

\- Setting Temperature per Model

\- Verifying that the Reasoning Gemini 2.0 calls are set to reason as this seems to be disabled by default

\- VSCode Shadow edits for files that we don't need to watch being edited in the editor. This is super useful for log files. There are VSCode methods to do that.


Thanks again, mrubens. I'm also on the Discord, not the same nick.
This is Amazing
Awesome! Thank you for hammering this out.
Could you work on using minimizing the tokens you use?
Roo Code 3.14.3 Release Notes | Boomerang Orchestrator | Sexy UI Refresh

[Join our Discord so Hannes can pump the MAUs](https://discord.gg/Fku5q25B)

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/RooCode) if you have any questions or concerns.*
Does Roocode devs ever sleep?
Does the new orchestrator support memory bank?
Y‚Äôall ship!!!

Have you hit a point where using ROO code to write ROO code has accelerated things in a significant way?
How sexy we talking here?
thanks! But am I the only one not able tu use prompt caching with Gemini 2.5 preview? Even if I hit the checkbox and then click 'Save', the option will be not saved. If I return the settings, I can see the checkbox is again unselected
Thank you so much, i dont have to do this in custom modes myself anymore, it was such a pain. I didn not need or want to maintain custom modes for this kind a thing. don't get me wrong i am not complaining at all, this is an appreciation comment. Thanks for thinking for those of us who want to and will do agentic development right now.
So custom .roomodes and .roo files for orchestrator and boomerang can be deleted as it will revert to default boomerang now?
Not loving the customer colored icons - but love roo
Awesome, as always :) Thank you!

  
Could we add add a nice little X for me to close this annoying new warning? lol

https://preview.redd.it/cxd9djxm19xe1.png?width=918&format=png&auto=webp&s=56b67b67609999978385719506a8278c846beccd
Run Local LLMs in Google Colab for FREE ‚Äî with GPU Acceleration & Roo Code Access! üíªüß†üöÄ
Hey folks! üëã

I just published a Colab notebook that lets you **run local LLM models** (like LLaMA3, Qwen, Mistral, etc.) **for free** in **Google Colab** using **GPU acceleration** ‚Äî and the best part? It exposes the model through a **public API** using Cloudflare, so you can access it remotely from anywhere (e.g., with `curl`, Postman, or **VS Code ROO Code extension**).

No need to pay for a cloud VM or deal with Docker installs ‚Äî it's plug & play!

üîó **GitHub Repo**: [https://github.com/enescingoz/colab-llm](https://github.com/enescingoz/colab-llm)

# üß© Features:

* üß† Run local models (e.g., `qwen2.5-coder`, `llama3`) using [Ollama](https://ollama.com/)
* üöÄ Free Colab GPU support (T4 High-RAM recommended)
* üåê Public access with [Cloudflared tunnel]()
* üõ†Ô∏è Easy to connect with ROO Code or your own scripts
* üìÑ Full README and step-by-step instructions included

Let me know if you try it out, or if you'd like help running your own model! üî•
does it run the tools roo uses? Looks great!
I am interested and thank you for sharing! Now, could you please break iy down for my dumb ass brain? Why does this exist, what does it do well or not so well and what are the gotchas? Any good use cases as examples please?
this is a wild hack, which other models besides deepseek would you use?
Thanks for breaking it down! Makes total sense now. Awesome that you could pull this off!
Thanks for sharing! I will take a look!
Take my upvote.
damn was hoping for this to be good, but harder to work with. Qwen couldn't figure out my test. 

this was a cool thing though. Thanks for giving me real world experience with gwen
Roo Code 3.10.3 - A Bug Squashing Release
Roo Code 3.10.3 is now available with improved file handling and numerous bug fixes!

### üöÄ Feature Highlights
* Enhanced partial file reads with the ability to explicitly request full file reads when needed, custom chunk size controls, and clearer instructions

### üîß General ImpROOvements
* Update the welcome page to provide 1-click OAuth flows with LLM routers (thanks dtrugman!)
* Switch to a more direct method of tracking OpenRouter tokens/spend

### üêõ Bug Fixes
* Fix issues where questions and suggestions weren't showing up for non-streaming models and were hard to read in some themes
* A variety of fixes and improvements to experimental multi-block diff (thanks KJ7LNW!)
* Fix opacity of drop-down menus in settings (thanks KJ7LNW!)
* Fix bugs with reading and mentioning binary files like PDFs
* Fix the pricing information for OpenRouter free models (thanks Jdo300!)
* Fix an issue with our unit tests on Windows (thanks diarmidmackenzie!)
* Fix a maxTokens issue for the Outbound provider (thanks pugazhendhi-m!)
* Fix line number issue with partial file reads (thanks samhvw8!)

---

If you find Roo Code helpful, please consider [leaving a review](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details) on the VS Code Marketplace. Your feedback helps others discover this tool!
The auto checkpoints feature is being a pain in the ass sometimes, it works sometimes, and doesn't sometimes, and sometimes it just makes my source control disappear, doesn't show the files changed, even after the tasks are done.
Where to raise support tickets? Would love it if Roo would stop trying to use "&&" in terminal windows where "&&" isn't supported.

Even after learning it's not supported it seems to carry on defaulting to this in future commands.
Thank you, u/hannesrudolph!

If it‚Äôs not too much trouble, would you mind posting one of those ‚ÄúRoo vs Cline‚Äù comparisons?
Some wild idea: how about treesitter / lsp for chunked loading? You could load exactly those symbols that are needed for a given task
Well, having lots of trouble with the vs code copilot LM api integration. When it comes to updating or creating files, it shows the content in the roocode output window, even with write_file tags, but the ide does not pick it up and actually Create or modify the file! 
This is killer
OpenRouter added Gemini automatic cache support. Can Roo add support for this?

Yes, working on it!
From the office hours, they are working on it!

https://github.com/RooVetGit/Roo-Code/pull/2827
I'm blown away by the cost saving difference... This makes gemini 2.5 pro so much cheaper and I finally don't have to use the experimental version anymore!
These posts really annoy me. Do you really think you‚Äôre so early to this that the devs are not waiting for it to drop? These posts only take time away from the developers to answers these obvious posts. Or are you that ignorant you don‚Äôt realize it?
Gemini 2.5 Pro Trying to Diff Edit Lol!!!
I fucking love it, I've never tried greasing a weasel.....buuuuuttt I might have to.
Hahaha love it too! One of us for sure! üòÇ
The funny thing is‚Ä¶ we‚Äôve implemented a means for Roo to know if the files have been changed before it goes to edit them since it last read them. 

LLMs are quite funny sometimes.
Hahaha, sometimes swearing makes an LLM seem more human. If I saw this in a Turing test, I'd definitely vote for it being human :)
Seems like you are using a "tad bit" too high temperature for coding.
Power steering is awesome
The LLM finally stays on task and doesn't get diverted into adding bugs.    Tasks now take significantly less time.

Thanks for a great product!
Feel free to post some praise on other subs :)   
Could use the exposure
How does this power steering thing work really?
Have you used a specific steering prompt to have it avoid bug hunting and stay on task?
Nice! Can‚Äôt wait to jump back in on a previous project
Roo Code 3.3.4 Released! üöÄ
While this is a minor version update, it brings **dramatically faster** performance and enhanced functionality to your daily Roo Code experience!

## ‚ö° Lightning Fast Edits
* Drastically speed up diff editing - now up to **10x faster** for a smoother, more responsive experience
* *Special thanks to hannesrudolph and KyleHerndon for their contributions!*

## üîß Network Optimization
* Added per-server MCP network timeout configuration
* Customize timeouts from 15 seconds up to an hour
* Perfect for working with slower or more complex MCP servers

## üí° Quick Actions
* Added new code actions for explaining, improving, or fixing code
* Access these actions in multiple ways:
  * Through the VSCode context menu
  * When highlighting code in the editor
  * Right-clicking problems in the Problems tab
  * Via the lightbulb indicator on inline errors
* Choose to handle improvements in your current task or create a dedicated new task for larger changes
* *Thanks to samhvw8 for this awesome contribution!*

---
*Download the latest version from our [VSCode Marketplace page](https://marketplace.visualstudio.com/items?itemName=rooveterinaryinc.roo-cline)*

*Join our communities:*
* *[Discord server](https://discord.gg/roocode) for real-time support and updates*
* *[r/RooCode](https://reddit.com/r/RooCode) for discussions and announcements*
How can I add specific files to be worked on in chat?  
The \`Add File\` feature seems to show unrelated files to what I have currently opened or had previously opened.
Thanks for the update guys ! 
Would it be possible to implement a privacy feature somehow ?
I explain: 
Would be nice if the tool could ignore some files in the context (like .yanl or .env files etc) and also to rename packages name with something random instead of using the real names and also into each Java classes about importations too and reverting it before testing and pushing the code for example ? The aim of would be to avoid sending private information to the LLM API‚Äôs before the tool make the online requests
I wish there were more debugging (logging for example) and prompt optimization options in the prompt window. At the moment, you can modify each profile prompt or a custom prompt, but there is a lot more being sent in the request that you don't notice. 

I disabled MCP servers and noticed my token count in the request went down, so I started analyzing the request and there's a bunch of instructions being sent every single time explaining the agent how to use those tools. I understand MCP servers' purpose are to enhance the agent's capabilities, but I can't even fit them into the request.

I constantly get rate limited hard, and my productivity is close to none. If the chat is fresh and the code is small, sometimes I'll get a command or 2 in, but afterwards, after the ~14k token mark in the request, providers just tend to shut me down. DS has been getting attacked all week, so their resources are not available, leaving other providers with stricter and more expensive rates. 

God forbid you run into a hallucination cycle, and you spend your very limited rate solving a simple type issue. High token limit rates are scarce, and computational resources are limited. Why are these agents bombarding API's with so many tokens? 

I can literally read an ASP .NET Core manual and do it all by hand faster than I can get 4+ successful responses.
How do i add .rooignore so it will never touch my docker-compose file for example?
The Daily Dilemma of a Roo Code User

Only reason I have gone to bed is because I got rate limited üò≠
Funny, AI would take over jobs. Instead of getting more sleep, we get less as we watch AI (tools)
Well AI vibe coding really steals my sleep, it's just so satisfying, it's the joy of knowing I can make something and develop it easily
I already have all the fearures I need in Roo Code, so I sleep well
I feel seen.
As promised - I built SuperArchitect with Roocode - a tool that orchestrates multiple LLMs for better architecture planning
SuperArchitect is a command-line tool that leverages multiple AI models in parallel to generate comprehensive architectural plans, providing a more robust alternative to single-model approaches.

# Technical Overview

SuperArchitect implements a 6-step workflow to transform high-level architecture requests into comprehensive design proposals:

1. **Initial Planning Decomposition**: The high-level request is decomposed into multiple specialized architectural planning tasks. For example, "Design a microservice architecture for an e-commerce platform" gets broken down into service identification, data flow design, API gateway planning, etc.
2. **Multi-Model Consultation**: Each decomposed planning step is sent concurrently to multiple configured LLMs (currently supporting Claude, OpenAI, and Gemini) via their respective APIs. This happens in `core/query_manager.py` which handles asynchronous API requests and response processing.
3. **Analyzer AI Evaluation**: The responses from different models for each planning step are processed by an analyzer that identifies consensus points, conflicting recommendations, and unique insights. This provides a form of "AI peer review" for architectural decisions.
4. **Architecture Segmentation**: The analyzed content is automatically categorized into standard architectural sections (components, data flow, technology stack, security considerations, etc.), making the output more structured and usable.
5. **Comparative Analysis**: The segmented results are systematically compared across different planning steps to identify dependencies, conflicts, and optimization opportunities. This helps ensure the final plan is internally consistent.
6. **Synthesis and Integration**: The most valuable recommendations are selected and merged into a cohesive architectural plan, with rationale provided for significant design decisions.

# Implementation Details

The tool is built with a modular structure:

* [`main.py`](http://main.py) orchestrates the workflow
* `core/query_manager.py` handles model communication
* `core/analysis/engine.py` handles evaluation and segmentation
* `core/synthesis/engine.py` manages comparison and integration

Configuration is handled via a `config.yaml` file where you can specify your API keys and which specific model variants to use (e.g., `o3`, `claude-3.7`, `gemini-2.5-pro`).

# Current State & Limitations

Several components currently use placeholder logic that requires further implementation (specifically the decomposition, analysis, segmentation, comparison, and synthesis modules). I'm actively working on these components and would welcome contributions.

# Why This Matters

Traditional AI-assisted architecture tools rely on a single model, which means you're limited by that model's particular strengths and weaknesses. SuperArchitect's multi-model approach provides:

1. **Reduced hallucination risk** through cross-validation across models
2. **More comprehensive perspectives** by leveraging the unique strengths of different AI architectures
3. **Higher confidence recommendations** backed by multi-model consensus
4. **Better conflict resolution** through structured analysis of competing recommendations

[https://github.com/Okkay914/SuperArchitect](https://github.com/Okkay914/SuperArchitect)

I'm looking for feedback and contributors who are interested in advancing multi-model AI systems. What other architectural tasks do you think could benefit from this approach? 

I'd like to make it a community mode on Roocode if anyone can give me any tips or help me? 
Looks like code generated with Claude, it‚Äôs very bulky for what it does 

First add a gitignore file and clear out the pycache files.
Next use a framework to like lite llm to get rid of the handlers and base classes 

You could probably do this in - 100 lines with like langchain prompt templates loaded from disk.

RooCode can also do this with a couple of modes each pinned to a different model and some custom rules
Cool! Now go add all this good info to your GitHub readme!!
I spent so much thought and credits on this pls be nice to me lmao :))
Super cool share. The genius is in your prompting, not the code. Hopefully the comments stay nice and constructive. Building tools like this for yourself will be the quickest way to learn. Thanks for sharing!
Roo Code 3.15 Release Notes | Prompt Caching for Google Vertex | MAJOR Terminal Handling Improvement | More!!!

I've been waiting for this post! NEW TERMINAL IMPROVEMENTS ARE INSANE!!! great stuff!!
üî•release! üï∫
Whatever you did over the past few updates with Gemini 2,5 (exp) is absolute gold - The main problem I seemed to have is that it started hallucinating and looping over the same mistake twice or even multiple times... now that's just gone. The diffs are so much better too. I've never felt more AGI than I have now.

Mad props to the team!

  
edit: using gemini 2.5 openrouter studio+vertex for reference.
I'm not sure if it's this version that caused it but now I have an issue where Run Command only shows the prompt ($), it doesn't show the actual command to be run. Clicking the Run Command button will cause it to show as it's being run.

Looks like there's an issue open for it already: https://github.com/RooVetGit/Roo-Code/issues/3128
RooCode Top 4 Best LLMs for Agents - Claude 3.5 Sonnet vs DeepSeek R1 vs Gemini 2.0 Flash + Thinking
I recently tested 4 LLMs in RooCode to perform a useful and straightforward research task with multiple steps, without any user in the loop.

\- TL;DR: Final results spreadsheet: [https://docs.google.com/spreadsheets/d/1ybTpJvu0vJCYbGHJAG0DniyafNECTRzjgOjgzPSbOMo](https://docs.google.com/spreadsheets/d/1ybTpJvu0vJCYbGHJAG0DniyafNECTRzjgOjgzPSbOMo)

https://preview.redd.it/t1vqdq88dvje1.png?width=1623&format=png&auto=webp&s=52cebdbb0f68c5d98f2cc0735d7b0e2716590684

The prompt asks each LLM to:

\- Take a list of LLMs

\- Search online for their official Providers' pricing pages (Brave Search MCP)

\- Scrape the different web pages for pricing information (Puppeteer MCP)

\- Scrape Aider Polyglot Leaderboard

\- Scrape the Live Bench Leaderboard

\- Consolidate the pricing data and leaderboard data

\- Store the consolidated data in a JSON file and an HTML file

Resources:  
\- For those who just want to see the LLMs doing the actual work: [https://youtu.be/ldhSupCNL9c](https://youtu.be/ldhSupCNL9c)

\- GitHub repo: [https://github.com/marvijo-code/marvijo-software-yt](https://github.com/marvijo-code/marvijo-software-yt)  
\- RooCode repo:¬†[https://github.com/RooVetGit/Roo-Code](https://github.com/RooVetGit/Roo-Code)

\- MCP servers repo:¬†[https://github.com/modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)

\- Folder "RooCode Top 4 Best LLMs for Agents"

\- Contains:

\-- the generated files from different LLMs,

\-- MCP configuration file

\-- and the prompt used

\- I was personally surprised to see the results of the Gemini models! I didn't think they'd do that well given they don't have good instruction following when they code.

\- I didn't include o3-mini because I'm on the right Tier but haven't received API access yet. I'll test and compare it when I receive access
This is awesome. You should do a test where you have them each tackle tickets that require multiple files from a diff codebase and see how they do. Maybe not involving scraping.

EDIT: Nvm checked the spreadsheet. Actually fairly comprehensive. Nice. I guess what I would say is that it would be cool to pair reasoning/non-reasoning models. Ex - o3-mini-high/deepseek R1/Gemini thinking for plan + sonnet/deepseek V3/Gemini flash 2.0 for execution
Interesting results. I'm going to try gemini with roo code too. I need to lower these openrouter bills somehow... üòÖ
Very interesting. Ill give gemini a fair shot. Have been using sonnet for a really long time. Just didnt think anything better would work with roocode. Cheers!
Seriously, thanx!
Awesome, very awesome! This is very good, thank you for taking the time to do and share with the community.
i use deepseek-r1 api, but occurrence error, because¬†it never calls the tools leading to continuous errors
Can you try Gemini 2.0 PRO

I will try the follow workflow for few days:
- plan with R1 or O3
- augment the plan with Soonet
- execute the plan with Gemini
Nice. Now try to do the same with Smolagents:

[https://github.com/huggingface/smolagents](https://github.com/huggingface/smolagents)
I dunno what kind of test you ran but for me Sonnet is way above any of those.
I used the latest Gemini the one that came first. Spent 2 hours trying to resolve an issue with my code python. It just kept wanting to add error checking.

I gave the 2 python files to deepseek the one online. Said here is the error. It told me to fix 2 lines of code done.
Interesting. Did you change r1 temperature for coding? 

Maybe I missed it. 
You use always one model for architecture and for coding?
I figured myself that Gemini 2.0 Flash Thinking is the best, good to see these results.
Could you have this run on a cron and update the leaderboard every few days? make a website out of it!
surprising since gemini scored low on coding compared to others
RooMode is here! - 3.3.20 Patch Notes for Roo Code
## üèóÔ∏è Project Mode Support
- Introducing `.roomodes` file support for project-level mode customization
- Define project-specific custom modes right in your workspace

## üí¨ Ask Mode Updates
- Ask mode is now purely for chat interactions
- Removed markdown file editing capabilities to focus on its core purpose

## ü§ñ Provider Support
- Added new Mistral models to expand your options (thanks @d-oit and @bramburn!)

## üîß General Improvements
- Add setting to control the number of visible editor tabs in context
- Improve initial setup experience by fixing API key entry on welcome screen


----

If Roo Code has been useful to you, take a moment to [rate it on the VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details). Reviews help others discover it and keep it growing!  

---
*Download the latest version from our [VSCode Marketplace page](https://marketplace.visualstudio.com/items?itemName=rooveterinaryinc.roo-cline) and pleaes WRITE US A REVIEW*

*Join our communities:*
* *[Discord server](https://discord.gg/roocode) for real-time support and updates*
* *[r/RooCode](https://reddit.com/r/RooCode) for discussions and announcements*
Is this the same as the memory bank in cline,  but you each ‚Äúrole‚Äù has a separate memory bank that has their own role specific artefacts to refer to? Including progress and current context?
Great additions
Can it please just use .xxxrules - meaning cursor, windsurf rules file? I use multiple tools and it‚Äôs a pain to maintain multiple rule files. We really don‚Äôt need another / just just existing .rules file.
Will we see a moving away from the Cline.ts core code soon?
No batch tool = endlessly over expensive at large context windows.
I'm a reasonably heavy user, spending $100+ per day. Is anyone else endlessly frustrated that Roo's file-reading and writing tools are scoped to a single file per call. Executing multi-file reads and writes with large contexts is so much more expensive in tokens compared to, say Claude Code, which has batching capability. So, if I want to batch create 20 files based on a 80k context, I can do that in Claude Code in one call. In Roo the same thing requires 20 CALLS and costs literally 20 TIMES the tokens. The problem is that I really need the huge Gemini context window. Is there some solution for me out there? I feel like at the heavier use end there is a real need for batching. 
Great point. You‚Äôre right! 

We‚Äôre a community-driven project, built by and for the community. Many Roo features exist because someone cared enough to make them happen. We welcome contributions and won‚Äôt make excuses for this feature not existing yet. If you‚Äôve got the time and interest, reach out and we‚Äôll coordinate. If someone else reading this does, reach out too. I‚Äôm all for it.
there is some work going on regarding this  
see: [https://github.com/RooVetGit/Roo-Code/pull/2873](https://github.com/RooVetGit/Roo-Code/pull/2873)
The biggest missing thing in Roo right now is a codebase indexer with (semantic+full-text) search over tree-sitter extracted code constructs. I'm hacking up a python server which embeds LanceDB as an MCP tool for it, but there's no reason you can't ship this with Roo. LanceDB can be fully embedded (in the single process sense), and Transformers.js can handle the snippet embedding (in the vector space sense).
ong bruv AI agents can be MUCH MUCH smarter

Windsurf is already doing a lot of batching! You can see it attempts to analyze 6-7 files at once, write multiple files at once as well

Windsurf and Cursor are using a middle-man patch applier (likely fine-tuned Qwen model) to apply patches suggested by powerful LLMs (instead of letting the power LLM specify an accurate SEARCH&REPLACE block, which could fail and end in a loop of retries)

why is this not open source yet? It's so easy and feasible to implement
https://github.com/adamwlarson/RooCodeMicroManager Have fun my dude
A batch tool is a great idea!   
  
Can you describe a bit more your use case?

The main use case I can think of is when I need seed the files for a new feature or new project, right now they are created one by one. Is that the same thing you are running into?

For example today I built a new feature that had 6 new components, a new controller, and a new page. So 8 file creation calls. My context wasn't 80k because I utilize a custom mode in RooCode to hand out file creation tasks with less context, but still I am paying for those tokens whether cached or not.
You can try using open-codex or openai-codex with gemini, but idk if supports batching
How are you spending $100 per day? Is that you as an individual or a whole team? And I can ask are you a new dev? Genuinely interested if I'm missing out here, maybe I could be more productive if I used more tokens?
Roo Code can be expensive as it uses a lot of tokens due to a few reasons:

* They perform RAG on your code (takes tokens to process)
* They pass a lot of context to the model (even if the files are not relevant to the task)
* They use huge system prompts to support various tools (large system prompts take up a lot of tokens)
* They call multiple tools to complete a task (one task takes multiple API calls)

If you are looking to cut the cost and make AI coding more affordable, you can consider trying out the tool I built:¬†16x Prompt. It is less automated than Roo Code (no automated code editing), but it helps you manage source code context and select¬†**only relevant files**¬†for the task. This helps to keep the cost low (less than $20 a month in my experience).
Roo Code 3.11.0 Release Notes - Project Level MCP Config, Fast Edits and MOREEEEEEE.....

Roo Code 3.3.6 Released - Meet the Powerful "New Task" Tool
Introducing a powerful new way to manage your context

## üöÄ üîÑ The Powerful "New Task" Tool
Enables you to create new tasks from within existing ones, allowing for automatic context continuation. Here are some neat use cases:

* Say "Summarize this and start a new task based on the summary" to create a fresh chat session that builds on your current context

* Include "summarize and start a new task when your context is more than 80% full" in your custom mode instructions

* Include "Update memory bank and start a new task when your context is more than 80% full" within the .clinerules file. [See here to setup a memory bank](https://docs.cline.bot/improving-your-prompting-skills/custom-instructions-library/cline-memory-bank)

## ‚ú® UI Improvements
* Enhanced dropdown visuals for better user experience (thanks psv2522!)

## ü§ñ Provider Support
* Added support for perplexity/sonar-reasoning integration (thanks Szpadel!)
* Added support for the Unbound provider (thanks vigneshsubbiah16!)

## üêõ Bug Fixes
* Fixed critical bug affecting qwen-max and other OpenAI-compatible providers (thanks Szpadel!)

---
*Download the latest version from our [VSCode Marketplace page](https://marketplace.visualstudio.com/items?itemName=rooveterinaryinc.roo-cline) and pleaes WRITE US A REVIEW*

*Join our communities:*
* *[Discord server](https://discord.gg/roocode) for real-time support and updates*
* *[r/RooCode](https://reddit.com/r/RooCode) for discussions and announcements*
I love to see such rapid progress, but I will admit I wish Roo and Cline would kiss and make-up. Both teams are moving really fast but as a user, it would be better if all that effort was moving one project forward.
Nice work on all the new updates!

For those using the Memory Bank instructions, do you put them in the Custom Instructions for all models or as .clinerules?

Along this same line of thinking, I'm wondering if there is an impact on the output or different way that Custom Instructions and .clinerules are used in the prompt? Or are they totally interchangeable?

Any plan to change the name of the .clinerules file now that it's called Roo Code? Maybe a .roolues file lol?
Amazing!
well done. I love the updates!
Seems it will be best add-on soon :-)
Can anyone determine if memory bank is actually beneficial? I‚Äôm not sure I need it over just context files in a folder, unless I‚Äôm missing something
Nice Update
Here you say perplexity is now supported, but it's not in the API dropdown. Where can I enter my perplexity API key?
Roo Code 3.3.5 Release
A new update bringing improved visibility and enhanced editing capabilities!

## üìä Context-Aware Roo
Roo now knows its current token count and context capacity percentage, enabling context-aware prompts such as "Update Memory Bank at 80% capacity" (thanks MuriloFP!)

## ‚úÖ Auto-approve Mode Switching
Add checkboxes to auto-approve mode switch requests for a smoother workflow (thanks MuriloFP!)

## ‚úèÔ∏è New Experimental Editing Tools
* Insert blocks of text at specific line numbers with `insert_content`
* Replace text across files with `search_and_replace`

These complement existing diff editing and whole file editing capabilities (thanks samhvw8!)

## ü§ñ DeepSeek Improvements
* Better support for DeepSeek R1 with captured reasoning
* Support for more OpenRouter variants
* Fixed crash on empty chunks
* Improved stability without system messages

(thanks Szpadel!)

---
*Download the latest version from our [VSCode Marketplace page](https://marketplace.visualstudio.com/items?itemName=rooveterinaryinc.roo-cline)*

*Join our communities:*
* *[Discord server](https://discord.gg/roocode) for real-time support and updates*
* *[r/RooCode](https://reddit.com/r/RooCode) for discussions and announcements*
Exciting update!
Does Roo remove information from the context window when it gets close to capacity? 

For example, removing some earlier iterations of code or other items that take up a chunk of tokens but will not affect performance if they are removed from the context window.
https://preview.redd.it/f0an85mlwyfe1.png?width=461&format=png&auto=webp&s=426df396586946758712b7407b150773a8977237

I am facing this issue, is there anything wrong with it? It Can not use VS Code LM API and do not allow me to change the API Provider. :/

How can I solve this?
It just keeps getting better
Really great software, thank you.

One small thing: the Architect mode wants to switch to code mode or write a text file when all I want is to have a conversation about the code base without it touching my code base.  It would be great to add a talk only mode.

Thanks again!
How can I access deepseek R1 without being too slow? I understand that there are too many requests, I tried openrouter and it's slow responding kills.
Thank you Roomunity!
I want to thank you all for your amazing support as we continue to grow and learn along the way. 

This week was our first week with over 50bn tokens one day on OpenRouter. 

Today we crossed the 7000 users on Reddit and 8000 on Discord! 

This week we posted our first podcast on our new YouTube channel. 

I‚Äôm sure there is more that I missed but nonetheless I wanted to say thank you. 

You are Roo. Thank you. 
You all are doing amazing work! I've been using Cline for a while but recently looked into Roo Code and am surprised at how many amazing features and customization options are available in it. I'm going to switch over to Roo permanently once I set up my own modes and instructions and get a better handle on it.
Been a huge time saver for me and allows me to get back to personal programming with my limited amount of time.
It's a productivity freaking nitro blast.  Thanks so much for it.  Using it to test stealth models is also a blast, but yeah, the Boomerang Tasks mode kind of sealed it for me and my former usual suspects (Cline, Cursor, Copilot etc) are all getting rather lonely.  Keep up the Aussie theming!
Discord link
Optimized Roo Code Setup to Slash Token Costs
Hey all,

I‚Äôve fine-tuned my Roo Code setup (VS Code) to blend Claude Pro and OpenRouter, slashing my token costs from ‚Ç¨60/day to ‚Ç¨20-30/day. It uses a daily-split **memory bank** and smart fallbacks‚Äîperfect for solo AI coders. Here‚Äôs the gist:

* Daily Split: Files like [activeContext-2025-03-02.md](http://activeContext-2025-03-02.md) cap at 5k-15k tokens.
* Fallback: After a week off, it auto-loads the latest day.
* Manual Updates: Type UMB to save tokens, no real-time bloat.
* Claude Pro + Haiku: Pro for big stuff, Haiku for cheap updates.

# Setup

Drop these .clinerules files in your project root and make a memory-bank/ folder. ~~Full configs on Pastebin:~~

* [~~.clinerules-architect~~](https://pastebin.com/uyqcs7m9) ~~(system design)~~
* [~~.clinerules-code~~](https://pastebin.com/3Sbtra4q) ~~(coding)~~
* [~~.clinerules-ask~~](https://pastebin.com/raw/Qj5wy9GX) ~~(questions)~~

or github: [https://github.com/shipdocs/roocode-memorybank-optimized](https://github.com/shipdocs/roocode-memorybank-optimized)



# How to Use

1. Install Roo Code in VS Code.
2. Add the files + your OpenRouter/Claude Pro API keys (in config.json).
3. Work, then UMB to update daily files.
4. Back from a break? It grabs the last day automatically.

# Why?

Halved my costs while keeping Claude‚Äôs power. Great for PHP/webdev or any AI-driven gig. Thanks to xAI‚Äôs Grok for the help!

What do you think? Tweaks welcome!

(i am not a programmer and cant give support, i just noticed my token usage going up three times)
These memory banks are cool! Though one thing I noticed is that the formatting of the apply_diff tool usage is wrong. Is it necessary to give it the exact XML, or would it work to just ask it to use apply_diff to add X content to the memory bank?

In general I‚Äôm nervous about coupling the memory bank too closely with specific tool formats because they could change in the future.
[https://github.com/shipdocs/roocode-memorybank-optimized](https://github.com/shipdocs/roocode-memorybank-optimized)
Updated the github repo with complete files, and hopefully dealth with the xml remark
i dont know how to update the title, but its about memory-bank token usage reduction
20 Euros a day still seems like a lot though.
There are so many tasks in the prompts that the AI will have no capacity left to actually code!
I am a refugee from cline and have been using cline's memory bank (https://docs.cline.bot/improving-your-prompting-skills/custom-instructions-library/cline-memory-bank)

I want to move to Roo Code and was looking for a tool like this, except I dont want to use Claude Pro. I tend to prefer DeepSeek R1 for planning, for example, and often also for coding. But it's got a wee small 64k context window so this context management tool is what I need.

How would I move from the current state of my Cline memory bank to using this RooCode memory bank?
hey thanks for posting this. would you say its still relevent or have you explored more up to date options? thanks
Hey u/mrubens, thanks for chiming in‚Äîcool to hear from a Roo Code dev! I‚Äôm just a barge captain trying to keep my token bills in check, not a coder, so I leaned on Grok to build this. You‚Äôre right about apply\_diff‚ÄîI noticed it‚Äôs locked into XML formatting, which might break if tools change. I‚Äôll ask Grok to tweak it to be less strict. No clue if it needs exact XML or just a nudge to add content‚Äîany tips? I‚Äôll update the GitHub repo if we crack it. Cheers!
One More Thing
Hidden in those patch notes I just posted about was a gem. We've introduced a rate limiting feature in Roo Code to address issues users have encountered with rate limit errors when using models like Claude 3.5 Sonnet with the VS Code API. [github.com](https://github.com/RooVetGit/Roo-Code/issues/426?utm_source=chatgpt.com)

To adjust the rate limiting settings:

1. Click the settings wheel in Roo-Code.
2. Navigate to the **Advanced Settings** section.
3. Locate the **Rate Limit** slider.
4. Set your preferred interval between API requests (up to 60 seconds).

Finding the optimal interval may require some trial and error to suit your specific workflow. This feature is designed to help manage the frequency of your API requests, ensuring a smoother development experience.
Has anyone found an optimal rate limit?
Thank you so much!


I've been risking using its API and my approach is to stop when it says I reached the rate limit. I wait for a while before trying again.


Man, I've been testing the agent feature of Copilot and it's nowhere as good as Roo


Thank you again!
Very neat feature, I'm finding myself using it and tweak it more and more as the development progresses. That gave me a small idea/wish for future improvements, and even tho its not a big deal it would be nice to have a quick setting of some sort to easily adjust the seconds as the project becomes larger, the need for higher time increases and it would be nice not having to go to settings and scroll down. I know, exhausting right?
Great feature! I assume this effects all providers / models when set?
What a great feature, and a sigh of relief! I hit rate limits all. the. time. in my workflow so this makes life better.
3.7.10 Release Notes - even more impROOvments!
Sorry for ANOTHER ping today! It's just that we had to get these tweaks and new features in your hands before the end of the day!

## üìä Mermaid Diagrams Support

* Add support for Mermaid diagrams - now you can visualize flowcharts, sequences, and more directly in your conversations (thanks Cline!)

## ü§ñ AI Model Expansion

* Add Gemini models on Vertex AI for more model options (thanks ashktn!)

## ‚å®Ô∏è Productivity Boost

* Keyboard shortcuts to switch between modes - navigate your pouch of tools faster than ever (thanks @aheizi!). Click on the mode popup menu to see all available shortcuts

Wow! 2 releases in one day - Roo team on a roll! Thank you!
you on fire broskys

now we maybe have a few weeks before Microsoft "acquires" Roo and shuts it all down
Roo-mazing!
Roo Code vs Cline
^(EDIT: Updated Feb 8, 2025)

# Features Roo Code offers that **Cline doesn't YET**:

- **New_Task Tool**: Create new tasks from within existing ones, allowing for automatic context continuation, includes option for automatic approval.(01/24/30)
- **Custom Modes**: Create unlimited custom modes, each with their own prompts, model selections, and toolsets.
- **Smarter Mode Switching**: Modes can now intelligently request switches to other modes when needed, making your workflow more seamless. For example, when you need to make code changes while in Architect mode, Roo can suggest switching to Code mode automatically.(01/24/25)
- **Mode Level Custom File Pattern Restrictions**: Granular file access control for custom modes. You can now create specialized roles like technical writers with access limited to markdown files only, ensuring focused and secure workflows.(01/24/25)
- **Enhanced Markdown Support per Mode**: Ask and Architect modes now have markdown editing capabilities, perfect for documentation tasks and architectural planning.(01/24/25)
- **Quick Actions**: Code actions for explaining, improving, or fixing code. Accessed through the VSCode context menu when highlighting code in the editor, Right-clicking problems in the Problems tab, and Via the lightbulb indicator on inline errors. Allows you to handle improvements in your current task or create a dedicated new task for larger changes. Thanks to samhvw8.(01/24/27)
- **Support for Glama API**: Support for Glama.ai API router which includes costing, caching, cache tracking, image processing and compute use.
- **Delete Messages**: Remove messages using the trash can icon. Choose to delete just the selected message and its API calls, or the message and all subsequent activity.
- **Enhance Prompt Button**: Automatically improve your prompts with one click. Configure to use either the current model or a dedicated model. Customize the prompt enhancement prompt for even better results.
- **Language Selection**: Communicate in English, Japanese, Spanish, French, German, and more
- **List and Add Models**: Browse and add OpenAI-compatible models with or without streaming
- **Git Commit Mentions**: Use `@-mention` to bring Git commit context into your conversations
- **Quick Prompt History Copying**: Reuse past prompts with one click using the copy button in the initial prompt box.
- **Terminal Output Control**: Limit terminal lines passed to the model to prevent context overflow.
- **Auto-Retry Failed API Requests**: Configure automatic retries with customizable delays between attempts.
- **Exponential Backoff for API Retries**: Automatically increases retry delays (5s, 10s, 20s, etc.) for consecutive failures.(02/08/25)
- **Custom Rate Limiting**: Configure minimum delay between API requests to prevent provider overload.(02/08/25)
- **Slash Command Mode Switching**: Quick mode changes using commands like `/ask` or `/code`.(02/08/25)
- **Delay After Editing Adjustment**: Set a pause after writes for diagnostic checks and manual intervention before automatic actions.
- **Diff Mode Toggle**: Enable or disable diff editing
- **Diff Mode Switching**: Experimental new unified diff algorithm can be enabled in settings
- **Diff Match Precision**: Control how precisely (1-100) code sections must match when applying diffs. Lower values allow more flexible matching but increase the risk of incorrect replacements
- **Browser User Screenshot Quality**: Adjust the WebP quality of browser screenshots. Higher values provide clearer screenshots but increase token usage
- **MCP network timeout configuration**: Customize timeouts from 15 seconds up to an hour.(01/24/27)

---

# Features Cline offers that **Roo Code doesn't YET**:

- *Currently none identified*

---

# Features they both offer but are significantly different:

- **Notifications**: Roo Code uses optional sound effects for task completion, while Cline uses optional system notifications

- **Modes**:  (Table relating to "Modes" feature only)

| Modes Feature | Roo Code | Cline |
|---------|-----------|--------|
| Default Modes | Code/Architect/Ask | Plan/Act |
| Custom Prompt | Yes | No |
| Per-mode Tool Selection | Yes | No |
| Per-mode Model Selection | Yes | No |
| Custom Modes | Yes | No |
| Activation | Manual | Auto on plan->act |

---

> ‚ö† **Disclaimer:** This comparison between Roo Code and Cline might not be entirely accurate, as both tools are actively evolving and frequently adding new features. If you notice any inaccuracies or features we've missed, please let us know in the comments, and we'll update the list immediately. Your feedback helps us keep this guide as accurate and helpful as possible!
I would like to add that it is possible to configure sliding window context length, unlike in Cline
Newbie here. Is it free and open source?
In Cline, I didn't find that it can automatically switch from plan to act.
has there been any serious discussion between Cline and Roo to team up?
as a developer in which repo should i contribute cline or roo code
Roo Code 3.15's prompt caching cut my daily costs by 65% - Here's the data
    I wanted to share my exact usage data since the 3.15 update with prompt caching for Google Vertex. The architectural changes have dramatically reduced my costs.
    
    ## My actual usage data (last 4 days)
    
    | Day | Individual Sessions | Daily Total |
    |-----|---------------------|-------------|
    | Today | 6 √ó $10 | $60 |
    | 2 days ago | 6 √ó $10, 1 √ó $20 | $80 |
    | 3 days ago | 6 √ó $10, 3 √ó $20, 1 √ó $30, 1 √ó $8 | $148 |
    | 4 days ago | 13 √ó $10, 1 √ó $20, 1 √ó $25 | $175 |
    
    ## The architectural impact is clear
    
    Looking at this data from a system architecture perspective:
    
    1. **65% cost reduction**: My daily costs dropped from $175 to $60 (65% decrease)
    2. **Session normalization**: Almost all sessions now cost exactly $10
    3. **Elimination of expensive outliers**: $25-30 sessions have disappeared entirely
    4. **Consistent performance**: Despite the cost reduction, functionality remains the same
    
    ## Technical analysis of the prompt caching architecture
    
    The prompt caching implementation appears to be working through several architectural mechanisms:
    
    1. **Intelligent token reuse**: The system identifies semantically similar prompts and reuses tokens
    2. **Session-level optimization**: The architecture appears to optimize each session independently
    3. **Adaptive caching strategy**: The system maintains effectiveness while reducing API calls
    4. **Transparent implementation**: These savings occur without any changes to how I use Roo
    
    From an architectural standpoint, this is an elegant solution that optimizes at exactly the right layer - between the application and the LLM API. It doesn't require users to change their behavior, yet delivers significant efficiency improvements.
    
    ## Impact on my workflow
    
    The cost reduction has actually changed how I use Roo:
    - I'm more willing to experiment with different approaches
    - I can run more iterations on complex problems
    - I no longer worry about session costs when working on large projects
    
    Has anyone else experienced similar cost reductions? I'm curious if the architectural improvements deliver consistent results across different usage patterns.
    
    *The data speaks for itself - prompt caching is a game-changer for regular Roo users. Kudos to the engineering team for this architectural improvement!*

https://preview.redd.it/fjg1x1jgb3ye1.png?width=641&format=png&auto=webp&s=3bce69c965a36cb4bf14558f893fca30b9e6f526

https://preview.redd.it/qmwrnqxcb3ye1.png?width=764&format=png&auto=webp&s=b3a3c45b904bb4e65769a66e3b6028cccaa69a7d


What model are you using?  Gemini 2.5 doesn't have prompt cacheing right?
Roo really needs smart context compression along with the caching.
Still waiting for this to come to OpenRouter ü•≤

Not here yet as of Roo 3.15
Hmm, have a LiteLLM caching which works with RooCode OpenAI Capability adapter?!
How do you keep track on this? I couldnt find out
Which API are you using today? 04/16/25
Yesterday I posted about Gemini 2.5‚Äôs performance seemingly going down. All the comments agreed and said it was due to a change in compute resources.

So the question is: which model are you currently using and why?

For the first time in a while it seems that OpenAI is a contender with 4.1. People around here saying that its performance is almost as good as Claude 3.7 but with 4x less cost.

What are your thoughts? If Claude wasn‚Äôt so expensive I‚Äôd be using it. 
I‚Äôve been using Claude for all my projects for months. Tried out Gemini 2.5 when it was first release because the context window was exciting but experienced the same dwindle of performance (+ no caching gets expensive). so I switched back to 3.7. Gave GPT-4.1 a run for the last few days because of benchmark scores and context window size but ended up switching back to 3.7 Sonnet again today. IMO nothing compares to the code quality of 3.7 Sonnet. I‚Äôll sacrifice the context window for quality of code. So much time saved debugging and the loops of errors. I work mostly with javascript apps.
Honestly, at first I thought you all were crazy with the constant posts about how a model suddenly started performing worse. Then I started really using these models heavily for coding, and I‚Äôve logged many hours across quite a few models. It‚Äôs 100% true, and I also noticed a decrease in Gemini 2.5 quality over the past few days.
[Roo Code LLM Evaluations for Coding Use-Cases](https://roocode.com/evals)

Roo Code‚Äôs comprehensive benchmark evaluates major LLMs using real-world programming challenges sourced from Exercism, covering five widely used languages: Go, Java, JavaScript, Python, and Rust. This approach provides practical insight into the effectiveness of each model when used for actual development tasks, taking into account their accuracy, execution speed, context window capacity, and operational cost.

Claude 3.7 Sonnet delivers the highest overall accuracy among all models tested, excelling notably in JavaScript, Python, Go, and Rust. It is particularly valuable for projects where precision across multiple languages is crucial. While somewhat expensive and only average in terms of speed, its large context window and superior accuracy make it ideal for applications where code correctness is paramount.

GPT-4.1 stands out as a strong generalist, balancing accuracy, speed, and context capacity effectively. It achieves consistent, high-level performance across all tested languages and completes tasks faster than any other top-performing model. Coupled with its large 1M-token context window, GPT-4.1 is highly recommended for large-scale codebases, multi-file refactoring, or tasks requiring frequent, rapid iterations.

Gemini 2.5 Pro warrants attention due to its growing popularity and competitive performance. It demonstrates particularly strong accuracy in Python, Java, and JavaScript, with an overall accuracy comparable to GPT-4.1. Although not the absolute best in any single language, its balanced performance, solid reasoning capability, and competitive context window position it as a reliable alternative to GPT models‚Äîespecially attractive to teams already invested in Google‚Äôs AI ecosystem.

On the economical end, GPT-4.1 Mini offers the best cost-to-performance balance. While its accuracy is somewhat lower than premium models, it maintains impressive performance in JavaScript, Python, and Java, accompanied by a generous context window and relatively fast runtime. This makes GPT-4.1 Mini particularly suitable for budget-conscious teams, rapid prototyping, and iterative workflows.

Notably, certain models fall short in practical use. Gemini 2.0 Flash provides high throughput but significantly lower accuracy, limiting its suitability for precision-oriented development tasks. Similarly, o3 stands out negatively due to its exceptionally high cost combined with modest performance, making it impractical for most coding applications.

In summary, project priorities should guide the model choice:

Claude 3.7 Sonnet for maximum accuracy and reliability.

GPT-4.1 for the best balance of speed, large context capacity, and accuracy.

Gemini 2.5 Pro for teams favoring a strong, balanced performer within Google‚Äôs AI ecosystem.

GPT-4.1 Mini for cost-effective, rapid coding iterations and prototyping.

Models such as Gemini Flash or o3, lacking sufficient accuracy or cost-efficiency, should generally be avoided for development-focused tasks.
Still using Gemini 2.5 Pro EXP under Vertex API + Open Router. Getting lots of message saying 

"You exceeded your current quota. Please migrate to Gemini 2.5 Pro Preview (models/gemini-2.5-pro-preview-03-25) for higher quota limits"

if smaller tasks just move to windsurf + 4.1 (free for a week), the only issue is windsurf does not read the memory bank setup by roocode.

The rest of the tasks still using Claude Desktop + MCP to complete.
Use 2.5 and excited to see when flash comes out, I expect that will become my main.
As I am exploring free options, I am currently using Deepseek V3 via OpenRouter.
It's all the same thing with Jim and I, switched to deepseek and watched it fail miserably, over to Claude which was better but not by a huge amount. Just cost a lot more, finally ended up at GPT and got the results we needed. 

So agree with all your sentiment.
Gemini 2.0 Flash is still good
I've been using 4.1. It's been great.
I'm convinced they tie the performance to the stock market Lol
Gemini 2.5 pro through copilot api, only get 120k context window from copilot api and somehow never pass 60k in practice, but good enough as a workhorse. Powersteering also helps to keep it on track.
I'm using GPT 4.1 in the free trial with Windsurf, its kinda good indeed.
grok 3 mini is amazing for its price so i have been using that a lot. plus the style it has just clicks for me. feels very natural.
I was using Gemini few days ago for a whole day. At begging it was really great. Fast and smart. Don't forget anything and was very best model I ve work with. During coding session, few hours later, it stop to respond for a minute or two. Than it start to act like after lobotomy. Constantly forget what it is doing, forgetting to continue task to an end and start to make big mistakes with simple things. It was huge difference in quality. I was restarting sessions so I don't overload it with context - max 300k tokens in a session. Than I got a bill and was pissed and forget about Gemini.
Gemini is fucking retarded with alzheimers all of a sudden - a real shame.
You answered for me already. 2.5 until it took a (imo MAJOR) dive in the last week or so and suddenly messes things up constantly, and not small mistakes, but big mistakes that destroyed 24 hours of previous work.  4.1 is really cheap and imo is more reliable and much easier to work with than 3.7.    
  
I'll add this though... I have ChatGPT Plus, so my process at the moment is to start in my ChatGPT Desktop app using o3 to help me architect a gameplan, make an outline, and research repo options on github that I am looking at using, including looking for similar alternative repos, choose a tech stack and come up with a detailed PD (project doc) with Phases, 1, 2, 3, 4, etc.    
  
Then I take that into Roo using 4.1 to execute the code.    
  
OR, sometimes I take that into Roo and ask 3.7 what it thinks about the PD gameplan just to see if it sees any additional things worth noting, which, 3.7 does sometimes see something like (great plan, but it would be a good idea to \_\_\_\_).  (and I've tested this with other models, and oddly, it's ALWAYS 3.7 that seems to see some extra genius little better way to do something... to me 3.7 is really smart but SO fking disorganized, I can't deal with actually letting it do my coding.  I have ADHD, but I swear 3.7 has ADHD x100)  
  
If this happens, I go back to o3 to confirm that 3.7's idea is good.  And so far, every time this has happened, o3 agreed, great idea.  At that point, I execute with 4.1.    
  
BUT, I'm very interested in exploring o4-mini for code execution as well.  I'm curious to see if it outperforms 4.1, bc it's cheaper and has thinking/reasoning.  (Note: 4.1 sucks at using MCPs, like Brave search bc it uses the wrong syntax, so I swap back to 2.5 just when I need a web search or similar)
Cursor vs RooCode
I'm not as smart as software engineers, business side, but I self thought myself a bit of python. Vibe coding made my progress much easier. Having some code understanding really helps. I started with Pycharm (sucked), then Cursor, then Roo. The reason I liked Roo is that it can do way more than Cursor based of my humble and short coding experience. Keep me honest , am I correct on the following:

1 - Roo can run on full auto with auto approve and boomerang mode enabled. Also it can run terminal commands and check browser to fix issues automatically. Cursor cannot?  
2 - Cursor is paid and Roo is free, why would someone ever pay for Cursor?  
3 - Is there a "best list" of instructions for Roo / Cursor that helps AI set up the project correctly with all the right docs and keeps it following best practices in software development?

I know, newbie questions, and much appreciate your pointers, help or rants :) ! Tx

\-----

THANKS FOR ALL YOUR INSIGHTS FOLKS, LOVE REDDIT, LOVE THIS COMMUNITY, THANK YOU!
As someone who uses cursor but never have as my main tool, I am excited to see what others have to say on this topic! 

The good the bad and the ugly!  Let‚Äôs here it Roommunity üòÉ
I've been using Cursor for \~9 months now, similar background as you, but probably have more coding experience than a bit of python.

I don't know the exact timeline, so someone might correct me on this - but I believe cursor was the first one to come out with this 'agent' mode, which seemingly broke everything open.  Now, it wasn't just about fixing and editing a file, it was the true birth of vibe coding.

I also don't care whatsoever about the costs.  I know that isn't the case for some people, but $15 (or even $150) vs free is irrelevant, I'll use what is best - I'm guessing I'll be at \~$1000 this month in API costs (mostly Gemini).

That said, \~1 month ago I swapped to RooCode and I haven't looked back.  The boomerang mode is amazing.  Maybe it will just take some time for people to swap over... not sure.
Roo isn't "free", yes it doesn't cost to use but the LLM has to come from somewhere. If you maximize your usage Cursor is actually a great deal for $20/m. It's actually hard to beat that price wise (unless you're microsoft and can afford to lose money indefinitely on copilot pro, though it looks like they are going to increase pricing to $19/m).
I use Roo primarily with my Deepseek key, but I do use Cursor sometimes when I need several AIs to verify the same thing.

Roo's free mode cannot match what you get from cursor's subscription. The free models from openrouter are not on part with sonnet 3.7 or its equivalent. Yes you do get gemini 2.5 pro but those rate limits hit you before you even get started with your project.

If you already pay for your API key from say deepseek or gemini, Roo is a better choice. Otherwise Cursor is better value for money.

Yes, Cursor does have a YOLO mode.
Roo being free and community driven and by being "Bring Your Own Key" has a lot of liberty in experimenting stuff . The biggest difference between cursor and Roo/Cline is that ,  the latter can optimise for results without much consideration on cost, while Cursor  always need to keep Cost in consideration. 

Both are great products. 

Cursor excels in identifying that  piece of code related to the user query , going layer by layer , all by being frugal in tokens , which is an incredible art and feat. But being frugal means, it can also miss some stuff. Compared to that in Roo, one would simply dump all the relevant files and use a model with large context. There are certainly use cases where each has its merit.

Generally I would prefer to use both. When things does not work as expected in one, there is no harm in trying the other . I am certainly on budget. But I have the basic plans of Windsurf and Cursor and SuperGrok . And I use aistudio free tokens  from couple of google accounts and openrouter  until it rate limits

If there is one thing I wish I had discovered earlier was the possibility of automating many repetitive tasks with custom MCPs (like those works that involve excel or google sheets). I knew about MCPs the day it was launched, but never realised its power until recently. If one is using MCPs, Roo's version of MCP is a bit more polished. With the right MCP tools , there is incredible value that one can make even from a cheap model like Gemini Flash.

Of late I have been experimenting with integrating aider as an MCP with Cursor . Didn't get time to play much with it. But that is also one I am very much excited about .
How are you using Roo for free? Are you just using the free models from Google and OpenRouter?

I've seen people spending way more than $20 a month on Cline and Roo code. Cursor is much cheaper if you consider the actual API cost associated with Roo Code.
I personally really dislike cursor.¬†
1. Cursor yolo mode I believe
2. Because they like waiting for slow requests /s¬†
Subscriptions are affordable
3. Go to Google and search best cursorrules.¬†
For roo, you should probably make ur own, or use rooflow¬†
Agree, i just installed roocode abd spent 100usd in 3 days in operouter using gpt 4.0 just to learn to use it
Don‚Äôt you have to pay for openrouter api to use too code?
didn't like SPARC so here's ACE
three things I didn't like about SPARC:

* devops/integration is something I want full control on
* i wanna avoid this tdd obsession
* debug is horrendous

so a simpler approach is born:

* **architect:**¬†designs scalable, secure and modular architectures based on requirements, including diagrams and pseudocode.
* **create:**¬†writes clean, efficient, and modular code based on architectural designs.
* **enhance:**¬†improves code quality, performance, security, and maintainability through analysis, refactoring, and automation.
* **ace manager:**¬†orchestrates complex workflows by delegating tasks to the appropriate modes (architect, create, enhance) and tracking overall progress. manages task decomposition and synthesis.

  
```
{
  "customModes": [
    {
      "customInstructions": "Read documentation, use MCP servers to understand more about the project or other technologies. Create architecture mermaid diagrams and data flows for the Architect Phase IN ADDITION TO modular pseudocode and flow logic that includes clear structure. Split complex logic across modules. Specify key inputs and outputs. Ensure no part of the design includes secrets or hardcoded env values. Emphasize modular boundaries and maintain extensibility. Provide detailed descriptions of data flows and API contracts. MUST provide pseudocode BEFORE diagrams and data flows.  Focus on internal module structure, not deployment details.",
      "groups": ["command", "mcp", "read"],
      "name": "Architect",
      "roleDefinition": "You design scalable, secure, and modular architectures for the ace Architect Phase based on functional specs and user needs. You define responsibilities across services, APIs, components, generate pseudocode AND create architecture diagrams and data flows.",
      "slug": "architect",
      "source": "global"
    },
    {
      "customInstructions": "You create code. Write modular code using clean architecture principles for the Create Phase. Never hardcode secrets or environment values. Always ensure types are strict, avoid using any or leaving variables without types. Use config files or environment abstractions. Focus on code clarity and proper documentation. Provide clear entry-points and describe expected behavior using comments. Use `new_task` for subtasks and finish with `attempt_completion` if a defined end point is achieved.",
      "groups": ["browser", "command", "edit", "mcp", "read"],
      "name": "Create",
      "roleDefinition": "You write clean, efficient, modular code based on pseudocode and architecture, part of the Create Phase. You use configuration for environments and break large components into maintainable files.",
      "slug": "create",
      "source": "global"
    },
    {
      "customInstructions": "You are a Code Enhancer, you polish, specializing in improving the quality, performance, security, and maintainability of existing code, using static code analysis. You will fix vulnerability exploits and improve existing code. Adhere to the ACE methodology throughout. Follow these guidelines:\n\n1.  **Code Analysis:** Use static code analysis (e.g. SonarQube, ESLint, linters, and other tools/processes that improve code) to identify potential issues in the code (violations, security vulnerabilities, performance bottlenecks, maintainability issues).\n\n2. Find and exploit vulnerabilities. Identify risks with security and provide solutions based on the CVE database.\n\n3.  **Root Cause Analysis:** Investigate the root causes of issues and propose solutions to prevent recurrence. Escalate to 'Architect' if necessary to improve architecture so existing issues can be fixed, avoiding future vulnerabilities/exploits.\n\n4.  **Code Refactoring:** Refactor code to improve its clarity, readability, and maintainability. Follow established coding standards and best practices.\n\n5.  **Performance Optimization:**  Identify and address performance bottlenecks in the code. Optimize algorithms, data structures, and resource usage to improve performance. Make clear suggestions on how to improve memory usage and speed.\n\n6.  **Security Hardening:** Improve the security of the code by addressing identified vulnerabilities and implementing security best practices (e.g., input validation, output encoding, secure authentication, protection against common attacks).\n\n7.  **Automated Testing:**  Add or improve automated tests (unit tests, integration tests, etc.) to ensure the code's quality and reliability. Enchance or work with tests written by Create to guarantee functionality.\n\n8.  **Documentation Enhancement:**  Improve the code's documentation by adding comments, updating existing documentation, and ensuring that the documentation is consistent with the code.\n\n9.  **Review of Build/Deployment Pipeline:** Analyze the build and deployment pipeline to check for inefficiencies, security vulnerabilities, and areas where automation can be improved.\n\n10. Version Control and Safe Updates - Updates should be limited for certain files, and always be tracked. Any exploit or vulnerability should include the related version of tools that should be installed in the environment to prevent exposure.\n\n11. **Feedback Loops:** Provide feedback to earlier phases (Architect and Create) if you identify design flaws or coding errors that need to be addressed, passing links to CVE databases for the Create mode to properly deploy.\n\n12. **Code Changes:** Implement code changes to address identified issues and improve the code. Ensure code changes should be small/limited when possible and tested thoroughly. Where applicable, escalate to create mode with detail for the deployment of code changes.\n\n13. **Document Reasoning:** Provide documentation that outlined why code changes were made, data the results of testing. The document should point to version data as well as previous releases.\n\n14. **Completion Signal:**  Use `attempt_completion` with a summary of changes made, a description of the issues addressed, links to CVE, links to tests performed, and any follow-up actions recommended. The report should point to all versions of code and software installed.",
      "groups": ["browser", "command", "edit", "mcp", "read"],
      "name": "Enhance",
      "roleDefinition": "Enhance code quality, performance, security, and maintainability by performing code analysis, refactoring, and automation to prevent coding issues.",
      "slug": "enhance",
      "source": "global"
    },
    {
      "slug": "manager",
      "name": "ACE",
      "roleDefinition": "You are the ACE Manager, orchestrating complex workflows based on the Architect, Create, Enhance methodology. You break down objectives into delegated subtasks, a strategic workflow orchestrator who coordinates complex tasks by delegating them to appropriate specialized modes. You have a comprehensive understanding of each mode's capabilities and limitations, allowing you to effectively break down complex problems into discrete tasks that can be solved by different specialists.",
      "customInstructions": "Welcome! We're using the ACE methodology: Architect (Define, Research & Design), Create (Generate output, solve bugs, ), Enhance (Refine & Optimize).  Follow these steps:\n\n1. **Architect:** Clarify objectives and scope. Create a high-level design/blueprint (pseudocode, diagrams, etc.). Focus on overall structure and data flow. Avoid hardcoded values.\n2. **Create:** Develop the core output (code, text, etc.) based on the design. Maintain modularity.\n3. **Enhance:** Refine and optimize the output. Your role is to coordinate complex workflows by delegating tasks to specialized modes. As an orchestrator, you should:\n\n1. When given a complex task, break it down into logical subtasks that can be delegated to appropriate specialized modes.\n\n2. For each subtask, use the `new_task` tool to delegate. Choose the most appropriate mode for the subtask's specific goal and provide comprehensive instructions in the `message` parameter. These instructions must include:\n    *   All necessary context from the parent task or previous subtasks required to complete the work.\n    *   A clearly defined scope, specifying exactly what the subtask should accomplish.\n    *   An explicit statement that the subtask should *only* perform the work outlined in these instructions and not deviate.\n    *   An instruction for the subtask to signal completion by using the `attempt_completion` tool, providing a concise yet thorough summary of the outcome in the `result` parameter, keeping in mind that this summary will be the source of truth used to keep track of what was completed on this project. \n    *   A statement that these specific instructions supersede any conflicting general instructions the subtask's mode might have.\n\n3. Track and manage the progress of all subtasks. When a subtask is completed, analyze its results and determine the next steps.\n\n4. Help the user understand how the different subtasks fit together in the overall workflow. Provide clear reasoning about why you're delegating specific tasks to specific modes.\n\n5. When all subtasks are completed, synthesize the results and provide a comprehensive overview of what was accomplished.\n\n6. Ask clarifying questions when necessary to better understand how to break down complex tasks effectively.\n\n7. Suggest improvements to the workflow based on the results of completed subtasks.\n\nUse subtasks to maintain clarity. If a request significantly shifts focus or requires a different expertise (mode), consider creating a subtask rather than overloading the current one. \n\nUse `new_task` to assign to any of the following roles:\n- architect\n- create\n- enhance.\n\nDon't use Ask, Debug modes.",
      "groups": [],
      "source": "global"
    }
  ]
}
```
Why the hate on TDD it feels like exactly what would be perfect for AI Coding, short functions that can be 100% tested till they do whats expected, especially with languages like say rust that have such good erroring and testing natively, sub-agents working to get specific functions working perfectly and then wrapping those into the overall function seems smart

Edit: Ugh anger at TDD, but then writes prompts for "clean architecture principles"
My head is now officially swimming with all of the different setup options people are posting here in the reddit community.

What's the best way to play around with these different setup ideas? Do we just add this code to a file inside of a folder and open it in VS Code to automatically import the settings?   
  
Or is there a different/better way?
How can you integrate documentation of libraries/packages you use?
Which models have you tested ACE with? SPARC may work fine on larger models but doesn‚Äôt seem to do well with smaller models. For instance tasks that I can single-shot with DeepSeek-R1-671B-FP or Gemini-2.5-pro-exp-0325 are very difficult to accomplish with SPARC + Gemma3-27b-it for example. In my view if I can‚Äôt scale it down and run it locally then it only has enterprise value at best (which isn‚Äôt nothing but doesn‚Äôt meet a simple users needs).
Apply diff edits with Gemini 2.5 work much better with 3.11.7
The update 3.11.7 should really fix most of the errors people were running into with using the apply\_diff tool. Please let me know your experience if you were having troubles with this before. 
Awesome, thank you. I thought I had lost my mind and was doing something wrong.
A couple of hours ago I added the following instructions to Code and Debug mode, that seem to have made a difference, although it didn't entirely get rid of issues:

> When editing a file, use the following process:

> - Use the apply_diff tool, making sure the diff uses the correct format.

> - If that fails, re-read the whole file, recalculate the diff, and try again.

> - If that fails, read the file and rewrite it with the changes using the write_to_file tool.

I just checked and I'm on 3.11.7, so... Did it improve because of the update, because of the instructions, or both? Can I remove the instructions?
Seems a lot better but still has some issues. Also I noticed that now the ai seems able to stop the terminal now that's really cool. I'll tackle a pretty large yaml project that was driving me insane with failures (bug reported btw) and I'll report back.
Want to use gemini 2.5 pro without rate limit?
I don't know why nobody has made this so far but here we are: have been using it in the past week, haven't encountered any rate limit at all. Use openai compatible provider in roo code and fly...

[https://github.com/junfeiwa/rust-api-spinner-v3-latest](https://github.com/junfeiwa/rust-api-spinner-v3-latest)
This is a good way to get your Google account flagged. I wouldn't do it without any sort of proxying strategy, and even then... look, you can get $300 in credits just by signing up for GCP and you *immediately* get upgraded to 20RPM. This kind of thing really isn't needed.
https://github.com/junfeiwa/rust-api-spinner-v3-latest.   forgot to delete my own api keys from it, this is the new one
Potential future work includes proxy for each api key, and more routing strategy, but im lazy so feel free to take it from here, signing off.
Been using two accounts for the past week just on different versions of vscode. A few billion tokens. No issues
üôåüèº
but why you closed this ????? now cent install it !!!
‚ù§Ô∏è
Hey I‚Äôm having some trouble, I got it working, but say I make google accounts add no billing account and just get the api keys and rotate these api keys would this still be okay? And it says Gemini 1.5 pro latest in the code, I‚Äôm confused since I just signed up for a normal api key I can‚Äôt tell if it‚Äôs the Gemini 2.5 pro exp free?
How to use cursor-tools with Roo (also works with Cline)
Hey there. I just wanted to share that I've gotten [cursor-tools](https://github.com/eastlondoner/cursor-tools) working with Roo Code and I'm really happy with how things are working.

I'm in the process of switching to Roo and I really missed the workflow I had with Cursor where it would talk to `cursor-tools` for large project context questions and code reviews.

[Screenshot of it working](https://github.com/user-attachments/assets/f6b8b3a0-c4d8-47de-8400-130a33c04ee4)

I'm really happy with how this is working. It makes the agent even more independent, and the Gemini Pro project analysis continues to be spot on.

I actually got this working without embedding the normal cursor-tools rules.

First, install cursor-tools following the repo instructions and set up `cursor-tools.config.json` in the project root as usual.

# cursor-tools.config.json

    {
        "repo": {
            "provider": "openrouter",
            "model": "google/gemini-2.0-pro-exp-02-05:free"
        },
        "plan": {
            "fileProvider": "openrouter",
            "thinkingProvider": "openrouter",
            "fileModel": "google/gemini-2.0-pro-exp-02-05:free",
            "thinkingModel": "google/gemini-2.0-flash-thinking-exp:free"
        },
        "doc": {
            "provider": "openrouter",
            "model": "google/gemini-2.0-pro-exp-02-05:free"
        }
    }

Edit: Funnily, Gemini Pro 2.5 just released a few hours after I posted this with hugely improved long context support...

Then set up your `.clinerules` file. This file is compatible with both Cline and Roo Code.

# .clinerules

    # Ask Gemini for help
    
    Gemini is your coding assistant. They have a vast knowledge of the codebase.
    
    ## What Gemini can help with
    
    -   Code Review
    -   Planning solutions
    -   Best practices and code style
    -   Explaining long action chains across multiple files
    
    ## How to run Gemini
    
    -   Use the **terminal command** `cursor-tools`
    -   This is a command you should run in terminal, not an MCP tool.
    -   The commands `cursor-tools plan` & `cursor-tools repo` are explained in further detail below.
    
    # When to ask Gemini
    
    ## Mandatory
    
    ### Code review
    
    Whenever you finish a task and are ready to report back with your results, **you need to ask Gemini to review your work**.
    
    #### Use natural language and try to be as detailed as possible with your question
    cursor-tools repo "Take a look at the work I have done. These are the files: foo, bar, baz, etc. The goal of this work was to achieve XYZ. Please check for bugs or logic gaps, and let me know if I have matched the guidelines and style of the codebase."`
    
    ## Recommended
    
    ### Implementation plan
    
    If the contents of `./context/CURRENT_PROJECT.md`, `./context/CURRENT_TASK.md`, and the guides in the `./documentation` directory do not provide enough information about your implementation, you should ask     Gemini to help you plan out a solution to your specific issue.
    
    #### Architecture question
    `cursor-tools plan "Please help me plan out a way to make personal assistants be able to create bookings etc. on behalf of the therapist they work for."`
    
    #### Stack question
    `cursor-tools plan "Please help me plan out step by step the refactor of our email template system from EJS to a more modern framework."`
    
    ### Second opinion
    
    Before you start writing a new file with a high level of complexity, you can ask Gemini for a second opinion on your intended course of action before you start.
    
    #### Be very specific about your implementation plan, and use Gemini's extensive codebase knowledge to     your advantage
    `cursor-tools repo "I need a second opinion on something. I am about to create a new webhook that captures data from Airtable and syncs it with a user's account. Here is a high level overview of the business logic, 1. x, 2. y, 3. z. I am planning to write this functionality inline in the webhook handler. Does this sound like the best plan, or are there some useful utilities in the codebase that may make this easier?"`

Just FYI, I am not using the more advanced features of Cursor Tools like browser control and Perplexity and as such the above rules only include repo analysis, planning and code review related stuff.
Could this be an mcp?
I've never used Cursor, but what is the benefit of using both Cline/Roo + Cursor.

Can you not just get Roo to switch modes for code reviews within the cline rules?

Great to see it working for you - just trying to understand what the benefits of combining both are vs Cline/Roo alone.
Couldn't you just use the Gemini model directly in Roo?
If you are using Cursor and Roo, I honestly don't see any advantages to cursor-tools.

Browser, plan and act phase, documentation, web search, codebase search. Aren't all of these things already present in Roo and Cursor?
Been playing around with boomerang and agents in Roo using the rules files from https://github.com/GreatScottyMac/roo-code-memory-bank.git as a starting point. Sonnet is a PITA being horny to code but the new Gemini 2.5 pro seems really great at reliably handling tool calls and sticking to the rules. The general idea is a boss mode that subtasks other modes/agent that do their piece and then return to the boss for the next assignment. Just need to tighten up the handoffs etc but so far it works ok except for Sonnet. That bugger just wants to keep going and going.
Roo Code 3.7 - Yes, we support Claude Sonnet 3.7

Thank you for being awesome!
5 stars as always, thank you,
Great!!
Congrats!
awesome! but..... it's never worked for me and now gone?
Gemini 2.5 Flash + Thinking, A New Look, File Appending and Bug Squashing! | Roo Code 3.13 Release Notes

If I try to use the Gemini-2.5-flash-preview-thinking model (through OpenRouter), the only response I ever get is:

`Roo is having trouble...`

`Roo Code uses complex prompts and iterative task execution that may be challenging for less capable models. For best results, it's recommended to use Claude 3.7 Sonnet for its advanced agentic coding capabilities.`

Is there some extra configuration needed?
Who wants prettier "thinking"?

Absolutely!
Noice!
What is this architecturally, u/hannesrudolph? Just "output the thinking as markdown" + markdown parser or..?
Awesome!
Roo Code 3.3.19 - BUG squash time!!
- Fix a bug where aborting in the middle of file writes would not revert the write
- Honor the VS Code theme for dialog backgrounds
- Make it possible to clear out the default custom instructions for built-in modes
- Add a help button that links to our new documentation site (which we would love help from the community to improve!)
- Switch checkpoints logic to use a shadow git repository to work around issues with hot reloads and polluting existing repositories (thanks Cline for the inspiration!)

‚Äî‚Äî

# Roo Code is free, but I need a favor‚Äîtake a minute and  **[Leave a review here](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline&ssr=false#review-details)**. It helps more people find Roo Code!
Let the team cook. Thank you and anyone else who has helped make this project possible; it‚Äôs dope.
I love waking up to read about Roo improvements, makes my coffee taste even better :)

Help an 'ole man understand this (looked at docs):

"Switch checkpoints logic to use a shadow git repository to work around issues with hot reloads and polluting existing repositories (thanks Cline for the inspiration!)"
>Fix a bug where aborting in the middle of file writes would not revert the write

Oh thank the lord. I was definitely getting this one today.
You guys (and gals?) are fucking killing it. Thanks for all you do!
so many updates, these guys are really feeling the agi
Great work guys!@
3 tiny changes that lower my blood pressure and gives me a nice little dopamine hit of satisfaction each time I watch them in use
First, in the write\_to\_file tool description I added "favored operating pattern is to use apply\_diff."

Second, I (Roo, under my direction haha) added a programmatic check that requires a file to have been read before it can be edited, if it's not a new file, for both write\_to\_file and apply\_diff. After the change is saved the check is cleared. I love watching this work and watching the ai be forced to read the file before editing it -- helps create more accurate apply\_diffs too.

https://preview.redd.it/c58sycjyz1he1.png?width=1402&format=png&auto=webp&s=ff2d6aa789f6c2c9293cd0eef3219f78817e4214

I'll be adding to this check when editing a file that Roo hasn't made silent changes to the file over what was intended and authorized to be changed.

Third, I added an element to the response given back to the ai after to write\_to\_file or apply\_diff that directs the ai to commit with a "detailed, specific, measured, descriptive commit message that leave meticulous forensic evidence for future ai‚Äôs to know and understand every action and intention. Make sure not to be unjustifiably definitive in your claims. Future ai‚Äôs must be able to understand the true state of functionality and the complete thinking and actions in code from commit messages." This one makes me happy each time too: a drastic lessening of annoyance.

Tiny changes with huge reductions in frustration = nice little pleasures.

Edit: words.
This is awesome! Any interest in opening a PR with these changes? More than happy to help support.
How to add the programmatic check?
Must be a pretty chunky file to cost > $0.50 per request.
